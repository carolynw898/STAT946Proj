{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b74adf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T23:08:51.261146Z",
     "iopub.status.busy": "2025-04-07T23:08:51.260851Z",
     "iopub.status.idle": "2025-04-07T23:08:52.486801Z",
     "shell.execute_reply": "2025-04-07T23:08:52.485745Z"
    },
    "papermill": {
     "duration": 1.232016,
     "end_time": "2025-04-07T23:08:52.488286",
     "exception": false,
     "start_time": "2025-04-07T23:08:51.256270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\n",
      "/kaggle/input/1-var-dataset/1_var_test.json\n",
      "/kaggle/input/1-var-dataset/1_var_val.json\n",
      "/kaggle/input/1-var-dataset/1_var_train.json\n",
      "/kaggle/input/xye_9var/pytorch/default/1/XYE_9Var.pt\n",
      "/kaggle/input/symbolic_diffusion_initial/pytorch/default/1/symbolic_diffusion_model.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354e1d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:08:52.495460Z",
     "iopub.status.busy": "2025-04-07T23:08:52.495112Z",
     "iopub.status.idle": "2025-04-07T23:08:57.385843Z",
     "shell.execute_reply": "2025-04-07T23:08:57.384806Z"
    },
    "papermill": {
     "duration": 4.896046,
     "end_time": "2025-04-07T23:08:57.387596",
     "exception": false,
     "start_time": "2025-04-07T23:08:52.491550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import glob\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "from math import exp, sin, cos\n",
    "\n",
    "\n",
    "def generateDataStrEq(\n",
    "    eq, n_points=2, n_vars=3, decimals=4, supportPoints=None, min_x=0, max_x=3\n",
    "):\n",
    "    X = []\n",
    "    Y = []\n",
    "    # TODO: Need to make this faster\n",
    "    for p in range(n_points):\n",
    "        if supportPoints is None:\n",
    "            if type(min_x) == list:\n",
    "                x = []\n",
    "                for _ in range(n_vars):\n",
    "                    idx = np.random.randint(len(min_x))\n",
    "                    x += list(\n",
    "                        np.round(np.random.uniform(min_x[idx], max_x[idx], 1), decimals)\n",
    "                    )\n",
    "            else:\n",
    "                x = list(np.round(np.random.uniform(min_x, max_x, n_vars), decimals))\n",
    "            assert (\n",
    "                len(x) != 0\n",
    "            ), \"For some reason, we didn't generate the points correctly!\"\n",
    "        else:\n",
    "            x = supportPoints[p]\n",
    "\n",
    "        tmpEq = eq + \"\"\n",
    "        for nVID in range(n_vars):\n",
    "            tmpEq = tmpEq.replace(\"x{}\".format(nVID + 1), str(x[nVID]))\n",
    "        y = float(np.round(eval(tmpEq), decimals))\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# def processDataFiles(files):\n",
    "#     text = \"\"\n",
    "#     for f in tqdm(files):\n",
    "#         with open(f, 'r') as h:\n",
    "#             lines = h.read() # don't worry we won't run out of file handles\n",
    "#             if lines[-1]==-1:\n",
    "#                 lines = lines[:-1]\n",
    "#             #text += lines #json.loads(line)\n",
    "#             text = ''.join([lines,text])\n",
    "#     return text\n",
    "\n",
    "\n",
    "def processDataFiles(files):\n",
    "    text = \"\"\n",
    "    for f in files:\n",
    "        with open(f, \"r\") as h:\n",
    "            lines = h.read()  # don't worry we won't run out of file handles\n",
    "            if lines[-1] == -1:\n",
    "                lines = lines[:-1]\n",
    "            # text += lines #json.loads(line)\n",
    "            text = \"\".join([lines, text])\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize_equation(eq):\n",
    "    token_spec = [\n",
    "        (r'\\*\\*'),                # exponentiation\n",
    "        (r'exp'),                 # exp function\n",
    "        (r'[+\\-*/=()]'),          # operators and parentheses\n",
    "        (r'sin'),                 # sin function\n",
    "        (r'cos'),                 # cos function\n",
    "        (r'log'),                 # log function\n",
    "        (r'x\\d+'),                # variables like x1, x23, etc.\n",
    "        (r'C'),                   # constants placeholder\n",
    "        (r'-?\\d+\\.\\d+'),          # decimal numbers\n",
    "        (r'-?\\d+'),               # integers\n",
    "        (r'_'),                   # padding token\n",
    "    ]\n",
    "    token_regex = '|'.join(f'({pattern})' for pattern in token_spec)\n",
    "    matches = re.finditer(token_regex, eq)\n",
    "    return [match.group(0) for match in matches]\n",
    "\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        block_size,\n",
    "        tokens,\n",
    "        numVars,\n",
    "        numYs,\n",
    "        numPoints,\n",
    "        target=\"Skeleton\",\n",
    "        addVars=False,\n",
    "        const_range=[-0.4, 0.4],\n",
    "        xRange=[-3.0, 3.0],\n",
    "        decimals=4,\n",
    "        augment=False,\n",
    "    ):\n",
    "\n",
    "        data_size, vocab_size = len(data), len(tokens)\n",
    "        print(\"data has %d examples, %d unique.\" % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = {tok: i for i, tok in enumerate(tokens)}\n",
    "        self.itos = {i: tok for i, tok in enumerate(tokens)}\n",
    "\n",
    "\n",
    "        self.numVars = numVars\n",
    "        self.numYs = numYs\n",
    "        self.numPoints = numPoints\n",
    "\n",
    "        # padding token\n",
    "        self.paddingToken = \"_\"\n",
    "        self.paddingID = self.stoi[\"_\"]  # or another ID not already used\n",
    "        self.stoi[self.paddingToken] = self.paddingID\n",
    "        self.itos[self.paddingID] = self.paddingToken\n",
    "\n",
    "        self.threshold = [-1000, 1000]\n",
    "\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data  # it should be a list of examples\n",
    "        self.target = target\n",
    "        self.addVars = addVars\n",
    "\n",
    "        self.const_range = const_range\n",
    "        self.xRange = xRange\n",
    "        self.decimals = decimals\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab an example from the data\n",
    "        chunk = self.data[idx]  # sequence of tokens including x, y, eq, etc.\n",
    "\n",
    "        try:\n",
    "            chunk = json.loads(chunk)  # convert the sequence tokens to a dictionary\n",
    "        except Exception as e:\n",
    "            print(\"Couldn't convert to json: {} \\n error is: {}\".format(chunk, e))\n",
    "            # try the previous example\n",
    "            idx = idx - 1\n",
    "            idx = idx if idx >= 0 else 0\n",
    "            chunk = self.data[idx]\n",
    "            chunk = json.loads(chunk)  # convert the sequence tokens to a dictionary\n",
    "\n",
    "        # find the number of variables in the equation\n",
    "        printInfoCondition = random.random() < 0.0000001\n",
    "        eq = chunk[self.target]\n",
    "        if printInfoCondition:\n",
    "            print(f\"\\nEquation: {eq}\")\n",
    "        vars = re.finditer(\"x[\\d]+\", eq)\n",
    "        numVars = 0\n",
    "        for v in vars:\n",
    "            v = v.group(0).strip(\"x\")\n",
    "            v = eval(v)\n",
    "            v = int(v)\n",
    "            if v > numVars:\n",
    "                numVars = v\n",
    "\n",
    "        if self.target == \"Skeleton\" and self.augment:\n",
    "            threshold = 5000\n",
    "            # randomly generate the constants\n",
    "            cleanEqn = \"\"\n",
    "            for chr in eq:\n",
    "                if chr == \"C\":\n",
    "                    # genereate a new random number\n",
    "                    chr = \"{}\".format(\n",
    "                        np.random.uniform(self.const_range[0], self.const_range[1])\n",
    "                    )\n",
    "                cleanEqn += chr\n",
    "\n",
    "            # update the points\n",
    "            nPoints = np.random.randint(\n",
    "                *self.numPoints\n",
    "            )  # if supportPoints is None else len(supportPoints)\n",
    "            try:\n",
    "                if printInfoCondition:\n",
    "                    print(\"Org:\", chunk[\"X\"], chunk[\"Y\"])\n",
    "\n",
    "                X, y = generateDataStrEq(\n",
    "                    cleanEqn,\n",
    "                    n_points=nPoints,\n",
    "                    n_vars=self.numVars,\n",
    "                    decimals=self.decimals,\n",
    "                    min_x=self.xRange[0],\n",
    "                    max_x=self.xRange[1],\n",
    "                )\n",
    "\n",
    "                # replace out of threshold with maximum numbers\n",
    "                y = [e if abs(e) < threshold else np.sign(e) * threshold for e in y]\n",
    "\n",
    "                # check if there is nan/inf/very large numbers in the y\n",
    "                conditions = (\n",
    "                    (np.isnan(y).any() or np.isinf(y).any())\n",
    "                    or len(y) == 0\n",
    "                    or (abs(min(y)) > threshold or abs(max(y)) > threshold)\n",
    "                )\n",
    "                if not conditions:\n",
    "                    chunk[\"X\"], chunk[\"Y\"] = X, y\n",
    "\n",
    "                if printInfoCondition:\n",
    "                    print(\"Evd:\", chunk[\"X\"], chunk[\"Y\"])\n",
    "            except Exception as e:\n",
    "                # for different reason this might happend including but not limited to division by zero\n",
    "                print(\n",
    "                    \"\".join(\n",
    "                        [\n",
    "                            f\"We just used the original equation and support points because of {e}. \",\n",
    "                            f\"The equation is {eq}, and we update the equation to {cleanEqn}\",\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # encode every character in the equation to an integer\n",
    "        # < is SOS, > is EOS\n",
    "        if self.addVars:\n",
    "            dix = [self.stoi[s] for s in \"<\" + str(numVars) + \":\" + eq + \">\"]\n",
    "        else:\n",
    "            eq_tokens = tokenize_equation(eq)\n",
    "            if self.addVars:\n",
    "                token_seq = [\"<\", str(numVars), \":\", *eq_tokens, \">\"]\n",
    "            else:\n",
    "                token_seq = [\"<\", *eq_tokens, \">\"]\n",
    "            dix = [self.stoi[tok] for tok in token_seq]\n",
    "\n",
    "        inputs = dix[:-1]\n",
    "        outputs = dix[1:]\n",
    "\n",
    "        # add the padding to the equations\n",
    "        paddingSize = max(self.block_size - len(inputs), 0)\n",
    "        paddingList = [self.paddingID] * paddingSize\n",
    "        inputs += paddingList\n",
    "        outputs += paddingList\n",
    "\n",
    "        # make sure it is not more than what should be\n",
    "        inputs = inputs[: self.block_size]\n",
    "        outputs = outputs[: self.block_size]\n",
    "\n",
    "        points = torch.zeros(self.numVars + self.numYs, self.numPoints - 1)\n",
    "        for idx, xy in enumerate(zip(chunk[\"X\"], chunk[\"Y\"])):\n",
    "\n",
    "            if not isinstance(xy[0], list) or not isinstance(\n",
    "                xy[1], (list, float, np.float64)\n",
    "            ):\n",
    "                print(f\"Unexpected types: {type(xy[0])}, {type(xy[1])}\")\n",
    "                continue  # Skip if types are incorrect\n",
    "\n",
    "            # don't let to exceed the maximum number of points\n",
    "            if idx >= self.numPoints - 1:\n",
    "                break\n",
    "\n",
    "            x = xy[0]\n",
    "            x = x + [0] * (max(self.numVars - len(x), 0))  # padding\n",
    "\n",
    "            y = [xy[1]] if type(xy[1]) == float or type(xy[1]) == np.float64 else xy[1]\n",
    "\n",
    "            y = y + [0] * (max(self.numYs - len(y), 0))  # padding\n",
    "            p = x + y  # because it is only one point\n",
    "            p = torch.tensor(p)\n",
    "            # replace nan and inf\n",
    "            p = torch.nan_to_num(\n",
    "                p,\n",
    "                nan=self.threshold[1],\n",
    "                posinf=self.threshold[1],\n",
    "                neginf=self.threshold[0],\n",
    "            )\n",
    "            \n",
    "            points[:, idx] = p\n",
    "\n",
    "        points = torch.nan_to_num(\n",
    "            points,\n",
    "            nan=self.threshold[1],\n",
    "            posinf=self.threshold[1],\n",
    "            neginf=self.threshold[0],\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        outputs = torch.tensor(outputs, dtype=torch.long)\n",
    "        numVars = torch.tensor(numVars, dtype=torch.long)\n",
    "        return inputs, outputs, points, numVars\n",
    "\n",
    "\n",
    "# Relative Mean Square Error\n",
    "def relativeErr(y, yHat, info=False, eps=1e-5):\n",
    "    yHat = np.reshape(yHat, [1, -1])[0]\n",
    "    y = np.reshape(y, [1, -1])[0]\n",
    "    if len(y) > 0 and len(y) == len(yHat):\n",
    "        err = ((yHat - y)) ** 2 / np.linalg.norm(y + eps)\n",
    "        if info:\n",
    "            for _ in range(5):\n",
    "                i = np.random.randint(len(y))\n",
    "                print(\"yPR,yTrue:{},{}, Err:{}\".format(yHat[i], y[i], err[i]))\n",
    "    else:\n",
    "        err = 100\n",
    "\n",
    "    return np.mean(err)\n",
    "\n",
    "\n",
    "def lossFunc(constants, eq, X, Y, eps=1e-5):\n",
    "    err = 0\n",
    "    eq = eq.replace(\"C\", \"{}\").format(*constants)\n",
    "\n",
    "    for x, y in zip(X, Y):\n",
    "        eqTemp = eq + \"\"\n",
    "        if type(x) == np.float32:\n",
    "            x = [x]\n",
    "        for i, e in enumerate(x):\n",
    "            # make sure e is not a tensor\n",
    "            if type(e) == torch.Tensor:\n",
    "                e = e.item()\n",
    "            eqTemp = eqTemp.replace(\"x{}\".format(i + 1), str(e))\n",
    "        try:\n",
    "            yHat = eval(eqTemp)\n",
    "        except:\n",
    "            print(\"Exception has been occured! EQ: {}, OR: {}\".format(eqTemp, eq))\n",
    "            continue\n",
    "            yHat = 100\n",
    "        try:\n",
    "            # handle overflow\n",
    "            err += relativeErr(y, yHat)  # (y-yHat)**2\n",
    "        except:\n",
    "            print(\n",
    "                \"Exception has been occured! EQ: {}, OR: {}, y:{}-yHat:{}\".format(\n",
    "                    eqTemp, eq, y, yHat\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "            err += 10\n",
    "\n",
    "    err /= len(Y)\n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357cb622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:08:57.395196Z",
     "iopub.status.busy": "2025-04-07T23:08:57.394791Z",
     "iopub.status.idle": "2025-04-07T23:08:57.418946Z",
     "shell.execute_reply": "2025-04-07T23:08:57.418078Z"
    },
    "papermill": {
     "duration": 0.029181,
     "end_time": "2025-04-07T23:08:57.420169",
     "exception": false,
     "start_time": "2025-04-07T23:08:57.390988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from SymbolicGPT: https://github.com/mojivalipour/symbolicgpt/blob/master/models.py\n",
    "class PointNetConfig:\n",
    "    \"\"\"base PointNet config\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddingSize,\n",
    "        numberofPoints,\n",
    "        numberofVars,\n",
    "        numberofYs,\n",
    "        method=\"GPT\",\n",
    "        varibleEmbedding=\"NOT_VAR\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.embeddingSize = embeddingSize\n",
    "        self.numberofPoints = numberofPoints  # number of points\n",
    "        self.numberofVars = numberofVars  # input dimension (Xs)\n",
    "        self.numberofYs = numberofYs  # output dimension (Ys)\n",
    "        self.method = method\n",
    "        self.varibleEmbedding = varibleEmbedding\n",
    "\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    \"\"\"\n",
    "    The PointNet structure in the orginal PointNet paper:\n",
    "    PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation by Qi et. al. 2017\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "        self.num_units = config.embeddingSize\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            config.numberofVars + config.numberofYs, self.num_units, 1\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(self.num_units, 2 * self.num_units, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * self.num_units, 4 * self.num_units, 1)\n",
    "        self.fc1 = nn.Linear(4 * self.num_units, 2 * self.num_units)\n",
    "        self.fc2 = nn.Linear(2 * self.num_units, self.num_units)\n",
    "\n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "        self.input_batch_norm = nn.BatchNorm1d(config.numberofVars + config.numberofYs)\n",
    "        # self.input_layer_norm = nn.LayerNorm(config.numberofPoints)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.num_units)\n",
    "        self.bn2 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn3 = nn.BatchNorm1d(4 * self.num_units)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn5 = nn.BatchNorm1d(self.num_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [batch, #features, #points]\n",
    "        :return:\n",
    "            logit: [batch, embedding_size]\n",
    "        \"\"\"\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        x, _ = torch.max(x, dim=2)  # global max pooling\n",
    "        assert x.size(1) == 4 * self.num_units\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        # x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class NoisePredictionTransformer(nn.Module):\n",
    "    def __init__(self, n_embd, max_seq_len, n_layer=6, n_head=8, max_timesteps=1000):\n",
    "        super().__init__()\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, max_seq_len, n_embd))\n",
    "        self.time_emb = nn.Embedding(max_timesteps, n_embd)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=n_embd,\n",
    "            nhead=n_head,\n",
    "            dim_feedforward=n_embd * 4,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layer)\n",
    "\n",
    "    def forward(self, x_t, t, condition):\n",
    "        B, L, _ = x_t.shape\n",
    "        pos_emb = self.pos_emb[:, :L, :]\n",
    "        time_emb = self.time_emb(t).unsqueeze(1)\n",
    "        condition = condition.unsqueeze(1)\n",
    "        x = x_t + pos_emb + time_emb + condition\n",
    "        return self.encoder(x)  # Predicts x_start\n",
    "\n",
    "\n",
    "# Symbolic Diffusion with Hybrid Loss\n",
    "class SymbolicGaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tnet_config,\n",
    "        vocab_size,\n",
    "        max_seq_len,\n",
    "        padding_idx: int = 0,\n",
    "        max_num_vars: int = 9,\n",
    "        n_layer=6,\n",
    "        n_head=8,\n",
    "        n_embd=512,\n",
    "        timesteps=1000,\n",
    "        beta_start=0.0001,\n",
    "        beta_end=0.02,\n",
    "        ce_weight=1.0,  # Weight for CE loss relative to MSE\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.padding_idx = padding_idx\n",
    "        self.n_embd = n_embd\n",
    "        self.timesteps = timesteps\n",
    "        self.ce_weight = ce_weight\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Embedding layers\n",
    "        self.tok_emb = nn.Embedding(vocab_size, n_embd, padding_idx=self.padding_idx)\n",
    "        self.vars_emb = nn.Embedding(max_num_vars, n_embd)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Linear(n_embd, vocab_size, bias=False)\n",
    "        self.decoder.weight = self.tok_emb.weight\n",
    "\n",
    "        # Models\n",
    "        self.tnet = tNet(tnet_config)\n",
    "        self.model = NoisePredictionTransformer(\n",
    "            n_embd, max_seq_len, n_layer, n_head, timesteps\n",
    "        )\n",
    "\n",
    "        # Noise schedule\n",
    "        self.register_buffer(\"beta\", torch.linspace(beta_start, beta_end, timesteps))\n",
    "        self.register_buffer(\"alpha\", 1.0 - self.beta)\n",
    "        self.register_buffer(\"alpha_bar\", torch.cumprod(self.alpha, dim=0))\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        noise = torch.randn_like(x_start)\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t]).view(-1, 1, 1)\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar[t]).view(-1, 1, 1)\n",
    "\n",
    "        x_t = sqrt_alpha_bar * x_start + sqrt_one_minus_alpha_bar * noise\n",
    "        return x_t\n",
    "\n",
    "    def p_mean_variance(self, x, t, t_next, condition):\n",
    "        alpha_t = self.alpha[t]\n",
    "        alpha_bar_t = self.alpha_bar[t]\n",
    "        alpha_bar_t_next = self.alpha_bar[t_next]\n",
    "        beta_t = self.beta[t]\n",
    "\n",
    "        x_start_pred = self.model(x, t.long(), condition)\n",
    "\n",
    "        coeff1 = torch.sqrt(alpha_bar_t_next) * beta_t / (1 - alpha_bar_t)\n",
    "        coeff2 = torch.sqrt(alpha_t) * (1 - alpha_bar_t_next) / (1 - alpha_bar_t)\n",
    "        mean = coeff1 * x_start_pred + coeff2 * x\n",
    "        variance = (1 - alpha_bar_t_next) / (1 - alpha_bar_t) * beta_t\n",
    "        return mean, variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, t_next, condition):\n",
    "        mean, variance = self.p_mean_variance(x, t, t_next, condition)\n",
    "        if torch.all(t_next == 0):\n",
    "            return mean\n",
    "        noise = torch.randn_like(x)\n",
    "        return mean + torch.sqrt(variance) * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, points, variables, batch_size=16):\n",
    "        condition = self.tnet(points) + self.vars_emb(variables)\n",
    "        shape = (batch_size, self.max_seq_len, self.n_embd)\n",
    "        x = torch.randn(shape, device=self.device)\n",
    "        steps = torch.arange(self.timesteps, 0, -1, device=self.device)\n",
    "\n",
    "        for i in tqdm(\n",
    "            range(self.timesteps), desc=\"sampling loop\", total=self.timesteps\n",
    "        ):\n",
    "            t = steps[i]\n",
    "            t_next = (\n",
    "                steps[i + 1]\n",
    "                if i + 1 < self.timesteps\n",
    "                else torch.tensor(0, device=self.device)\n",
    "            )\n",
    "            x = self.p_sample(x, t, t_next, condition)\n",
    "\n",
    "        # Map embeddings to token indices via decoder\n",
    "        logits = self.decoder(x)  # [B, L, vocab_size]\n",
    "        token_indices = torch.argmax(logits, dim=-1)  # [B, L]\n",
    "        return token_indices\n",
    "\n",
    "    def p_losses(self, x_start, points, tokens, variables, t, noise=None):\n",
    "        \"\"\"Hybrid loss: MSE on embeddings + CE on tokens.\"\"\"\n",
    "        noise = torch.randn_like(x_start) if noise is None else noise\n",
    "        x_t = self.q_sample(x_start, t, noise)\n",
    "        condition = self.tnet(points) + self.vars_emb(variables)\n",
    "        x_start_pred = self.model(x_t, t.long(), condition)\n",
    "\n",
    "        # MSE loss on embeddings\n",
    "        mse_loss = F.mse_loss(x_start_pred, x_start)\n",
    "\n",
    "        # CE loss on tokens\n",
    "        logits = self.decoder(x_start_pred)  # [B, L, vocab_size]\n",
    "        ce_loss = F.cross_entropy(\n",
    "            logits.view(-1, self.vocab_size),  # [B*L, vocab_size]\n",
    "            tokens.view(-1),  # [B*L]\n",
    "            ignore_index=self.padding_idx,  # Assuming padding_idx=0\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = mse_loss + self.ce_weight * ce_loss\n",
    "        return total_loss, mse_loss, ce_loss\n",
    "\n",
    "    def forward(self, points, tokens, variables, t):\n",
    "        token_emb = self.tok_emb(tokens)\n",
    "        total_loss, mse_loss, ce_loss = self.p_losses(\n",
    "            token_emb, points, tokens, variables, t\n",
    "        )\n",
    "        return total_loss, mse_loss, ce_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfdd9cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:08:57.427252Z",
     "iopub.status.busy": "2025-04-07T23:08:57.427013Z",
     "iopub.status.idle": "2025-04-07T23:08:57.441190Z",
     "shell.execute_reply": "2025-04-07T23:08:57.440553Z"
    },
    "papermill": {
     "duration": 0.019222,
     "end_time": "2025-04-07T23:08:57.442508",
     "exception": false,
     "start_time": "2025-04-07T23:08:57.423286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: SymbolicGaussianDiffusion,  # Changed type hint\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: Adam,\n",
    "    train_dataset: CharDataset,\n",
    "    timesteps: int,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    num_epochs: int,\n",
    ") -> Tuple[float, float, float]:  # Now returns all loss components\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_mse_loss = 0\n",
    "    total_ce_loss = 0\n",
    "\n",
    "    for i, (_, tokens, points, variables) in tqdm.tqdm(\n",
    "        enumerate(train_loader),\n",
    "        total=len(train_loader),\n",
    "        desc=f\"Epoch {epoch+1}/{num_epochs}\",\n",
    "    ):\n",
    "        points, tokens, variables = (\n",
    "            points.to(device),\n",
    "            tokens.to(device),\n",
    "            variables.to(device),\n",
    "        )\n",
    "        t = torch.randint(0, timesteps, (tokens.shape[0],), device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Model now returns (total_loss, mse_loss, ce_loss)\n",
    "        total_loss, mse_loss, ce_loss = model(points, tokens, variables, t)\n",
    "\n",
    "        if (i + 1) % 250 == 0:\n",
    "            print(f\"Batch {i + 1}/{len(train_loader)}:\")\n",
    "            print(f\"total_loss: {total_loss}, mse: {mse_loss}, ce: {ce_loss}\")\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate all losses\n",
    "        total_train_loss += total_loss.item()\n",
    "        total_mse_loss += mse_loss.item()\n",
    "        total_ce_loss += ce_loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_mse_loss = total_mse_loss / len(train_loader)\n",
    "    avg_ce_loss = total_ce_loss / len(train_loader)\n",
    "    return avg_train_loss, avg_mse_loss, avg_ce_loss\n",
    "\n",
    "\n",
    "def val_epoch(\n",
    "    model: SymbolicGaussianDiffusion,  # Changed type hint\n",
    "    val_loader: DataLoader,\n",
    "    train_dataset: CharDataset,\n",
    "    timesteps: int,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    num_epochs: int,\n",
    ") -> Tuple[float, float, float]:  # Now returns all loss components\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_mse_loss = 0\n",
    "    total_ce_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, tokens, points, variables in tqdm.tqdm(\n",
    "            val_loader, total=len(val_loader), desc=\"Validating\"\n",
    "        ):\n",
    "            points, tokens, variables = (\n",
    "                points.to(device),\n",
    "                tokens.to(device),\n",
    "                variables.to(device),\n",
    "            )\n",
    "            t = torch.randint(0, timesteps, (tokens.shape[0],), device=device)\n",
    "\n",
    "            # Model returns (total_loss, mse_loss, ce_loss)\n",
    "            total_loss, mse_loss, ce_loss = model(points, tokens, variables, t)\n",
    "\n",
    "            total_val_loss += total_loss.item()\n",
    "            total_mse_loss += mse_loss.item()\n",
    "            total_ce_loss += ce_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    avg_mse_loss = total_mse_loss / len(val_loader)\n",
    "    avg_ce_loss = total_ce_loss / len(val_loader)\n",
    "    return avg_val_loss, avg_mse_loss, avg_ce_loss\n",
    "\n",
    "\n",
    "def train_single_gpu(\n",
    "    model: SymbolicGaussianDiffusion,  # Changed type hint\n",
    "    train_dataset: CharDataset,\n",
    "    val_dataset: CharDataset,\n",
    "    num_epochs=10,\n",
    "    save_every=2,\n",
    "    batch_size=32,\n",
    "    timesteps=1000,\n",
    "    learning_rate=1e-3,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train with epoch progress\n",
    "        avg_train_loss, avg_mse_loss, avg_ce_loss = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            train_dataset,\n",
    "            timesteps,\n",
    "            device,\n",
    "            epoch,\n",
    "            num_epochs,\n",
    "        )\n",
    "\n",
    "        # Validate with epoch progress\n",
    "        avg_val_loss, val_mse_loss, val_ce_loss = val_epoch(\n",
    "            model, val_loader, train_dataset, timesteps, device, epoch, num_epochs\n",
    "        )\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        # Print detailed epoch summary\n",
    "        print(\"\\nEpoch Summary:\")\n",
    "        print(\n",
    "            f\"Train Total Loss: {avg_train_loss:.4f} (MSE: {avg_mse_loss:.4f}, CE: {avg_ce_loss:.4f})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Val Total Loss: {avg_val_loss:.4f} (MSE: {val_mse_loss:.4f}, CE: {val_ce_loss:.4f})\"\n",
    "        )\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            state_dict = model.state_dict()\n",
    "            torch.save(state_dict, \"best_model.pth\")\n",
    "            print(f\"New best model saved with val loss: {best_val_loss:.4f}\")\n",
    "\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6ca877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:08:57.449353Z",
     "iopub.status.busy": "2025-04-07T23:08:57.449124Z",
     "iopub.status.idle": "2025-04-07T23:08:57.537941Z",
     "shell.execute_reply": "2025-04-07T23:08:57.537075Z"
    },
    "papermill": {
     "duration": 0.093742,
     "end_time": "2025-04-07T23:08:57.539324",
     "exception": false,
     "start_time": "2025-04-07T23:08:57.445582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "n_embd = 512\n",
    "timesteps = 1000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 5\n",
    "blockSize = 32\n",
    "numVars = 1\n",
    "numYs = 1\n",
    "numPoints = 250\n",
    "target = 'Skeleton'\n",
    "const_range = [-2.1, 2.1]\n",
    "trainRange = [-3.0, 3.0]\n",
    "decimals = 8\n",
    "addVars = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098de390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:08:57.546605Z",
     "iopub.status.busy": "2025-04-07T23:08:57.546340Z",
     "iopub.status.idle": "2025-04-07T23:08:57.549516Z",
     "shell.execute_reply": "2025-04-07T23:08:57.548799Z"
    },
    "papermill": {
     "duration": 0.008232,
     "end_time": "2025-04-07T23:08:57.550949",
     "exception": false,
     "start_time": "2025-04-07T23:08:57.542717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"/kaggle/input/1-var-dataset/1_var_train.json\"\n",
    "val_path = \"/kaggle/input/1-var-dataset/1_var_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af953c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:08:57.558313Z",
     "iopub.status.busy": "2025-04-07T23:08:57.558072Z",
     "iopub.status.idle": "2025-04-07T23:09:15.439563Z",
     "shell.execute_reply": "2025-04-07T23:09:15.438548Z"
    },
    "papermill": {
     "duration": 17.886557,
     "end_time": "2025-04-07T23:09:15.440845",
     "exception": false,
     "start_time": "2025-04-07T23:08:57.554288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 498795 examples, 27 unique.\n",
      "id:50277\n",
      "outputs:C*x1+C>__________________________\n",
      "variables:1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "\n",
    "files = glob.glob(train_path)\n",
    "text = processDataFiles(files)\n",
    "text = text.split('\\n') # convert the raw text to a set of examples\n",
    "# skeletons = []\n",
    "skeletons = [json.loads(item)['Skeleton'] for item in text if item.strip()]\n",
    "all_tokens = set()\n",
    "for eq in skeletons:\n",
    "    all_tokens.update(tokenize_equation(eq))\n",
    "integers = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "all_tokens.update(integers)  # add all integers to the token set\n",
    "tokens = sorted(list(all_tokens) + ['_', 'T', '<', '>', ':'])  # special tokens\n",
    "trainText = text[:-1] if len(text[-1]) == 0 else text\n",
    "random.shuffle(trainText) # shuffle the dataset, it's important specailly for the combined number of variables experiment\n",
    "train_dataset = CharDataset(trainText, blockSize, tokens=tokens, numVars=numVars,\n",
    "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
    "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
    "\n",
    "idx = np.random.randint(train_dataset.__len__())\n",
    "inputs, outputs, points, variables = train_dataset.__getitem__(idx)\n",
    "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
    "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
    "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d179060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:09:15.447578Z",
     "iopub.status.busy": "2025-04-07T23:09:15.447315Z",
     "iopub.status.idle": "2025-04-07T23:09:15.538419Z",
     "shell.execute_reply": "2025-04-07T23:09:15.537645Z"
    },
    "papermill": {
     "duration": 0.095837,
     "end_time": "2025-04-07T23:09:15.539763",
     "exception": false,
     "start_time": "2025-04-07T23:09:15.443926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 972 examples, 27 unique.\n",
      "tensor(-2.9973) tensor(2.8438)\n",
      "id:485\n",
      "outputs:C>______________________________\n",
      "variables:0\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(val_path)\n",
    "textVal = processDataFiles([files[0]])\n",
    "textVal = textVal.split('\\n') # convert the raw text to a set of examples\n",
    "val_dataset = CharDataset(textVal, blockSize, tokens=tokens, numVars=numVars,\n",
    "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
    "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
    "\n",
    "# print a random sample\n",
    "idx = np.random.randint(val_dataset.__len__())\n",
    "inputs, outputs, points, variables = val_dataset.__getitem__(idx)\n",
    "print(points.min(), points.max())\n",
    "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
    "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
    "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b180aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:09:15.546944Z",
     "iopub.status.busy": "2025-04-07T23:09:15.546732Z",
     "iopub.status.idle": "2025-04-07T23:09:17.221035Z",
     "shell.execute_reply": "2025-04-07T23:09:17.220287Z"
    },
    "papermill": {
     "duration": 1.679793,
     "end_time": "2025-04-07T23:09:17.222664",
     "exception": false,
     "start_time": "2025-04-07T23:09:15.542871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-bf5598038ba2>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(\"/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\", map_location=torch.device(device))\n"
     ]
    }
   ],
   "source": [
    "weights = torch.load(\"/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\", map_location=torch.device(device))\n",
    "\n",
    "#vars_emb_weights = weights['vars_emb.weight']\n",
    "tok_emb_weights = weights['tok_emb.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e76d615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:09:17.230461Z",
     "iopub.status.busy": "2025-04-07T23:09:17.230246Z",
     "iopub.status.idle": "2025-04-08T00:50:52.947828Z",
     "shell.execute_reply": "2025-04-08T00:50:52.946724Z"
    },
    "papermill": {
     "duration": 6095.723023,
     "end_time": "2025-04-08T00:50:52.949351",
     "exception": false,
     "start_time": "2025-04-07T23:09:17.226328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   3%|▎         | 250/7794 [00:36<17:36,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 2.803213119506836, mse: 1.3523979187011719, ce: 1.4508150815963745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   6%|▋         | 500/7794 [01:12<17:30,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 2.1594676971435547, mse: 1.3281495571136475, ce: 0.831318199634552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  10%|▉         | 750/7794 [01:49<17:48,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 2.3239758014678955, mse: 1.3251063823699951, ce: 0.9988694190979004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  13%|█▎        | 1000/7794 [02:28<17:55,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 2.246151924133301, mse: 1.236047625541687, ce: 1.0101042985916138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  16%|█▌        | 1250/7794 [03:06<16:47,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 1.8546398878097534, mse: 1.1486310958862305, ce: 0.706008791923523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  19%|█▉        | 1500/7794 [03:45<16:21,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 1.851926565170288, mse: 1.0315630435943604, ce: 0.820363461971283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  22%|██▏       | 1750/7794 [04:24<15:35,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 1.7515376806259155, mse: 0.9856534004211426, ce: 0.765884280204773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  26%|██▌       | 2000/7794 [05:03<15:03,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 1.878409504890442, mse: 0.9916896820068359, ce: 0.886719822883606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  29%|██▉       | 2250/7794 [05:42<14:17,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 1.5370471477508545, mse: 0.872600793838501, ce: 0.6644462943077087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  32%|███▏      | 2500/7794 [06:20<13:40,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 1.1254217624664307, mse: 0.7271144390106201, ce: 0.39830729365348816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  35%|███▌      | 2750/7794 [06:59<13:02,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 1.3049204349517822, mse: 0.7360402345657349, ce: 0.5688801407814026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  38%|███▊      | 3000/7794 [07:38<12:17,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 1.1256673336029053, mse: 0.6306405067443848, ce: 0.4950268864631653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  42%|████▏     | 3250/7794 [08:17<11:43,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 1.2224040031433105, mse: 0.5853101015090942, ce: 0.6370939016342163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  45%|████▍     | 3500/7794 [08:55<11:05,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 1.3936150074005127, mse: 0.6489464044570923, ce: 0.7446686029434204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  48%|████▊     | 3750/7794 [09:34<10:28,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.7958780527114868, mse: 0.4690704047679901, ce: 0.3268076479434967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  51%|█████▏    | 4000/7794 [10:13<09:47,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 1.256026268005371, mse: 0.5406988263130188, ce: 0.7153274416923523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  55%|█████▍    | 4250/7794 [10:52<09:07,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 1.1390266418457031, mse: 0.5264507532119751, ce: 0.612575888633728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  58%|█████▊    | 4500/7794 [11:31<08:34,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.9479575157165527, mse: 0.4382385313510895, ce: 0.5097190141677856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  61%|██████    | 4750/7794 [12:09<07:51,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 1.1318581104278564, mse: 0.45336461067199707, ce: 0.6784934401512146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  64%|██████▍   | 5000/7794 [12:48<07:12,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 1.2643734216690063, mse: 0.47545960545539856, ce: 0.7889137864112854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  67%|██████▋   | 5250/7794 [13:27<06:34,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.8296408653259277, mse: 0.401164174079895, ce: 0.4284766614437103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  71%|███████   | 5500/7794 [14:06<05:54,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.9335244297981262, mse: 0.3839479088783264, ce: 0.5495765209197998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  74%|███████▍  | 5750/7794 [14:45<05:16,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.9255407452583313, mse: 0.3734057545661926, ce: 0.5521349906921387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  77%|███████▋  | 6000/7794 [15:23<04:37,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.7544429302215576, mse: 0.31095415353775024, ce: 0.443488746881485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  80%|████████  | 6250/7794 [16:02<03:58,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.9050230979919434, mse: 0.3247774839401245, ce: 0.5802456140518188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  83%|████████▎ | 6500/7794 [16:41<03:20,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.8645598292350769, mse: 0.3059195876121521, ce: 0.5586402416229248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  85%|████████▌ | 6642/7794 [17:03<02:58,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equation: C*x1**2+C*x1+C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  87%|████████▋ | 6750/7794 [17:20<02:42,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.8003764748573303, mse: 0.3235405683517456, ce: 0.4768359065055847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  90%|████████▉ | 7000/7794 [17:59<02:03,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.6529006958007812, mse: 0.28027912974357605, ce: 0.3726215660572052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  93%|█████████▎| 7250/7794 [18:37<01:24,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.8600479960441589, mse: 0.32982516288757324, ce: 0.5302228331565857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  96%|█████████▌| 7500/7794 [19:16<00:45,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.752748966217041, mse: 0.2932053208351135, ce: 0.4595436751842499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  99%|█████████▉| 7750/7794 [19:55<00:06,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.881679356098175, mse: 0.31184613704681396, ce: 0.5698332190513611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 7794/7794 [20:02<00:00,  6.48it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:01<00:00, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 1.3768 (MSE: 0.6623, CE: 0.7145)\n",
      "Val Total Loss: 0.7366 (MSE: 0.2480, CE: 0.4885)\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.7366\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/5:   3%|▎         | 250/7794 [00:38<19:30,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 0.7915871143341064, mse: 0.24429020285606384, ce: 0.547296941280365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:   6%|▋         | 500/7794 [01:17<18:49,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 0.8267897367477417, mse: 0.25402727723121643, ce: 0.5727624297142029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  10%|▉         | 750/7794 [01:56<18:11,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.7057859897613525, mse: 0.21454575657844543, ce: 0.4912402331829071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  13%|█▎        | 1000/7794 [02:35<17:43,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.6985313296318054, mse: 0.2410198599100113, ce: 0.4575114846229553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  16%|█▌        | 1250/7794 [03:14<16:54,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.6319164037704468, mse: 0.2041534185409546, ce: 0.4277629554271698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  19%|█▉        | 1500/7794 [03:53<16:24,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.6805254220962524, mse: 0.21353968977928162, ce: 0.46698570251464844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  22%|██▏       | 1750/7794 [04:32<15:42,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.7015860080718994, mse: 0.2219967395067215, ce: 0.4795892536640167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  26%|██▌       | 2000/7794 [05:11<15:02,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.7235637903213501, mse: 0.20749598741531372, ce: 0.5160678029060364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  29%|██▉       | 2250/7794 [05:49<14:31,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.6745002865791321, mse: 0.19819115102291107, ce: 0.4763091504573822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  32%|███▏      | 2500/7794 [06:28<13:48,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.7362369298934937, mse: 0.2343657910823822, ce: 0.5018711090087891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  35%|███▌      | 2750/7794 [07:07<13:02,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.6201194524765015, mse: 0.1941819190979004, ce: 0.4259375333786011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  38%|███▊      | 3000/7794 [07:46<12:30,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.9477267861366272, mse: 0.3179131746292114, ce: 0.6298136115074158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  42%|████▏     | 3250/7794 [08:25<11:49,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.670863926410675, mse: 0.20058073103427887, ce: 0.470283180475235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  45%|████▍     | 3500/7794 [09:04<11:14,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.5779291391372681, mse: 0.20096677541732788, ce: 0.3769623935222626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  48%|████▊     | 3750/7794 [09:43<10:28,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.8059256672859192, mse: 0.251481831073761, ce: 0.5544438362121582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  51%|█████▏    | 4000/7794 [10:22<09:51,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.7530562877655029, mse: 0.21827971935272217, ce: 0.5347765684127808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  55%|█████▍    | 4250/7794 [11:01<09:13,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.4806978106498718, mse: 0.14509722590446472, ce: 0.3356005847454071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  58%|█████▊    | 4500/7794 [11:40<08:33,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.76448655128479, mse: 0.2078508734703064, ce: 0.5566356778144836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  61%|██████    | 4750/7794 [12:19<07:56,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.8720264434814453, mse: 0.22907927632331848, ce: 0.6429471373558044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  64%|██████▍   | 5000/7794 [12:58<07:13,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.7333993911743164, mse: 0.2308233678340912, ce: 0.5025759935379028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  67%|██████▋   | 5250/7794 [13:37<06:36,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.7391877770423889, mse: 0.21513676643371582, ce: 0.5240510106086731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  71%|███████   | 5500/7794 [14:16<05:59,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.5564961433410645, mse: 0.20220834016799927, ce: 0.3542878031730652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  74%|███████▍  | 5750/7794 [14:55<05:17,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.682887077331543, mse: 0.22393199801445007, ce: 0.4589550495147705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  77%|███████▋  | 6000/7794 [15:34<04:39,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.6766022443771362, mse: 0.22873437404632568, ce: 0.44786790013313293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  80%|████████  | 6250/7794 [16:13<04:01,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.638864278793335, mse: 0.1991690844297409, ce: 0.43969517946243286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  83%|████████▎ | 6500/7794 [16:52<03:20,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.8758271932601929, mse: 0.2177312672138214, ce: 0.6580958962440491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  87%|████████▋ | 6750/7794 [17:31<02:43,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.6600271463394165, mse: 0.2205074429512024, ce: 0.4395196735858917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  90%|████████▉ | 7000/7794 [18:11<02:04,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.5175879001617432, mse: 0.18286627531051636, ce: 0.3347215950489044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  93%|█████████▎| 7250/7794 [18:50<01:25,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.7068728804588318, mse: 0.20909705758094788, ce: 0.4977758228778839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  96%|█████████▌| 7500/7794 [19:29<00:45,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.520897626876831, mse: 0.17970585823059082, ce: 0.34119173884391785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  99%|█████████▉| 7750/7794 [20:08<00:06,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.5957502722740173, mse: 0.1883668154478073, ce: 0.40738344192504883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 7794/7794 [20:15<00:00,  6.41it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:00<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.7019 (MSE: 0.2198, CE: 0.4820)\n",
      "Val Total Loss: 0.6334 (MSE: 0.1842, CE: 0.4492)\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.6334\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:   3%|▎         | 250/7794 [00:39<19:53,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 0.8637449741363525, mse: 0.2536913752555847, ce: 0.6100535988807678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:   6%|▋         | 500/7794 [01:18<19:04,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 0.4435518682003021, mse: 0.17338255047798157, ce: 0.27016931772232056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  10%|▉         | 750/7794 [01:57<18:22,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.8594338893890381, mse: 0.22772040963172913, ce: 0.6317134499549866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  13%|█▎        | 1000/7794 [02:37<17:47,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.8323633670806885, mse: 0.2255403995513916, ce: 0.6068229675292969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  16%|█▌        | 1250/7794 [03:16<17:03,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.7218965291976929, mse: 0.21148058772087097, ce: 0.5104159712791443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  19%|█▉        | 1500/7794 [03:55<16:33,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.52289879322052, mse: 0.1698913276195526, ce: 0.353007435798645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  22%|██▏       | 1750/7794 [04:34<15:45,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.5713565349578857, mse: 0.19812965393066406, ce: 0.3732268512248993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  26%|██▌       | 2000/7794 [05:13<14:58,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.42746174335479736, mse: 0.18111146986484528, ce: 0.2463502734899521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  29%|██▉       | 2250/7794 [05:52<14:26,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.4286259412765503, mse: 0.16185304522514343, ce: 0.26677289605140686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  32%|███▏      | 2500/7794 [06:31<13:47,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.8180109858512878, mse: 0.21771275997161865, ce: 0.6002982258796692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  35%|███▌      | 2750/7794 [07:10<13:05,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.6408965587615967, mse: 0.22486740350723267, ce: 0.4160291850566864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  38%|███▊      | 3000/7794 [07:49<12:29,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.5708451271057129, mse: 0.1749822050333023, ce: 0.3958629369735718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  42%|████▏     | 3250/7794 [08:28<11:52,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.6646755933761597, mse: 0.1948835253715515, ce: 0.46979206800460815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  45%|████▍     | 3500/7794 [09:08<11:10,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.7698661684989929, mse: 0.2098091095685959, ce: 0.5600570440292358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  48%|████▊     | 3750/7794 [09:47<10:31,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.6435375213623047, mse: 0.16964885592460632, ce: 0.47388866543769836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  51%|█████▏    | 4000/7794 [10:26<09:53,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.5603810548782349, mse: 0.17005428671836853, ce: 0.39032676815986633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  55%|█████▍    | 4250/7794 [11:05<09:14,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.6809452176094055, mse: 0.19509561359882355, ce: 0.48584961891174316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  58%|█████▊    | 4500/7794 [11:44<08:39,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.5694869756698608, mse: 0.1671200692653656, ce: 0.4023669362068176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  61%|██████    | 4750/7794 [12:23<07:54,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.7044150233268738, mse: 0.22161081433296204, ce: 0.48280420899391174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  64%|██████▍   | 5000/7794 [13:02<07:17,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.6527141332626343, mse: 0.19341617822647095, ce: 0.45929792523384094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  67%|██████▋   | 5250/7794 [13:41<06:36,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.6529728174209595, mse: 0.20125240087509155, ce: 0.4517204165458679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  71%|███████   | 5500/7794 [14:20<05:58,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.6606482267379761, mse: 0.1952683925628662, ce: 0.46537986397743225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  74%|███████▍  | 5750/7794 [14:59<05:19,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.5955583453178406, mse: 0.17683716118335724, ce: 0.41872119903564453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  77%|███████▋  | 6000/7794 [15:38<04:40,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.606549859046936, mse: 0.22242692112922668, ce: 0.38412296772003174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  80%|████████  | 6250/7794 [16:17<04:01,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.7703087329864502, mse: 0.2018507421016693, ce: 0.5684579610824585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  83%|████████▎ | 6500/7794 [16:57<03:21,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.6644207835197449, mse: 0.2406044900417328, ce: 0.4238162934780121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  87%|████████▋ | 6750/7794 [17:36<02:43,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.6458583474159241, mse: 0.2074071317911148, ce: 0.43845123052597046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  90%|████████▉ | 7000/7794 [18:15<02:03,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.5869241952896118, mse: 0.20041459798812866, ce: 0.38650956749916077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  93%|█████████▎| 7250/7794 [18:54<01:24,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.6880890130996704, mse: 0.20221000909805298, ce: 0.48587897419929504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  96%|█████████▌| 7500/7794 [19:33<00:45,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.580862283706665, mse: 0.1765686571598053, ce: 0.40429365634918213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  99%|█████████▉| 7750/7794 [20:12<00:06,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.6021738648414612, mse: 0.19123771786689758, ce: 0.4109361469745636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 7794/7794 [20:19<00:00,  6.39it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:00<00:00, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.6426 (MSE: 0.1952, CE: 0.4474)\n",
      "Val Total Loss: 0.6382 (MSE: 0.1839, CE: 0.4543)\n",
      "Learning Rate: 0.000100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/5:   3%|▎         | 250/7794 [00:39<19:52,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 0.7491709589958191, mse: 0.23252417147159576, ce: 0.5166468024253845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:   6%|▋         | 500/7794 [01:18<19:16,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 0.7193468809127808, mse: 0.21581682562828064, ce: 0.5035300850868225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  10%|▉         | 750/7794 [01:57<18:29,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.8206496834754944, mse: 0.2208017259836197, ce: 0.5998479723930359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  13%|█▎        | 1000/7794 [02:37<17:51,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.607125997543335, mse: 0.197175532579422, ce: 0.4099504351615906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  16%|█▌        | 1250/7794 [03:16<17:07,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.40149378776550293, mse: 0.15884269773960114, ce: 0.242651104927063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  19%|█▉        | 1500/7794 [03:55<16:29,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.5946148037910461, mse: 0.17494237422943115, ce: 0.419672429561615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  22%|██▏       | 1750/7794 [04:35<15:52,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.5892081260681152, mse: 0.18274009227752686, ce: 0.406468003988266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  26%|██▌       | 2000/7794 [05:14<15:04,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.6190183162689209, mse: 0.21263182163238525, ce: 0.40638652443885803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  29%|██▉       | 2250/7794 [05:53<14:27,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.5858324766159058, mse: 0.17000101506710052, ce: 0.41583144664764404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  32%|███▏      | 2500/7794 [06:32<13:49,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.49271130561828613, mse: 0.15603937208652496, ce: 0.33667194843292236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  35%|███▌      | 2750/7794 [07:11<13:06,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.4472140073776245, mse: 0.16588732600212097, ce: 0.28132668137550354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  38%|███▊      | 3000/7794 [07:50<12:30,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.6237618327140808, mse: 0.18122366070747375, ce: 0.44253817200660706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  42%|████▏     | 3250/7794 [08:29<11:52,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.5501350164413452, mse: 0.15647846460342407, ce: 0.39365655183792114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  45%|████▍     | 3500/7794 [09:08<11:11,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.5244737863540649, mse: 0.13274234533309937, ce: 0.3917314410209656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  48%|████▊     | 3750/7794 [09:47<10:35,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.5418643951416016, mse: 0.1630270630121231, ce: 0.37883734703063965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  51%|█████▏    | 4000/7794 [10:26<09:56,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.6099255084991455, mse: 0.16975447535514832, ce: 0.4401710331439972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  55%|█████▍    | 4250/7794 [11:05<09:18,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.4915138781070709, mse: 0.12525048851966858, ce: 0.36626338958740234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  58%|█████▊    | 4500/7794 [11:45<08:37,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.5525071620941162, mse: 0.1596391499042511, ce: 0.3928679823875427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  61%|██████    | 4750/7794 [12:24<07:59,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.42849376797676086, mse: 0.1532277762889862, ce: 0.27526599168777466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  64%|██████▍   | 5000/7794 [13:03<07:15,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.6641747951507568, mse: 0.19052079319953918, ce: 0.47365403175354004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  67%|██████▋   | 5250/7794 [13:42<06:35,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.5786541700363159, mse: 0.15516534447669983, ce: 0.4234888255596161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  71%|███████   | 5500/7794 [14:21<05:58,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.7393583059310913, mse: 0.17175328731536865, ce: 0.5676050186157227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  74%|███████▍  | 5750/7794 [15:00<05:20,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.644080400466919, mse: 0.1747177243232727, ce: 0.46936267614364624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  77%|███████▋  | 6000/7794 [15:39<04:44,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.7704215049743652, mse: 0.19552025198936462, ce: 0.574901282787323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  80%|████████  | 6250/7794 [16:19<04:03,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.5285043120384216, mse: 0.1468035727739334, ce: 0.3817007541656494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  83%|████████▎ | 6500/7794 [16:58<03:23,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.6759126782417297, mse: 0.16318632662296295, ce: 0.512726366519928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  87%|████████▋ | 6750/7794 [17:38<02:44,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.4960393011569977, mse: 0.1361275315284729, ce: 0.3599117696285248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  90%|████████▉ | 7000/7794 [18:17<02:05,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.5229132175445557, mse: 0.15684863924980164, ce: 0.3660646080970764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  93%|█████████▎| 7250/7794 [18:56<01:25,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.623106062412262, mse: 0.1626323163509369, ce: 0.4604737460613251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  96%|█████████▌| 7500/7794 [19:36<00:46,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.5820409059524536, mse: 0.15329857170581818, ce: 0.42874231934547424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  99%|█████████▉| 7750/7794 [20:15<00:06,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.39981788396835327, mse: 0.13094404339790344, ce: 0.26887384057044983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 7794/7794 [20:22<00:00,  6.38it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:01<00:00, 15.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.5945 (MSE: 0.1698, CE: 0.4247)\n",
      "Val Total Loss: 0.4794 (MSE: 0.1299, CE: 0.3496)\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.4794\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:   3%|▎         | 250/7794 [00:39<19:43,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 0.7291012406349182, mse: 0.17252248525619507, ce: 0.5565787553787231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:   6%|▋         | 500/7794 [01:18<19:03,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 0.6222289204597473, mse: 0.17542624473571777, ce: 0.44680267572402954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  10%|▉         | 750/7794 [01:57<18:38,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.4747333824634552, mse: 0.1394093632698059, ce: 0.3353240191936493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  13%|█▎        | 1000/7794 [02:37<17:49,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.5932381749153137, mse: 0.17300330102443695, ce: 0.4202348589897156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  16%|█▌        | 1250/7794 [03:16<17:21,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.4903102219104767, mse: 0.13319575786590576, ce: 0.3571144640445709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  19%|█▉        | 1500/7794 [03:56<16:31,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.6078946590423584, mse: 0.1678474247455597, ce: 0.4400472044944763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  22%|██▏       | 1750/7794 [04:35<16:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.49276527762413025, mse: 0.1398104727268219, ce: 0.35295480489730835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  26%|██▌       | 2000/7794 [05:15<15:16,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.4763675928115845, mse: 0.1537758708000183, ce: 0.32259172201156616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  29%|██▉       | 2250/7794 [05:54<14:37,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.4306081533432007, mse: 0.14019152522087097, ce: 0.2904166281223297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  32%|███▏      | 2500/7794 [06:34<13:54,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.5101659297943115, mse: 0.13015982508659363, ce: 0.3800061047077179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  35%|███▌      | 2750/7794 [07:13<13:11,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.5315396785736084, mse: 0.13994938135147095, ce: 0.39159026741981506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  38%|███▊      | 3000/7794 [07:53<12:32,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.6057891845703125, mse: 0.15494495630264282, ce: 0.4508441984653473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  42%|████▏     | 3250/7794 [08:32<11:49,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.7285109758377075, mse: 0.1814500391483307, ce: 0.5470609068870544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  45%|████▍     | 3500/7794 [09:11<11:11,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.5719096660614014, mse: 0.1414783000946045, ce: 0.4304313361644745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  48%|████▊     | 3750/7794 [09:50<10:33,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.4109147787094116, mse: 0.11870883405208588, ce: 0.29220595955848694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  51%|█████▏    | 4000/7794 [10:29<09:54,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.45694321393966675, mse: 0.12049715965986252, ce: 0.33644604682922363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  55%|█████▍    | 4250/7794 [11:08<09:13,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.5886490941047668, mse: 0.15834176540374756, ce: 0.4303073287010193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  58%|█████▊    | 4500/7794 [11:48<08:38,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.7140775918960571, mse: 0.17279404401779175, ce: 0.5412835478782654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  61%|██████    | 4750/7794 [12:27<07:55,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.45568132400512695, mse: 0.11866095662117004, ce: 0.3370203673839569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  64%|██████▍   | 5000/7794 [13:06<07:18,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.7432637214660645, mse: 0.17397823929786682, ce: 0.56928551197052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  67%|██████▋   | 5250/7794 [13:45<06:38,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.5356984734535217, mse: 0.12627416849136353, ce: 0.4094243049621582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  71%|███████   | 5500/7794 [14:24<05:59,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.5065790414810181, mse: 0.14296436309814453, ce: 0.3636147081851959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  74%|███████▍  | 5750/7794 [15:03<05:21,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.5288441181182861, mse: 0.1274733692407608, ce: 0.4013707637786865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  77%|███████▋  | 6000/7794 [15:42<04:40,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.3331661820411682, mse: 0.10572810471057892, ce: 0.2274380773305893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  80%|████████  | 6250/7794 [16:21<04:02,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.6216846704483032, mse: 0.1616356372833252, ce: 0.4600490629673004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  83%|████████▎ | 6500/7794 [17:01<03:21,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.5728191137313843, mse: 0.12852302193641663, ce: 0.44429612159729004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  87%|████████▋ | 6750/7794 [17:40<02:43,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.6799358129501343, mse: 0.14830438792705536, ce: 0.5316314101219177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  90%|████████▉ | 7000/7794 [18:19<02:05,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.49639463424682617, mse: 0.1379700005054474, ce: 0.3584246337413788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  93%|█████████▎| 7250/7794 [18:59<01:25,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.6831130385398865, mse: 0.16643311083316803, ce: 0.5166799426078796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  96%|█████████▌| 7500/7794 [19:38<00:46,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.4372456669807434, mse: 0.12337194383144379, ce: 0.3138737082481384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  99%|█████████▉| 7750/7794 [20:18<00:06,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.34312111139297485, mse: 0.11018188297748566, ce: 0.2329392433166504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 7794/7794 [20:25<00:00,  6.36it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:00<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.5494 (MSE: 0.1427, CE: 0.4067)\n",
      "Val Total Loss: 0.4720 (MSE: 0.1102, CE: 0.3618)\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.4720\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pconfig = PointNetConfig(\n",
    "    embeddingSize=n_embd,\n",
    "    numberofPoints=numPoints,\n",
    "    numberofVars=numVars,\n",
    "    numberofYs=numYs,\n",
    ")\n",
    "\n",
    "model = SymbolicGaussianDiffusion(\n",
    "    tnet_config=pconfig,  \n",
    "    vocab_size=train_dataset.vocab_size,\n",
    "    max_seq_len=blockSize,\n",
    "    padding_idx=train_dataset.paddingID,\n",
    "    max_num_vars=9,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    n_embd=n_embd,\n",
    "    timesteps=timesteps,\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    ce_weight=1.0  \n",
    ")\n",
    "\n",
    "train_single_gpu(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    num_epochs=num_epochs,\n",
    "    save_every=2,\n",
    "    batch_size=batch_size,\n",
    "    timesteps=timesteps,\n",
    "    learning_rate=learning_rate\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6977314,
     "sourceId": 11178716,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 282263,
     "modelInstanceId": 261112,
     "sourceId": 306062,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 290784,
     "modelInstanceId": 269794,
     "sourceId": 319741,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 290853,
     "modelInstanceId": 269860,
     "sourceId": 319828,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6130.695417,
   "end_time": "2025-04-08T00:50:58.291072",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T23:08:47.595655",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
