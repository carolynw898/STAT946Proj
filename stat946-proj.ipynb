{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902080b1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:22.460709Z",
     "iopub.status.busy": "2025-04-06T12:34:22.460360Z",
     "iopub.status.idle": "2025-04-06T12:34:23.653299Z",
     "shell.execute_reply": "2025-04-06T12:34:23.652530Z"
    },
    "papermill": {
     "duration": 1.198503,
     "end_time": "2025-04-06T12:34:23.654660",
     "exception": false,
     "start_time": "2025-04-06T12:34:22.456157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/1-var-dataset/1_var_test.json\n",
      "/kaggle/input/1-var-dataset/1_var_val.json\n",
      "/kaggle/input/1-var-dataset/1_var_train.json\n",
      "/kaggle/input/symbolic_diffusion_initial/pytorch/default/1/symbolic_diffusion_model.pth\n",
      "/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\n",
      "/kaggle/input/xye_9var/pytorch/default/1/XYE_9Var.pt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571b6add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:23.661721Z",
     "iopub.status.busy": "2025-04-06T12:34:23.661368Z",
     "iopub.status.idle": "2025-04-06T12:34:28.505164Z",
     "shell.execute_reply": "2025-04-06T12:34:28.504504Z"
    },
    "papermill": {
     "duration": 4.84885,
     "end_time": "2025-04-06T12:34:28.506643",
     "exception": false,
     "start_time": "2025-04-06T12:34:23.657793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import glob\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "from math import exp, sin, cos\n",
    "\n",
    "def generateDataStrEq(eq, n_points=2, n_vars=3,\n",
    "                      decimals=4, supportPoints=None, \n",
    "                      min_x=0, max_x=3):\n",
    "    X = []\n",
    "    Y= []\n",
    "    # TODO: Need to make this faster\n",
    "    for p in range(n_points):\n",
    "        if supportPoints is None:\n",
    "            if type(min_x) == list:\n",
    "                x = []\n",
    "                for _ in range(n_vars):\n",
    "                    idx = np.random.randint(len(min_x))\n",
    "                    x += list(np.round(np.random.uniform(min_x[idx], max_x[idx], 1), decimals))\n",
    "            else:\n",
    "                x = list(np.round(np.random.uniform(min_x, max_x, n_vars), decimals))\n",
    "            assert len(x)!=0, \"For some reason, we didn't generate the points correctly!\"\n",
    "        else:\n",
    "            x = supportPoints[p]\n",
    "\n",
    "        tmpEq = eq + ''\n",
    "        for nVID in range(n_vars):\n",
    "            tmpEq = tmpEq.replace('x{}'.format(nVID+1), str(x[nVID]))\n",
    "        y = float(np.round(eval(tmpEq), decimals))\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# def processDataFiles(files):\n",
    "#     text = \"\"\n",
    "#     for f in tqdm(files):\n",
    "#         with open(f, 'r') as h: \n",
    "#             lines = h.read() # don't worry we won't run out of file handles\n",
    "#             if lines[-1]==-1:\n",
    "#                 lines = lines[:-1]\n",
    "#             #text += lines #json.loads(line)    \n",
    "#             text = ''.join([lines,text])    \n",
    "#     return text\n",
    "\n",
    "def processDataFiles(files):\n",
    "    text = \"\"\n",
    "    for f in files:\n",
    "        with open(f, 'r') as h: \n",
    "            lines = h.read() # don't worry we won't run out of file handles\n",
    "            if lines[-1]==-1:\n",
    "                lines = lines[:-1]\n",
    "            #text += lines #json.loads(line)    \n",
    "            text = ''.join([lines,text])    \n",
    "    return text\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, block_size, chars, \n",
    "                 numVars, numYs, numPoints, target='EQ', \n",
    "                 addVars=False, const_range=[-0.4, 0.4],\n",
    "                 xRange=[-3.0,3.0], decimals=4, augment=False):\n",
    "\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d examples, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "        self.numVars = numVars\n",
    "        self.numYs = numYs\n",
    "        self.numPoints = numPoints\n",
    "        \n",
    "        # padding token\n",
    "        self.paddingToken = '_'\n",
    "        self.paddingID = self.stoi[self.paddingToken]\n",
    "        self.stoi[self.paddingToken] = self.paddingID\n",
    "        self.itos[self.paddingID] = self.paddingToken\n",
    "        self.threshold = [-1000,1000]\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data # it should be a list of examples\n",
    "        self.target = target\n",
    "        self.addVars = addVars\n",
    "\n",
    "        self.const_range = const_range\n",
    "        self.xRange = xRange\n",
    "        self.decimals = decimals\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab an example from the data\n",
    "        chunk = self.data[idx] # sequence of tokens including x, y, eq, etc.\n",
    "        \n",
    "        try:\n",
    "            chunk = json.loads(chunk) # convert the sequence tokens to a dictionary\n",
    "        except Exception as e:\n",
    "            print(\"Couldn't convert to json: {} \\n error is: {}\".format(chunk, e))\n",
    "            # try the previous example\n",
    "            idx = idx - 1 \n",
    "            idx = idx if idx>=0 else 0\n",
    "            chunk = self.data[idx]\n",
    "            chunk = json.loads(chunk) # convert the sequence tokens to a dictionary\n",
    "            \n",
    "        # find the number of variables in the equation\n",
    "        printInfoCondition = random.random() < 0.0000001\n",
    "        eq = chunk[self.target]\n",
    "        if printInfoCondition:\n",
    "            print(f'\\nEquation: {eq}')\n",
    "        vars = re.finditer('x[\\d]+',eq) \n",
    "        numVars = 0\n",
    "        for v in vars:\n",
    "            v = v.group(0).strip('x')\n",
    "            v = eval(v)\n",
    "            v = int(v)\n",
    "            if v > numVars:\n",
    "                numVars = v\n",
    "\n",
    "        if self.target == 'Skeleton' and self.augment:\n",
    "            threshold = 5000\n",
    "            # randomly generate the constants\n",
    "            cleanEqn = ''\n",
    "            for chr in eq:\n",
    "                if chr == 'C':\n",
    "                    # genereate a new random number\n",
    "                    chr = '{}'.format(np.random.uniform(self.const_range[0], self.const_range[1]))\n",
    "                cleanEqn += chr\n",
    "\n",
    "            # update the points\n",
    "            nPoints = np.random.randint(*self.numPoints) #if supportPoints is None else len(supportPoints)\n",
    "            try:\n",
    "                if printInfoCondition:\n",
    "                    print('Org:',chunk['X'], chunk['Y'])\n",
    "\n",
    "                X, y = generateDataStrEq(cleanEqn, n_points=nPoints, n_vars=self.numVars,\n",
    "                                         decimals=self.decimals, min_x=self.xRange[0], \n",
    "                                         max_x=self.xRange[1])\n",
    "\n",
    "                # replace out of threshold with maximum numbers\n",
    "                y = [e if abs(e)<threshold else np.sign(e) * threshold for e in y]\n",
    "\n",
    "                # check if there is nan/inf/very large numbers in the y\n",
    "                conditions = (np.isnan(y).any() or np.isinf(y).any()) or len(y) == 0 or (abs(min(y)) > threshold or abs(max(y)) > threshold)\n",
    "                if not conditions:\n",
    "                    chunk['X'], chunk['Y'] = X, y\n",
    "\n",
    "                if printInfoCondition:\n",
    "                    print('Evd:',chunk['X'], chunk['Y'])\n",
    "            except Exception as e: \n",
    "                # for different reason this might happend including but not limited to division by zero\n",
    "                print(\"\".join([\n",
    "                    f\"We just used the original equation and support points because of {e}. \",\n",
    "                    f\"The equation is {eq}, and we update the equation to {cleanEqn}\",\n",
    "                ]))\n",
    " \n",
    "        # encode every character in the equation to an integer\n",
    "        # < is SOS, > is EOS\n",
    "        if self.addVars:\n",
    "            dix = [self.stoi[s] for s in '<'+str(numVars)+':'+eq+'>']\n",
    "        else:\n",
    "            dix = [self.stoi[s] for s in '<'+eq+'>']\n",
    "        inputs = dix[:-1]\n",
    "        outputs = dix[1:]\n",
    "        \n",
    "        # add the padding to the equations\n",
    "        paddingSize = max(self.block_size-len(inputs),0)\n",
    "        paddingList = [self.paddingID]*paddingSize\n",
    "        inputs += paddingList\n",
    "        outputs += paddingList\n",
    "        \n",
    "        # make sure it is not more than what should be\n",
    "        inputs = inputs[:self.block_size]\n",
    "        outputs = outputs[:self.block_size]\n",
    "        \n",
    "        # extract points from the input sequence\n",
    "        # maxX = max(chunk['X'])\n",
    "        # maxY = max(chunk['Y'])\n",
    "        # minX = min(chunk['X'])\n",
    "        # minY = min(chunk['Y'])\n",
    "        points = torch.zeros(self.numVars+self.numYs, self.numPoints-1)\n",
    "        for idx, xy in enumerate(zip(chunk['X'], chunk['Y'])):\n",
    "\n",
    "            if not isinstance(xy[0], list) or not isinstance(xy[1], (list, float, np.float64)):\n",
    "                print(f\"Unexpected types: {type(xy[0])}, {type(xy[1])}\")\n",
    "                continue  # Skip if types are incorrect\n",
    "\n",
    "            # don't let to exceed the maximum number of points\n",
    "            if idx >= self.numPoints-1:\n",
    "                break\n",
    "            \n",
    "            x = xy[0]\n",
    "            #x = [(e-minX[eID])/(maxX[eID]-minX[eID]+eps) for eID, e in enumerate(x)] # normalize x\n",
    "            x = x + [0]*(max(self.numVars-len(x),0)) # padding\n",
    "\n",
    "            y = [xy[1]] if type(xy[1])==float or type(xy[1])==np.float64 else xy[1]\n",
    "\n",
    "            #y = [(e-minY)/(maxY-minY+eps) for e in y]\n",
    "            y = y + [0]*(max(self.numYs-len(y),0)) # padding\n",
    "            p = x+y # because it is only one point \n",
    "            p = torch.tensor(p)\n",
    "            #replace nan and inf\n",
    "            p = torch.nan_to_num(p, nan=self.threshold[1], \n",
    "                                 posinf=self.threshold[1], \n",
    "                                 neginf=self.threshold[0])\n",
    "            # p[p>self.threshold[1]] = self.threshold[1] # clip the upper bound\n",
    "            # p[p<self.threshold[0]] = self.threshold[0] # clip the lower bound\n",
    "            points[:,idx] = p\n",
    "\n",
    "        # Normalize points between zero and one # DxN\n",
    "        # minP = points.min(dim=1, keepdim=True)[0]\n",
    "        # maxP = points.max(dim=1, keepdim=True)[0]\n",
    "        # points -= minP\n",
    "        # points /= (maxP-minP+eps)\n",
    "        # if printInfoCondition:\n",
    "        #     print(f'Points: {points}')\n",
    "\n",
    "        # points -= points.mean()\n",
    "        # points /= points.std()\n",
    "        points = torch.nan_to_num(points, nan=self.threshold[1],\n",
    "                                 posinf=self.threshold[1],\n",
    "                                 neginf=self.threshold[0])\n",
    "\n",
    "        # if printInfoCondition:\n",
    "        #     print(f'Points: {points}')\n",
    "        #points += torch.normal(0, 0.05, size=points.shape) # add a guassian noise\n",
    "        \n",
    "        inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        outputs = torch.tensor(outputs, dtype=torch.long)\n",
    "        numVars = torch.tensor(numVars, dtype=torch.long)\n",
    "        return inputs, outputs, points, numVars\n",
    "\n",
    "# Relative Mean Square Error\n",
    "def relativeErr(y, yHat, info=False, eps=1e-5):\n",
    "    yHat = np.reshape(yHat, [1, -1])[0]\n",
    "    y = np.reshape(y, [1, -1])[0]\n",
    "    if len(y) > 0 and len(y)==len(yHat):\n",
    "        err = ( (yHat - y) )** 2 / np.linalg.norm(y+eps)\n",
    "        if info:\n",
    "            for _ in range(5):\n",
    "                i = np.random.randint(len(y))\n",
    "                print('yPR,yTrue:{},{}, Err:{}'.format(yHat[i],y[i],err[i]))\n",
    "    else:\n",
    "        err = 100\n",
    "\n",
    "    return np.mean(err)\n",
    "\n",
    "def lossFunc(constants, eq, X, Y, eps=1e-5):\n",
    "    err = 0\n",
    "    eq = eq.replace('C','{}').format(*constants)\n",
    "\n",
    "    for x,y in zip(X,Y):\n",
    "        eqTemp = eq + ''\n",
    "        if type(x) == np.float32:\n",
    "            x = [x]\n",
    "        for i,e in enumerate(x):\n",
    "            # make sure e is not a tensor\n",
    "            if type(e) == torch.Tensor:\n",
    "                e = e.item()\n",
    "            eqTemp = eqTemp.replace('x{}'.format(i+1), str(e))\n",
    "        try:\n",
    "            yHat = eval(eqTemp)\n",
    "        except:\n",
    "            print('Exception has been occured! EQ: {}, OR: {}'.format(eqTemp, eq))\n",
    "            continue\n",
    "            yHat = 100\n",
    "        try:\n",
    "            # handle overflow\n",
    "            err += relativeErr(y, yHat) #(y-yHat)**2\n",
    "        except:\n",
    "            print('Exception has been occured! EQ: {}, OR: {}, y:{}-yHat:{}'.format(eqTemp, eq, y, yHat))\n",
    "            continue\n",
    "            err += 10\n",
    "        \n",
    "    err /= len(Y)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d168eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:28.513836Z",
     "iopub.status.busy": "2025-04-06T12:34:28.513502Z",
     "iopub.status.idle": "2025-04-06T12:34:28.540613Z",
     "shell.execute_reply": "2025-04-06T12:34:28.539979Z"
    },
    "papermill": {
     "duration": 0.032089,
     "end_time": "2025-04-06T12:34:28.541882",
     "exception": false,
     "start_time": "2025-04-06T12:34:28.509793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# from SymbolicGPT: https://github.com/mojivalipour/symbolicgpt/blob/master/models.py\n",
    "class PointNetConfig:\n",
    "    \"\"\"base PointNet config\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddingSize,\n",
    "        numberofPoints,\n",
    "        numberofVars,\n",
    "        numberofYs,\n",
    "        method=\"GPT\",\n",
    "        varibleEmbedding=\"NOT_VAR\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.embeddingSize = embeddingSize\n",
    "        self.numberofPoints = numberofPoints  # number of points\n",
    "        self.numberofVars = numberofVars  # input dimension (Xs)\n",
    "        self.numberofYs = numberofYs  # output dimension (Ys)\n",
    "        self.method = method\n",
    "        self.varibleEmbedding = varibleEmbedding\n",
    "\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    \"\"\"\n",
    "    The PointNet structure in the orginal PointNet paper:\n",
    "    PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation by Qi et. al. 2017\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "        self.num_units = config.embeddingSize\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            config.numberofVars + config.numberofYs, self.num_units, 1\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(self.num_units, 2 * self.num_units, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * self.num_units, 4 * self.num_units, 1)\n",
    "        self.fc1 = nn.Linear(4 * self.num_units, 2 * self.num_units)\n",
    "        self.fc2 = nn.Linear(2 * self.num_units, self.num_units)\n",
    "\n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "        self.input_batch_norm = nn.BatchNorm1d(config.numberofVars + config.numberofYs)\n",
    "        # self.input_layer_norm = nn.LayerNorm(config.numberofPoints)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.num_units)\n",
    "        self.bn2 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn3 = nn.BatchNorm1d(4 * self.num_units)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn5 = nn.BatchNorm1d(self.num_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [batch, #features, #points]\n",
    "        :return:\n",
    "            logit: [batch, embedding_size]\n",
    "        \"\"\"\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        x, _ = torch.max(x, dim=2)  # global max pooling\n",
    "        assert x.size(1) == 4 * self.num_units\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        # x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class NoisePredictionTransformer(nn.Module):\n",
    "    \"\"\"Predicts continuous noise in the embedding space for diffusion-based symbolic regression.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        max_seq_len: int,\n",
    "        padding_idx: int = 0,\n",
    "        n_layer: int = 6,\n",
    "        n_head: int = 8,\n",
    "        n_embd: int = 512,\n",
    "        max_timesteps: int = 1000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # self.tok_emb = nn.Embedding(\n",
    "        #     vocab_size, n_embd, padding_idx=torch.tensor(padding_idx, dtype=torch.long)\n",
    "        # )\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, max_seq_len, n_embd))\n",
    "        self.time_emb = nn.Embedding(max_timesteps, n_embd)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=n_embd,\n",
    "            nhead=n_head,\n",
    "            dim_feedforward=n_embd * 4,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layer)\n",
    "        self.cross_attention = nn.MultiheadAttention(n_embd, n_head, batch_first=True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_t: torch.Tensor,\n",
    "        t: torch.Tensor,\n",
    "        condition: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Predicts noise from noisy token indices, timestep, and condition.\n",
    "\n",
    "        Args:\n",
    "            x_t: [B, L] - Noisy expression at time t (token indices)\n",
    "            t: [B] - Timestep\n",
    "            condition: [B, n_embd] - Combined T-Net and variable embeddings\n",
    "\n",
    "        Returns:\n",
    "            noise_pred: [B, L, n_embd] - Predicted noise in embedding space\n",
    "        \"\"\"\n",
    "        # print(x_t.shape)\n",
    "        _, L, _ = x_t.shape\n",
    "\n",
    "        # print(f\"x_t min: {x_t.min().item()}, max: {x_t.max().item()}\")\n",
    "        # print(self.tok_emb.weight.shape[0])  # Number of embeddings\n",
    "\n",
    "        # tok_emb = self.tok_emb(x_t.long())\n",
    "        pos_emb = self.pos_emb[:, :L, :]\n",
    "        time_emb = self.time_emb(t).unsqueeze(1)\n",
    "        x = x_t + pos_emb + time_emb \n",
    "\n",
    "        condition = condition.unsqueeze(1)  \n",
    "        attn_output, _ = self.cross_attention(x, condition, condition)  \n",
    "        x = x + attn_output  # Residual connection\n",
    "\n",
    "        noise_pred = self.encoder(x)\n",
    "        return noise_pred\n",
    "\n",
    "\n",
    "class SymbolicDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pconfig,\n",
    "        vocab_size: int,\n",
    "        max_seq_len: int,\n",
    "        padding_idx: int = 0,\n",
    "        max_num_vars: int = 9,\n",
    "        n_layer: int = 4,\n",
    "        n_head: int = 4,\n",
    "        n_embd: int = 512,\n",
    "        timesteps: int = 1000,\n",
    "        beta_start: float = 0.0001,\n",
    "        beta_end: float = 0.02,\n",
    "        tok_emb_weights: torch.Tensor = None,\n",
    "        vars_emb_weights: torch.Tensor = None,\n",
    "        train_decoder: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.timesteps = timesteps\n",
    "        self.n_embd = n_embd\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.tok_emb_weights = tok_emb_weights\n",
    "        self.vars_emb_weights = vars_emb_weights\n",
    "\n",
    "        # Initialize embedding layers\n",
    "        self.tok_emb = nn.Embedding(vocab_size, n_embd, padding_idx=padding_idx)\n",
    "        self.vars_emb = nn.Embedding(max_num_vars, n_embd)\n",
    "\n",
    "        # Load and freeze (requires_grad = False ensures they won't be updated) weights if provided\n",
    "        if tok_emb_weights is not None:\n",
    "            self.tok_emb.weight = nn.Parameter(tok_emb_weights, requires_grad=False)\n",
    "\n",
    "        if vars_emb_weights is not None:\n",
    "            self.vars_emb.weight = nn.Parameter(vars_emb_weights, requires_grad=False)\n",
    "\n",
    "        self.tnet = tNet(pconfig)\n",
    "        self.transformer = NoisePredictionTransformer(\n",
    "            vocab_size,\n",
    "            max_seq_len,\n",
    "            padding_idx,\n",
    "            n_layer=n_layer,\n",
    "            n_head=n_head,\n",
    "            n_embd=n_embd,\n",
    "            max_timesteps=timesteps,\n",
    "        )\n",
    "\n",
    "        self.train_decoder = train_decoder\n",
    "        if train_decoder:\n",
    "            self.decoder = nn.Linear(n_embd, vocab_size)\n",
    "        else:\n",
    "            self.decoder = self.round\n",
    "\n",
    "        self.register_buffer(\"beta\", torch.linspace(beta_start, beta_end, timesteps))\n",
    "        self.register_buffer(\"alpha\", 1.0 - self.beta)\n",
    "        self.register_buffer(\"alpha_bar\", torch.cumprod(self.alpha, dim=0))\n",
    "\n",
    "    def xtoi(self, xt):\n",
    "        B, L, _ = xt.shape\n",
    "        emb_table = self.tok_emb.weight  # [vocab_size, n_embd]\n",
    "\n",
    "        xt_flat = xt.view(B * L, -1)  # [B*L, n_embd]\n",
    "        # Compute squared L2 distance: ||xt - emb_table||^2\n",
    "        distances = torch.cdist(xt_flat, emb_table, p=2).pow(2)  # [B*L, vocab_size]\n",
    "        nearest_indices = torch.argmin(distances, dim=1).view(B, L)  # [B, L]\n",
    "\n",
    "        return nearest_indices\n",
    "\n",
    "    def round(self, xt):\n",
    "        emb_table = self.tok_emb.weight\n",
    "        idx = self.xtoi(xt)\n",
    "        return emb_table[idx]\n",
    "\n",
    "    def q_sample(\n",
    "        self,\n",
    "        x0: torch.Tensor,\n",
    "        t: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Adds Gaussian noise to the input embeddings at time t.\n",
    "\n",
    "        Args:\n",
    "            x0: [B, L, n_embd] - Original expression embeddings\n",
    "            t: [B] - Timestep\n",
    "\n",
    "        Returns:\n",
    "            xt: [B, L, n_embd] - Noisy embeddings at time t\n",
    "            noise: [B, L, n_embd] - Noise added to the original embeddings\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x0, dtype=torch.float)\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t]).view(-1, 1, 1)\n",
    "        sqrt_subone_alpha_bar = torch.sqrt(1 - self.alpha_bar[t]).view(-1, 1, 1)\n",
    "        xt = sqrt_alpha_bar * x0 + sqrt_subone_alpha_bar * noise\n",
    "        return xt, noise\n",
    "\n",
    "    def p_sample(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        t: int,\n",
    "        noise_pred: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Denoises the noisy embeddings at time t.\n",
    "\n",
    "        Args:\n",
    "            x: [B, L, n_embd] - Noisy embeddings at time t\n",
    "            t: int - Current timestep (scalar)\n",
    "            condition: [B, n_embd] - Combined T-Net and variable embeddings\n",
    "            device: str - Device to use (e.g., \"cuda\")\n",
    "\n",
    "        Returns:\n",
    "            x: [B, L, n_embd] - Denoised embeddings\n",
    "        \"\"\"\n",
    "        B = x.shape[0]\n",
    "        beta_t = self.beta[t].view(-1, 1, 1)\n",
    "        alpha_t = self.alpha[t].view(-1, 1, 1)\n",
    "        alpha_bar_t = self.alpha_bar[t].view(-1, 1, 1)\n",
    "        mean = (1 / torch.sqrt(alpha_t)) * (\n",
    "            x - (beta_t / torch.sqrt(1 - alpha_bar_t)) * noise_pred\n",
    "        )\n",
    "        return mean\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        points: torch.Tensor,\n",
    "        tokens: torch.Tensor,\n",
    "        variables: torch.Tensor,\n",
    "        t: torch.Tensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Training forward pass to predict noise added to embeddings.\n",
    "\n",
    "        Args:\n",
    "            points: [B, 2, 250] - Dataset points for conditioning\n",
    "            tokens: [B, L] - Ground truth expression (token indices)\n",
    "            variables: [B] - Number of variables per sample\n",
    "            t: [B] - Timestep\n",
    "\n",
    "        Returns:\n",
    "            y_pred: [B, L] - Generated expression (token indices)\n",
    "            noise_pred: [B, L, n_embd] - Predicted noise\n",
    "            noise: [B, L, n_embd] - Actual noise added\n",
    "        \"\"\"\n",
    "        B = tokens.shape[0]\n",
    "\n",
    "        condition = self.tnet(points)\n",
    "        vars_emb = self.vars_emb(variables)\n",
    "        condition = condition + vars_emb\n",
    "\n",
    "        token_emb = self.tok_emb(tokens)\n",
    "        xt, noise = self.q_sample(token_emb, t)\n",
    "        noise_pred = self.transformer(xt, t, condition)\n",
    "        y_pred = self.p_sample(xt, t, noise_pred)\n",
    "        if self.train_decoder:\n",
    "            y_pred = self.decoder(y_pred)\n",
    "        return y_pred, noise_pred, noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self,\n",
    "        points: torch.Tensor,\n",
    "        variables: torch.Tensor,\n",
    "        device: str = \"cuda\",\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Generates a sample by denoising from random noise.\n",
    "\n",
    "        Args:\n",
    "            points: [B, 2, 250] - Dataset points for conditioning\n",
    "            variables: [B] - Number of variables per sample\n",
    "            device: str - Device to use (e.g., \"cuda\")\n",
    "\n",
    "        Returns:\n",
    "            xt: [B, L] - Generated expression (token indices)\n",
    "        \"\"\"\n",
    "        condition = self.tnet(points) + self.vars_emb(variables)  # [B, n_embd]\n",
    "        B = condition.shape[0]\n",
    "\n",
    "        xt_emb = torch.randn(B, self.max_seq_len, self.n_embd, device=device)\n",
    "        t_tensor = torch.zeros(B, dtype=torch.long, device=device)  # [B]\n",
    "        for t in range(self.timesteps - 1, -1, -1):\n",
    "            t_tensor.fill_(t)  # Update in-place: [B] all set to t\n",
    "            noise_pred = self.transformer(xt_emb, t_tensor, condition)\n",
    "            xt_emb = self.p_sample(xt_emb, t, noise_pred)  # t as int for p_sample\n",
    "            if self.train_decoder:\n",
    "                xt_logits = self.decoder(xt_emb)\n",
    "                xt = torch.argmax(xt_logits, dim=-1)\n",
    "                xt_emb = self.tok_emb(xt)\n",
    "            else:\n",
    "                xt_emb = self.round(xt_emb)\n",
    "\n",
    "        xt = self.xtoi(xt_emb)\n",
    "        return xt\n",
    "\n",
    "    def loss_fn(\n",
    "        self,\n",
    "        noise_pred: torch.Tensor,  # [B, L, n_embd]\n",
    "        noise: torch.Tensor,  # [B, L, n_embd]\n",
    "        pred_logits: torch.Tensor,  # [B, L, vocab_size] or [B, L, n_embd]\n",
    "        tokens: torch.Tensor,  # [B, L]\n",
    "        t: torch.Tensor,  # [B]\n",
    "        verbose: bool = False,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        B, L = tokens.shape\n",
    "        device = tokens.device\n",
    "    \n",
    "        mse_loss = F.mse_loss(noise_pred, noise)\n",
    "        ce_weight = 1.0 - (t.float() / self.timesteps)\n",
    "    \n",
    "        if self.train_decoder:\n",
    "            ce_loss = F.cross_entropy(\n",
    "                pred_logits.view(-1, pred_logits.size(-1)),\n",
    "                tokens.view(-1),\n",
    "                reduction=\"none\",\n",
    "                ignore_index=self.padding_idx,\n",
    "            ).view(B, L)\n",
    "            weighted_ce_loss = (ce_weight.unsqueeze(1) * ce_loss).mean()\n",
    "            rounding_loss = torch.tensor(0.0, device=device)\n",
    "        else:\n",
    "            weighted_ce_loss = torch.tensor(0.0, device=device)\n",
    "            rounding_loss = F.mse_loss(pred_logits, self.tok_emb(tokens))  # predict exact target embeddings\n",
    "\n",
    "        total_loss = mse_loss + weighted_ce_loss + rounding_loss\n",
    "    \n",
    "        if verbose:\n",
    "            print(f\"MSE: {mse_loss.item():.4f}, CE: {weighted_ce_loss.item():.4f}, Rounding: {rounding_loss.item():.4f}\")\n",
    "    \n",
    "        return total_loss, mse_loss, weighted_ce_loss, rounding_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bd5b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:28.548540Z",
     "iopub.status.busy": "2025-04-06T12:34:28.548309Z",
     "iopub.status.idle": "2025-04-06T12:34:28.560927Z",
     "shell.execute_reply": "2025-04-06T12:34:28.560157Z"
    },
    "papermill": {
     "duration": 0.017246,
     "end_time": "2025-04-06T12:34:28.562170",
     "exception": false,
     "start_time": "2025-04-06T12:34:28.544924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import tqdm\n",
    "\n",
    "def train_epoch(\n",
    "    model: SymbolicDiffusion,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: Adam,\n",
    "    train_dataset: CharDataset,\n",
    "    timesteps: int,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    num_epochs: int\n",
    ") -> Tuple[float, float, float]:\n",
    "    model.train()\n",
    "    total_train_loss, total_train_mse, total_train_ce = 0, 0, 0\n",
    "    \n",
    "    for _, tokens, points, variables in tqdm.tqdm(train_loader, total=len(train_loader)):\n",
    "        points, tokens, variables = points.to(device), tokens.to(device), variables.to(device)\n",
    "        t = torch.randint(0, timesteps, (tokens.shape[0],), device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, noise_pred, noise = model(points, tokens, variables, t)\n",
    "        actual_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "        \n",
    "        loss, mse, ce, _ = actual_model.loss_fn(\n",
    "            noise_pred, noise, y_pred, tokens, t\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_mse += mse.item()\n",
    "        total_train_ce += ce.item()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_mse = total_train_mse / len(train_loader)\n",
    "    avg_train_ce = total_train_ce / len(train_loader)\n",
    "\n",
    "    return avg_train_loss, avg_train_mse, avg_train_ce\n",
    "\n",
    "def val_epoch(\n",
    "    model: SymbolicDiffusion,\n",
    "    val_loader: DataLoader,\n",
    "    train_dataset: CharDataset,\n",
    "    timesteps: int,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    num_epochs: int\n",
    ") -> Tuple[float, float, float]:\n",
    "    model.eval()\n",
    "    total_val_loss, total_val_mse, total_val_ce = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _, tokens, points, variables in tqdm.tqdm(val_loader, total=len(val_loader)):\n",
    "            points, tokens, variables = points.to(device), tokens.to(device), variables.to(device)\n",
    "            t = torch.randint(0, timesteps, (tokens.shape[0],), device=device)\n",
    "            y_pred, noise_pred, noise = model(points, tokens, variables, t)\n",
    "            actual_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "\n",
    "            loss, mse, ce, _ = actual_model.loss_fn(\n",
    "                noise_pred, noise, y_pred, tokens, t\n",
    "            )\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            total_val_mse += mse.item()\n",
    "            total_val_ce += ce.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    avg_val_mse = total_val_mse / len(val_loader)\n",
    "    avg_val_ce = total_val_ce / len(val_loader)\n",
    "\n",
    "    return avg_val_loss, avg_val_mse, avg_val_ce\n",
    "\n",
    "def train_single_gpu(\n",
    "    model: SymbolicDiffusion,\n",
    "    train_dataset: CharDataset,\n",
    "    val_dataset: CharDataset,\n",
    "    num_epochs=10,\n",
    "    save_every=2,\n",
    "    batch_size=32,\n",
    "    timesteps=1000,\n",
    "    learning_rate=1e-3,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Using {num_gpus} GPU(s)\" if num_gpus > 0 else \"Using CPU\")\n",
    "\n",
    "    if num_gpus > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=4\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, pin_memory=True, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train with epoch progress\n",
    "        avg_train_loss, avg_train_mse, avg_train_ce = train_epoch(\n",
    "            model, train_loader, optimizer, train_dataset, timesteps, device, epoch, num_epochs\n",
    "        )\n",
    "\n",
    "        # Validate with epoch progress\n",
    "        avg_val_loss, avg_val_mse, avg_val_ce = val_epoch(\n",
    "            model, val_loader, train_dataset, timesteps, device, epoch, num_epochs\n",
    "        )\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        # Print epoch summary after completion\n",
    "        print(\"\\nEpoch Summary:\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f} | MSE: {avg_train_mse:.4f} | CE: {avg_train_ce:.4f}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f} | MSE: {avg_val_mse:.4f} | CE: {avg_val_ce:.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "            torch.save(state_dict, \"best_model.pth\")\n",
    "            print(f\"New best model saved with val loss: {best_val_loss:.4f}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91cc325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:28.568298Z",
     "iopub.status.busy": "2025-04-06T12:34:28.568095Z",
     "iopub.status.idle": "2025-04-06T12:34:28.651214Z",
     "shell.execute_reply": "2025-04-06T12:34:28.650328Z"
    },
    "papermill": {
     "duration": 0.087763,
     "end_time": "2025-04-06T12:34:28.652658",
     "exception": false,
     "start_time": "2025-04-06T12:34:28.564895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "n_embd = 512\n",
    "timesteps = 1000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 5\n",
    "blockSize = 32\n",
    "numVars = 1\n",
    "numYs = 1\n",
    "numPoints = 250\n",
    "target = 'Skeleton'\n",
    "const_range = [-2.1, 2.1]\n",
    "trainRange = [-3.0, 3.0]\n",
    "decimals = 8\n",
    "addVars = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c117108a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:28.659378Z",
     "iopub.status.busy": "2025-04-06T12:34:28.659127Z",
     "iopub.status.idle": "2025-04-06T12:34:28.662238Z",
     "shell.execute_reply": "2025-04-06T12:34:28.661485Z"
    },
    "papermill": {
     "duration": 0.007854,
     "end_time": "2025-04-06T12:34:28.663594",
     "exception": false,
     "start_time": "2025-04-06T12:34:28.655740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"/kaggle/input/1-var-dataset/1_var_train.json\"\n",
    "val_path = \"/kaggle/input/1-var-dataset/1_var_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1401b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:28.669894Z",
     "iopub.status.busy": "2025-04-06T12:34:28.669695Z",
     "iopub.status.idle": "2025-04-06T12:34:43.221099Z",
     "shell.execute_reply": "2025-04-06T12:34:43.219979Z"
    },
    "papermill": {
     "duration": 14.556133,
     "end_time": "2025-04-06T12:34:43.222605",
     "exception": false,
     "start_time": "2025-04-06T12:34:28.666472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 498795 examples, 49 unique.\n",
      "id:93724\n",
      "outputs:C*log(C*exp(C*x1))+C>___________\n",
      "variables:1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "\n",
    "files = glob.glob(train_path)\n",
    "text = processDataFiles(files)\n",
    "chars = sorted(list(set(text))+['_','T','<','>',':']) # extract unique characters from the text before converting the text to a list, # T is for the test data\n",
    "text = text.split('\\n') # convert the raw text to a set of examples\n",
    "trainText = text[:-1] if len(text[-1]) == 0 else text\n",
    "random.shuffle(trainText) # shuffle the dataset, it's important specailly for the combined number of variables experiment\n",
    "train_dataset = CharDataset(trainText, blockSize, chars, numVars=numVars, \n",
    "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
    "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
    "\n",
    "idx = np.random.randint(train_dataset.__len__())\n",
    "inputs, outputs, points, variables = train_dataset.__getitem__(idx)\n",
    "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
    "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
    "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97952109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:43.229733Z",
     "iopub.status.busy": "2025-04-06T12:34:43.229510Z",
     "iopub.status.idle": "2025-04-06T12:34:43.319900Z",
     "shell.execute_reply": "2025-04-06T12:34:43.319002Z"
    },
    "papermill": {
     "duration": 0.095329,
     "end_time": "2025-04-06T12:34:43.321241",
     "exception": false,
     "start_time": "2025-04-06T12:34:43.225912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 972 examples, 49 unique.\n",
      "tensor(-2.7263) tensor(76.8960)\n",
      "id:908\n",
      "outputs:C*log(C*x1+C)**6+C>_____________\n",
      "variables:1\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(val_path)\n",
    "textVal = processDataFiles([files[0]])\n",
    "textVal = textVal.split('\\n') # convert the raw text to a set of examples\n",
    "val_dataset = CharDataset(textVal, blockSize, chars, numVars=numVars, \n",
    "                    numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
    "                    const_range=const_range, xRange=trainRange, decimals=decimals)\n",
    "\n",
    "# print a random sample\n",
    "idx = np.random.randint(val_dataset.__len__())\n",
    "inputs, outputs, points, variables = val_dataset.__getitem__(idx)\n",
    "print(points.min(), points.max())\n",
    "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
    "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
    "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f63f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:43.328779Z",
     "iopub.status.busy": "2025-04-06T12:34:43.328546Z",
     "iopub.status.idle": "2025-04-06T12:34:45.489032Z",
     "shell.execute_reply": "2025-04-06T12:34:45.488390Z"
    },
    "papermill": {
     "duration": 2.165778,
     "end_time": "2025-04-06T12:34:45.490469",
     "exception": false,
     "start_time": "2025-04-06T12:34:43.324691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-bf5598038ba2>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(\"/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\", map_location=torch.device(device))\n"
     ]
    }
   ],
   "source": [
    "weights = torch.load(\"/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\", map_location=torch.device(device))\n",
    "\n",
    "#vars_emb_weights = weights['vars_emb.weight']\n",
    "tok_emb_weights = weights['tok_emb.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d638d6b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T12:34:45.498091Z",
     "iopub.status.busy": "2025-04-06T12:34:45.497873Z",
     "iopub.status.idle": "2025-04-06T14:08:15.561109Z",
     "shell.execute_reply": "2025-04-06T14:08:15.559996Z"
    },
    "papermill": {
     "duration": 5611.135933,
     "end_time": "2025-04-06T14:08:16.630056",
     "exception": false,
     "start_time": "2025-04-06T12:34:45.494123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPU(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7794/7794 [18:33<00:00,  7.00it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Loss: 0.5462 | MSE: 0.1777 | CE: 0.3685\n",
      "Val Loss: 0.3217 | MSE: 0.0497 | CE: 0.2720\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.3217\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7794/7794 [18:41<00:00,  6.95it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 15.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Loss: 0.3512 | MSE: 0.0821 | CE: 0.2691\n",
      "Val Loss: 0.2884 | MSE: 0.0432 | CE: 0.2452\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.2884\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7794/7794 [18:40<00:00,  6.95it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Loss: 0.3173 | MSE: 0.0682 | CE: 0.2490\n",
      "Val Loss: 0.2797 | MSE: 0.0400 | CE: 0.2397\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.2797\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7794/7794 [18:41<00:00,  6.95it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Loss: 0.3020 | MSE: 0.0607 | CE: 0.2413\n",
      "Val Loss: 0.2673 | MSE: 0.0360 | CE: 0.2313\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.2673\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7794/7794 [18:40<00:00,  6.95it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Loss: 0.2938 | MSE: 0.0544 | CE: 0.2394\n",
      "Val Loss: 0.2614 | MSE: 0.0354 | CE: 0.2260\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.2614\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pconfig = PointNetConfig(\n",
    "        embeddingSize=n_embd,\n",
    "        numberofPoints=numPoints,\n",
    "        numberofVars=numVars,\n",
    "        numberofYs=numYs,\n",
    "    )\n",
    "    \n",
    "model = SymbolicDiffusion(\n",
    "        pconfig=pconfig,\n",
    "        vocab_size=train_dataset.vocab_size,\n",
    "        max_seq_len=blockSize,\n",
    "        padding_idx=train_dataset.paddingID,\n",
    "        max_num_vars=9,\n",
    "        n_layer=8,\n",
    "        n_head=8,\n",
    "        n_embd=n_embd,\n",
    "        timesteps=timesteps,\n",
    "        beta_start=0.0001,\n",
    "        beta_end=0.02,\n",
    "        tok_emb_weights=tok_emb_weights\n",
    "    )\n",
    "\n",
    "train_single_gpu(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        num_epochs=num_epochs,\n",
    "        save_every=2,\n",
    "        batch_size=batch_size,\n",
    "        timesteps=timesteps,\n",
    "        learning_rate=learning_rate\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6977314,
     "sourceId": 11178716,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 282263,
     "modelInstanceId": 261112,
     "sourceId": 306062,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 290784,
     "modelInstanceId": 269794,
     "sourceId": 319741,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 290853,
     "modelInstanceId": 269860,
     "sourceId": 319828,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5642.897307,
   "end_time": "2025-04-06T14:08:21.878464",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-06T12:34:18.981157",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
