{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45fbabf2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:03.309515Z",
     "iopub.status.busy": "2025-04-07T23:20:03.309234Z",
     "iopub.status.idle": "2025-04-07T23:20:04.150994Z",
     "shell.execute_reply": "2025-04-07T23:20:04.149936Z"
    },
    "papermill": {
     "duration": 0.847283,
     "end_time": "2025-04-07T23:20:04.152327",
     "exception": false,
     "start_time": "2025-04-07T23:20:03.305044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/xye_9var/pytorch/default/1/XYE_9Var.pt\n",
      "/kaggle/input/symbolic_diffusion_initial/pytorch/default/1/symbolic_diffusion_model.pth\n",
      "/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\n",
      "/kaggle/input/1-var-dataset/1_var_test.json\n",
      "/kaggle/input/1-var-dataset/1_var_val.json\n",
      "/kaggle/input/1-var-dataset/1_var_train.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac82535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:04.159275Z",
     "iopub.status.busy": "2025-04-07T23:20:04.158945Z",
     "iopub.status.idle": "2025-04-07T23:20:07.885795Z",
     "shell.execute_reply": "2025-04-07T23:20:07.884969Z"
    },
    "papermill": {
     "duration": 3.73202,
     "end_time": "2025-04-07T23:20:07.887484",
     "exception": false,
     "start_time": "2025-04-07T23:20:04.155464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import glob\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "from math import exp, sin, cos\n",
    "\n",
    "\n",
    "def generateDataStrEq(\n",
    "    eq, n_points=2, n_vars=3, decimals=4, supportPoints=None, min_x=0, max_x=3\n",
    "):\n",
    "    X = []\n",
    "    Y = []\n",
    "    # TODO: Need to make this faster\n",
    "    for p in range(n_points):\n",
    "        if supportPoints is None:\n",
    "            if type(min_x) == list:\n",
    "                x = []\n",
    "                for _ in range(n_vars):\n",
    "                    idx = np.random.randint(len(min_x))\n",
    "                    x += list(\n",
    "                        np.round(np.random.uniform(min_x[idx], max_x[idx], 1), decimals)\n",
    "                    )\n",
    "            else:\n",
    "                x = list(np.round(np.random.uniform(min_x, max_x, n_vars), decimals))\n",
    "            assert (\n",
    "                len(x) != 0\n",
    "            ), \"For some reason, we didn't generate the points correctly!\"\n",
    "        else:\n",
    "            x = supportPoints[p]\n",
    "\n",
    "        tmpEq = eq + \"\"\n",
    "        for nVID in range(n_vars):\n",
    "            tmpEq = tmpEq.replace(\"x{}\".format(nVID + 1), str(x[nVID]))\n",
    "        y = float(np.round(eval(tmpEq), decimals))\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# def processDataFiles(files):\n",
    "#     text = \"\"\n",
    "#     for f in tqdm(files):\n",
    "#         with open(f, 'r') as h:\n",
    "#             lines = h.read() # don't worry we won't run out of file handles\n",
    "#             if lines[-1]==-1:\n",
    "#                 lines = lines[:-1]\n",
    "#             #text += lines #json.loads(line)\n",
    "#             text = ''.join([lines,text])\n",
    "#     return text\n",
    "\n",
    "\n",
    "def processDataFiles(files):\n",
    "    text = \"\"\n",
    "    for f in files:\n",
    "        with open(f, \"r\") as h:\n",
    "            lines = h.read()  # don't worry we won't run out of file handles\n",
    "            if lines[-1] == -1:\n",
    "                lines = lines[:-1]\n",
    "            # text += lines #json.loads(line)\n",
    "            text = \"\".join([lines, text])\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize_equation(eq):\n",
    "    token_spec = [\n",
    "        (r'\\*\\*'),                # exponentiation\n",
    "        (r'exp'),                 # exp function\n",
    "        (r'[+\\-*/=()]'),          # operators and parentheses\n",
    "        (r'sin'),                 # sin function\n",
    "        (r'cos'),                 # cos function\n",
    "        (r'log'),                 # log function\n",
    "        (r'x\\d+'),                # variables like x1, x23, etc.\n",
    "        (r'C'),                   # constants placeholder\n",
    "        (r'-?\\d+\\.\\d+'),          # decimal numbers\n",
    "        (r'-?\\d+'),               # integers\n",
    "        (r'_'),                   # padding token\n",
    "    ]\n",
    "    token_regex = '|'.join(f'({pattern})' for pattern in token_spec)\n",
    "    matches = re.finditer(token_regex, eq)\n",
    "    return [match.group(0) for match in matches]\n",
    "\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        block_size,\n",
    "        tokens,\n",
    "        numVars,\n",
    "        numYs,\n",
    "        numPoints,\n",
    "        target=\"Skeleton\",\n",
    "        addVars=False,\n",
    "        const_range=[-0.4, 0.4],\n",
    "        xRange=[-3.0, 3.0],\n",
    "        decimals=4,\n",
    "        augment=False,\n",
    "    ):\n",
    "\n",
    "        data_size, vocab_size = len(data), len(tokens)\n",
    "        print(\"data has %d examples, %d unique.\" % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = {tok: i for i, tok in enumerate(tokens)}\n",
    "        self.itos = {i: tok for i, tok in enumerate(tokens)}\n",
    "\n",
    "\n",
    "        self.numVars = numVars\n",
    "        self.numYs = numYs\n",
    "        self.numPoints = numPoints\n",
    "\n",
    "        # padding token\n",
    "        self.paddingToken = \"_\"\n",
    "        self.paddingID = self.stoi[\"_\"]  # or another ID not already used\n",
    "        self.stoi[self.paddingToken] = self.paddingID\n",
    "        self.itos[self.paddingID] = self.paddingToken\n",
    "\n",
    "        self.threshold = [-1000, 1000]\n",
    "\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data  # it should be a list of examples\n",
    "        self.target = target\n",
    "        self.addVars = addVars\n",
    "\n",
    "        self.const_range = const_range\n",
    "        self.xRange = xRange\n",
    "        self.decimals = decimals\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab an example from the data\n",
    "        chunk = self.data[idx]  # sequence of tokens including x, y, eq, etc.\n",
    "\n",
    "        try:\n",
    "            chunk = json.loads(chunk)  # convert the sequence tokens to a dictionary\n",
    "        except Exception as e:\n",
    "            print(\"Couldn't convert to json: {} \\n error is: {}\".format(chunk, e))\n",
    "            # try the previous example\n",
    "            idx = idx - 1\n",
    "            idx = idx if idx >= 0 else 0\n",
    "            chunk = self.data[idx]\n",
    "            chunk = json.loads(chunk)  # convert the sequence tokens to a dictionary\n",
    "\n",
    "        # find the number of variables in the equation\n",
    "        printInfoCondition = random.random() < 0.0000001\n",
    "        eq = chunk[self.target]\n",
    "        if printInfoCondition:\n",
    "            print(f\"\\nEquation: {eq}\")\n",
    "        vars = re.finditer(\"x[\\d]+\", eq)\n",
    "        numVars = 0\n",
    "        for v in vars:\n",
    "            v = v.group(0).strip(\"x\")\n",
    "            v = eval(v)\n",
    "            v = int(v)\n",
    "            if v > numVars:\n",
    "                numVars = v\n",
    "\n",
    "        if self.target == \"Skeleton\" and self.augment:\n",
    "            threshold = 5000\n",
    "            # randomly generate the constants\n",
    "            cleanEqn = \"\"\n",
    "            for chr in eq:\n",
    "                if chr == \"C\":\n",
    "                    # genereate a new random number\n",
    "                    chr = \"{}\".format(\n",
    "                        np.random.uniform(self.const_range[0], self.const_range[1])\n",
    "                    )\n",
    "                cleanEqn += chr\n",
    "\n",
    "            # update the points\n",
    "            nPoints = np.random.randint(\n",
    "                *self.numPoints\n",
    "            )  # if supportPoints is None else len(supportPoints)\n",
    "            try:\n",
    "                if printInfoCondition:\n",
    "                    print(\"Org:\", chunk[\"X\"], chunk[\"Y\"])\n",
    "\n",
    "                X, y = generateDataStrEq(\n",
    "                    cleanEqn,\n",
    "                    n_points=nPoints,\n",
    "                    n_vars=self.numVars,\n",
    "                    decimals=self.decimals,\n",
    "                    min_x=self.xRange[0],\n",
    "                    max_x=self.xRange[1],\n",
    "                )\n",
    "\n",
    "                # replace out of threshold with maximum numbers\n",
    "                y = [e if abs(e) < threshold else np.sign(e) * threshold for e in y]\n",
    "\n",
    "                # check if there is nan/inf/very large numbers in the y\n",
    "                conditions = (\n",
    "                    (np.isnan(y).any() or np.isinf(y).any())\n",
    "                    or len(y) == 0\n",
    "                    or (abs(min(y)) > threshold or abs(max(y)) > threshold)\n",
    "                )\n",
    "                if not conditions:\n",
    "                    chunk[\"X\"], chunk[\"Y\"] = X, y\n",
    "\n",
    "                if printInfoCondition:\n",
    "                    print(\"Evd:\", chunk[\"X\"], chunk[\"Y\"])\n",
    "            except Exception as e:\n",
    "                # for different reason this might happend including but not limited to division by zero\n",
    "                print(\n",
    "                    \"\".join(\n",
    "                        [\n",
    "                            f\"We just used the original equation and support points because of {e}. \",\n",
    "                            f\"The equation is {eq}, and we update the equation to {cleanEqn}\",\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # encode every character in the equation to an integer\n",
    "        # < is SOS, > is EOS\n",
    "        if self.addVars:\n",
    "            dix = [self.stoi[s] for s in \"<\" + str(numVars) + \":\" + eq + \">\"]\n",
    "        else:\n",
    "            eq_tokens = tokenize_equation(eq)\n",
    "            if self.addVars:\n",
    "                token_seq = [\"<\", str(numVars), \":\", *eq_tokens, \">\"]\n",
    "            else:\n",
    "                token_seq = [\"<\", *eq_tokens, \">\"]\n",
    "            dix = [self.stoi[tok] for tok in token_seq]\n",
    "\n",
    "        inputs = dix[:-1]\n",
    "        outputs = dix[1:]\n",
    "\n",
    "        # add the padding to the equations\n",
    "        paddingSize = max(self.block_size - len(inputs), 0)\n",
    "        paddingList = [self.paddingID] * paddingSize\n",
    "        inputs += paddingList\n",
    "        outputs += paddingList\n",
    "\n",
    "        # make sure it is not more than what should be\n",
    "        inputs = inputs[: self.block_size]\n",
    "        outputs = outputs[: self.block_size]\n",
    "\n",
    "        points = torch.zeros(self.numVars + self.numYs, self.numPoints - 1)\n",
    "        for idx, xy in enumerate(zip(chunk[\"X\"], chunk[\"Y\"])):\n",
    "\n",
    "            if not isinstance(xy[0], list) or not isinstance(\n",
    "                xy[1], (list, float, np.float64)\n",
    "            ):\n",
    "                print(f\"Unexpected types: {type(xy[0])}, {type(xy[1])}\")\n",
    "                continue  # Skip if types are incorrect\n",
    "\n",
    "            # don't let to exceed the maximum number of points\n",
    "            if idx >= self.numPoints - 1:\n",
    "                break\n",
    "\n",
    "            x = xy[0]\n",
    "            x = x + [0] * (max(self.numVars - len(x), 0))  # padding\n",
    "\n",
    "            y = [xy[1]] if type(xy[1]) == float or type(xy[1]) == np.float64 else xy[1]\n",
    "\n",
    "            y = y + [0] * (max(self.numYs - len(y), 0))  # padding\n",
    "            p = x + y  # because it is only one point\n",
    "            p = torch.tensor(p)\n",
    "            # replace nan and inf\n",
    "            p = torch.nan_to_num(\n",
    "                p,\n",
    "                nan=self.threshold[1],\n",
    "                posinf=self.threshold[1],\n",
    "                neginf=self.threshold[0],\n",
    "            )\n",
    "            \n",
    "            points[:, idx] = p\n",
    "\n",
    "        points = torch.nan_to_num(\n",
    "            points,\n",
    "            nan=self.threshold[1],\n",
    "            posinf=self.threshold[1],\n",
    "            neginf=self.threshold[0],\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        outputs = torch.tensor(outputs, dtype=torch.long)\n",
    "        numVars = torch.tensor(numVars, dtype=torch.long)\n",
    "        return inputs, outputs, points, numVars\n",
    "\n",
    "\n",
    "# Relative Mean Square Error\n",
    "def relativeErr(y, yHat, info=False, eps=1e-5):\n",
    "    yHat = np.reshape(yHat, [1, -1])[0]\n",
    "    y = np.reshape(y, [1, -1])[0]\n",
    "    if len(y) > 0 and len(y) == len(yHat):\n",
    "        err = ((yHat - y)) ** 2 / np.linalg.norm(y + eps)\n",
    "        if info:\n",
    "            for _ in range(5):\n",
    "                i = np.random.randint(len(y))\n",
    "                print(\"yPR,yTrue:{},{}, Err:{}\".format(yHat[i], y[i], err[i]))\n",
    "    else:\n",
    "        err = 100\n",
    "\n",
    "    return np.mean(err)\n",
    "\n",
    "\n",
    "def lossFunc(constants, eq, X, Y, eps=1e-5):\n",
    "    err = 0\n",
    "    eq = eq.replace(\"C\", \"{}\").format(*constants)\n",
    "\n",
    "    for x, y in zip(X, Y):\n",
    "        eqTemp = eq + \"\"\n",
    "        if type(x) == np.float32:\n",
    "            x = [x]\n",
    "        for i, e in enumerate(x):\n",
    "            # make sure e is not a tensor\n",
    "            if type(e) == torch.Tensor:\n",
    "                e = e.item()\n",
    "            eqTemp = eqTemp.replace(\"x{}\".format(i + 1), str(e))\n",
    "        try:\n",
    "            yHat = eval(eqTemp)\n",
    "        except:\n",
    "            print(\"Exception has been occured! EQ: {}, OR: {}\".format(eqTemp, eq))\n",
    "            continue\n",
    "            yHat = 100\n",
    "        try:\n",
    "            # handle overflow\n",
    "            err += relativeErr(y, yHat)  # (y-yHat)**2\n",
    "        except:\n",
    "            print(\n",
    "                \"Exception has been occured! EQ: {}, OR: {}, y:{}-yHat:{}\".format(\n",
    "                    eqTemp, eq, y, yHat\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "            err += 10\n",
    "\n",
    "    err /= len(Y)\n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e87e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:07.894893Z",
     "iopub.status.busy": "2025-04-07T23:20:07.894404Z",
     "iopub.status.idle": "2025-04-07T23:20:07.923362Z",
     "shell.execute_reply": "2025-04-07T23:20:07.922540Z"
    },
    "papermill": {
     "duration": 0.034262,
     "end_time": "2025-04-07T23:20:07.924873",
     "exception": false,
     "start_time": "2025-04-07T23:20:07.890611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from SymbolicGPT: https://github.com/mojivalipour/symbolicgpt/blob/master/models.py\n",
    "class PointNetConfig:\n",
    "    \"\"\"base PointNet config\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddingSize,\n",
    "        numberofPoints,\n",
    "        numberofVars,\n",
    "        numberofYs,\n",
    "        method=\"GPT\",\n",
    "        varibleEmbedding=\"NOT_VAR\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.embeddingSize = embeddingSize\n",
    "        self.numberofPoints = numberofPoints  # number of points\n",
    "        self.numberofVars = numberofVars  # input dimension (Xs)\n",
    "        self.numberofYs = numberofYs  # output dimension (Ys)\n",
    "        self.method = method\n",
    "        self.varibleEmbedding = varibleEmbedding\n",
    "\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    \"\"\"\n",
    "    The PointNet structure in the orginal PointNet paper:\n",
    "    PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation by Qi et. al. 2017\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "        self.num_units = config.embeddingSize\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            config.numberofVars + config.numberofYs, self.num_units, 1\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(self.num_units, 2 * self.num_units, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * self.num_units, 4 * self.num_units, 1)\n",
    "        self.fc1 = nn.Linear(4 * self.num_units, 2 * self.num_units)\n",
    "        self.fc2 = nn.Linear(2 * self.num_units, self.num_units)\n",
    "\n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "        self.input_batch_norm = nn.BatchNorm1d(config.numberofVars + config.numberofYs)\n",
    "        # self.input_layer_norm = nn.LayerNorm(config.numberofPoints)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.num_units)\n",
    "        self.bn2 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn3 = nn.BatchNorm1d(4 * self.num_units)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * self.num_units)\n",
    "        self.bn5 = nn.BatchNorm1d(self.num_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [batch, #features, #points]\n",
    "        :return:\n",
    "            logit: [batch, embedding_size]\n",
    "        \"\"\"\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        x, _ = torch.max(x, dim=2)  # global max pooling\n",
    "        assert x.size(1) == 4 * self.num_units\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        # x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class NoisePredictionTransformer(nn.Module):\n",
    "    def __init__(self, n_embd, max_seq_len, n_layer=6, n_head=8, max_timesteps=1000):\n",
    "        super().__init__()\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, max_seq_len, n_embd))\n",
    "        self.time_emb = nn.Embedding(max_timesteps, n_embd)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=n_embd,\n",
    "            nhead=n_head,\n",
    "            dim_feedforward=n_embd * 4,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layer)\n",
    "\n",
    "    def forward(self, x_t, t, condition):\n",
    "        B, L, _ = x_t.shape\n",
    "        pos_emb = self.pos_emb[:, :L, :]\n",
    "        time_emb = self.time_emb(t).unsqueeze(1)\n",
    "        condition = condition.unsqueeze(1)\n",
    "        x = x_t + pos_emb + time_emb + condition\n",
    "        return self.encoder(x)  # Predicts x_start\n",
    "\n",
    "\n",
    "# Symbolic Diffusion with Hybrid Loss\n",
    "class SymbolicGaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tnet_config,\n",
    "        vocab_size,\n",
    "        max_seq_len,\n",
    "        padding_idx: int = 0,\n",
    "        max_num_vars: int = 9,\n",
    "        n_layer=6,\n",
    "        n_head=8,\n",
    "        n_embd=512,\n",
    "        timesteps=1000,\n",
    "        beta_start=0.0001,\n",
    "        beta_end=0.02,\n",
    "        ce_weight=1.0,  # Weight for CE loss relative to MSE\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.padding_idx = padding_idx\n",
    "        self.n_embd = n_embd\n",
    "        self.timesteps = timesteps\n",
    "        self.ce_weight = ce_weight\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Embedding layers\n",
    "        self.tok_emb = nn.Embedding(vocab_size, n_embd, padding_idx=self.padding_idx)\n",
    "        self.vars_emb = nn.Embedding(max_num_vars, n_embd)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Linear(n_embd, vocab_size, bias=False)\n",
    "        self.decoder.weight = self.tok_emb.weight\n",
    "\n",
    "        # Models\n",
    "        self.tnet = tNet(tnet_config)\n",
    "        self.model = NoisePredictionTransformer(\n",
    "            n_embd, max_seq_len, n_layer, n_head, timesteps\n",
    "        )\n",
    "\n",
    "        # Noise schedule\n",
    "        self.register_buffer(\"beta\", torch.linspace(beta_start, beta_end, timesteps))\n",
    "        self.register_buffer(\"alpha\", 1.0 - self.beta)\n",
    "        self.register_buffer(\"alpha_bar\", torch.cumprod(self.alpha, dim=0))\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        noise = torch.randn_like(x_start)\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t]).view(-1, 1, 1)\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar[t]).view(-1, 1, 1)\n",
    "\n",
    "        x_t = sqrt_alpha_bar * x_start + sqrt_one_minus_alpha_bar * noise\n",
    "        return x_t\n",
    "\n",
    "    def p_mean_variance(self, x, t, t_next, condition):\n",
    "        alpha_t = self.alpha[t]\n",
    "        alpha_bar_t = self.alpha_bar[t]\n",
    "        alpha_bar_t_next = self.alpha_bar[t_next]\n",
    "        beta_t = self.beta[t]\n",
    "\n",
    "        x_start_pred = self.model(x, t.long(), condition)\n",
    "\n",
    "        coeff1 = torch.sqrt(alpha_bar_t_next) * beta_t / (1 - alpha_bar_t)\n",
    "        coeff2 = torch.sqrt(alpha_t) * (1 - alpha_bar_t_next) / (1 - alpha_bar_t)\n",
    "        mean = coeff1 * x_start_pred + coeff2 * x\n",
    "        variance = (1 - alpha_bar_t_next) / (1 - alpha_bar_t) * beta_t\n",
    "        return mean, variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, t_next, condition):\n",
    "        mean, variance = self.p_mean_variance(x, t, t_next, condition)\n",
    "        if torch.all(t_next == 0):\n",
    "            return mean\n",
    "        noise = torch.randn_like(x)\n",
    "        return mean + torch.sqrt(variance) * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, points, variables, batch_size=16):\n",
    "        condition = self.tnet(points) + self.vars_emb(variables)\n",
    "        shape = (batch_size, self.max_seq_len, self.n_embd)\n",
    "        x = torch.randn(shape, device=self.device)\n",
    "        steps = torch.arange(self.timesteps, 0, -1, device=self.device)\n",
    "\n",
    "        for i in tqdm(\n",
    "            range(self.timesteps), desc=\"sampling loop\", total=self.timesteps\n",
    "        ):\n",
    "            t = steps[i]\n",
    "            t_next = (\n",
    "                steps[i + 1]\n",
    "                if i + 1 < self.timesteps\n",
    "                else torch.tensor(0, device=self.device)\n",
    "            )\n",
    "            x = self.p_sample(x, t, t_next, condition)\n",
    "\n",
    "        # Map embeddings to token indices via decoder\n",
    "        logits = self.decoder(x)  # [B, L, vocab_size]\n",
    "        token_indices = torch.argmax(logits, dim=-1)  # [B, L]\n",
    "        return token_indices\n",
    "\n",
    "    def p_losses(self, x_start, points, tokens, variables, t, noise=None):\n",
    "        \"\"\"Hybrid loss: MSE on embeddings + CE on tokens.\"\"\"\n",
    "        noise = torch.randn_like(x_start) if noise is None else noise\n",
    "        x_t = self.q_sample(x_start, t, noise)\n",
    "        condition = self.tnet(points) + self.vars_emb(variables)\n",
    "        x_start_pred = self.model(x_t, t.long(), condition)\n",
    "\n",
    "        # MSE loss on embeddings\n",
    "        mse_loss = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "        # CE loss on tokens\n",
    "        logits = self.decoder(x_start_pred)  # [B, L, vocab_size]\n",
    "        ce_loss = F.cross_entropy(\n",
    "            logits.view(-1, self.vocab_size),  # [B*L, vocab_size]\n",
    "            tokens.view(-1),  # [B*L]\n",
    "            ignore_index=self.padding_idx,  # Assuming padding_idx=0\n",
    "            reduction=\"mean\",\n",
    "        )\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = mse_loss + self.ce_weight * ce_loss\n",
    "        return total_loss, mse_loss, ce_loss\n",
    "\n",
    "    def forward(self, points, tokens, variables, t):\n",
    "        token_emb = self.tok_emb(tokens)\n",
    "        total_loss, mse_loss, ce_loss = self.p_losses(\n",
    "            token_emb, points, tokens, variables, t\n",
    "        )\n",
    "        return total_loss, mse_loss, ce_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f84d4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:07.935888Z",
     "iopub.status.busy": "2025-04-07T23:20:07.935653Z",
     "iopub.status.idle": "2025-04-07T23:20:07.948729Z",
     "shell.execute_reply": "2025-04-07T23:20:07.947897Z"
    },
    "papermill": {
     "duration": 0.020051,
     "end_time": "2025-04-07T23:20:07.950227",
     "exception": false,
     "start_time": "2025-04-07T23:20:07.930176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: SymbolicGaussianDiffusion,  # Changed type hint\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: Adam,\n",
    "    train_dataset: CharDataset,\n",
    "    timesteps: int,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    num_epochs: int,\n",
    ") -> Tuple[float, float, float]:  # Now returns all loss components\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_mse_loss = 0\n",
    "    total_ce_loss = 0\n",
    "\n",
    "    for i, (_, tokens, points, variables) in tqdm.tqdm(\n",
    "        enumerate(train_loader),\n",
    "        total=len(train_loader),\n",
    "        desc=f\"Epoch {epoch+1}/{num_epochs}\",\n",
    "    ):\n",
    "        points, tokens, variables = (\n",
    "            points.to(device),\n",
    "            tokens.to(device),\n",
    "            variables.to(device),\n",
    "        )\n",
    "        t = torch.randint(0, timesteps, (tokens.shape[0],), device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Model now returns (total_loss, mse_loss, ce_loss)\n",
    "        total_loss, mse_loss, ce_loss = model(points, tokens, variables, t)\n",
    "\n",
    "        if (i + 1) % 250 == 0:\n",
    "            print(f\"Batch {i + 1}/{len(train_loader)}:\")\n",
    "            print(f\"total_loss: {total_loss}, mse: {mse_loss}, ce: {ce_loss}\")\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate all losses\n",
    "        total_train_loss += total_loss.item()\n",
    "        total_mse_loss += mse_loss.item()\n",
    "        total_ce_loss += ce_loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_mse_loss = total_mse_loss / len(train_loader)\n",
    "    avg_ce_loss = total_ce_loss / len(train_loader)\n",
    "    return avg_train_loss, avg_mse_loss, avg_ce_loss\n",
    "\n",
    "\n",
    "def val_epoch(\n",
    "    model: SymbolicGaussianDiffusion,  # Changed type hint\n",
    "    val_loader: DataLoader,\n",
    "    train_dataset: CharDataset,\n",
    "    timesteps: int,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    num_epochs: int,\n",
    ") -> Tuple[float, float, float]:  # Now returns all loss components\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_mse_loss = 0\n",
    "    total_ce_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, tokens, points, variables in tqdm.tqdm(\n",
    "            val_loader, total=len(val_loader), desc=\"Validating\"\n",
    "        ):\n",
    "            points, tokens, variables = (\n",
    "                points.to(device),\n",
    "                tokens.to(device),\n",
    "                variables.to(device),\n",
    "            )\n",
    "            t = torch.randint(0, timesteps, (tokens.shape[0],), device=device)\n",
    "\n",
    "            # Model returns (total_loss, mse_loss, ce_loss)\n",
    "            total_loss, mse_loss, ce_loss = model(points, tokens, variables, t)\n",
    "\n",
    "            total_val_loss += total_loss.item()\n",
    "            total_mse_loss += mse_loss.item()\n",
    "            total_ce_loss += ce_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    avg_mse_loss = total_mse_loss / len(val_loader)\n",
    "    avg_ce_loss = total_ce_loss / len(val_loader)\n",
    "    return avg_val_loss, avg_mse_loss, avg_ce_loss\n",
    "\n",
    "\n",
    "def train_single_gpu(\n",
    "    model: SymbolicGaussianDiffusion,  # Changed type hint\n",
    "    train_dataset: CharDataset,\n",
    "    val_dataset: CharDataset,\n",
    "    num_epochs=10,\n",
    "    save_every=2,\n",
    "    batch_size=32,\n",
    "    timesteps=1000,\n",
    "    learning_rate=1e-3,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train with epoch progress\n",
    "        avg_train_loss, avg_mse_loss, avg_ce_loss = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            train_dataset,\n",
    "            timesteps,\n",
    "            device,\n",
    "            epoch,\n",
    "            num_epochs,\n",
    "        )\n",
    "\n",
    "        # Validate with epoch progress\n",
    "        avg_val_loss, val_mse_loss, val_ce_loss = val_epoch(\n",
    "            model, val_loader, train_dataset, timesteps, device, epoch, num_epochs\n",
    "        )\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        # Print detailed epoch summary\n",
    "        print(\"\\nEpoch Summary:\")\n",
    "        print(\n",
    "            f\"Train Total Loss: {avg_train_loss:.4f} (MSE: {avg_mse_loss:.4f}, CE: {avg_ce_loss:.4f})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Val Total Loss: {avg_val_loss:.4f} (MSE: {val_mse_loss:.4f}, CE: {val_ce_loss:.4f})\"\n",
    "        )\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            state_dict = model.state_dict()\n",
    "            torch.save(state_dict, \"best_model.pth\")\n",
    "            print(f\"New best model saved with val loss: {best_val_loss:.4f}\")\n",
    "\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3c01f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:07.960810Z",
     "iopub.status.busy": "2025-04-07T23:20:07.960578Z",
     "iopub.status.idle": "2025-04-07T23:20:08.039555Z",
     "shell.execute_reply": "2025-04-07T23:20:08.038597Z"
    },
    "papermill": {
     "duration": 0.086223,
     "end_time": "2025-04-07T23:20:08.041242",
     "exception": false,
     "start_time": "2025-04-07T23:20:07.955019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "n_embd = 512\n",
    "timesteps = 1000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 5\n",
    "blockSize = 32\n",
    "numVars = 1\n",
    "numYs = 1\n",
    "numPoints = 250\n",
    "target = 'Skeleton'\n",
    "const_range = [-2.1, 2.1]\n",
    "trainRange = [-3.0, 3.0]\n",
    "decimals = 8\n",
    "addVars = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56127e9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:08.052830Z",
     "iopub.status.busy": "2025-04-07T23:20:08.052576Z",
     "iopub.status.idle": "2025-04-07T23:20:08.055928Z",
     "shell.execute_reply": "2025-04-07T23:20:08.055061Z"
    },
    "papermill": {
     "duration": 0.010651,
     "end_time": "2025-04-07T23:20:08.057522",
     "exception": false,
     "start_time": "2025-04-07T23:20:08.046871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"/kaggle/input/1-var-dataset/1_var_train.json\"\n",
    "val_path = \"/kaggle/input/1-var-dataset/1_var_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041fe5a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:08.068703Z",
     "iopub.status.busy": "2025-04-07T23:20:08.068457Z",
     "iopub.status.idle": "2025-04-07T23:20:26.347285Z",
     "shell.execute_reply": "2025-04-07T23:20:26.346415Z"
    },
    "papermill": {
     "duration": 18.285905,
     "end_time": "2025-04-07T23:20:26.348693",
     "exception": false,
     "start_time": "2025-04-07T23:20:08.062788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 498795 examples, 27 unique.\n",
      "id:91116\n",
      "outputs:C*sin(C*x1+C)+C>___________________\n",
      "variables:1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "\n",
    "files = glob.glob(train_path)\n",
    "text = processDataFiles(files)\n",
    "text = text.split('\\n') # convert the raw text to a set of examples\n",
    "# skeletons = []\n",
    "skeletons = [json.loads(item)['Skeleton'] for item in text if item.strip()]\n",
    "all_tokens = set()\n",
    "for eq in skeletons:\n",
    "    all_tokens.update(tokenize_equation(eq))\n",
    "integers = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "all_tokens.update(integers)  # add all integers to the token set\n",
    "tokens = sorted(list(all_tokens) + ['_', 'T', '<', '>', ':'])  # special tokens\n",
    "trainText = text[:-1] if len(text[-1]) == 0 else text\n",
    "random.shuffle(trainText) # shuffle the dataset, it's important specailly for the combined number of variables experiment\n",
    "train_dataset = CharDataset(trainText, blockSize, tokens=tokens, numVars=numVars,\n",
    "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
    "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
    "\n",
    "idx = np.random.randint(train_dataset.__len__())\n",
    "inputs, outputs, points, variables = train_dataset.__getitem__(idx)\n",
    "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
    "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
    "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa05093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:26.355813Z",
     "iopub.status.busy": "2025-04-07T23:20:26.355566Z",
     "iopub.status.idle": "2025-04-07T23:20:26.428909Z",
     "shell.execute_reply": "2025-04-07T23:20:26.428109Z"
    },
    "papermill": {
     "duration": 0.078185,
     "end_time": "2025-04-07T23:20:26.430305",
     "exception": false,
     "start_time": "2025-04-07T23:20:26.352120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 972 examples, 27 unique.\n",
      "tensor(-486.0321) tensor(772.1927)\n",
      "id:349\n",
      "outputs:C*x1**6+C*x1+C>____________________\n",
      "variables:1\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(val_path)\n",
    "textVal = processDataFiles([files[0]])\n",
    "textVal = textVal.split('\\n') # convert the raw text to a set of examples\n",
    "val_dataset = CharDataset(textVal, blockSize, tokens=tokens, numVars=numVars,\n",
    "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
    "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
    "\n",
    "# print a random sample\n",
    "idx = np.random.randint(val_dataset.__len__())\n",
    "inputs, outputs, points, variables = val_dataset.__getitem__(idx)\n",
    "print(points.min(), points.max())\n",
    "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
    "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
    "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d080ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:26.437346Z",
     "iopub.status.busy": "2025-04-07T23:20:26.437134Z",
     "iopub.status.idle": "2025-04-07T23:20:28.680072Z",
     "shell.execute_reply": "2025-04-07T23:20:28.679030Z"
    },
    "papermill": {
     "duration": 2.248433,
     "end_time": "2025-04-07T23:20:28.681944",
     "exception": false,
     "start_time": "2025-04-07T23:20:26.433511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-bf5598038ba2>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(\"/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\", map_location=torch.device(device))\n"
     ]
    }
   ],
   "source": [
    "weights = torch.load(\"/kaggle/input/xye_1var/pytorch/default/1/XYE_1Var.pt\", map_location=torch.device(device))\n",
    "\n",
    "#vars_emb_weights = weights['vars_emb.weight']\n",
    "tok_emb_weights = weights['tok_emb.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a860f54f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T23:20:28.689898Z",
     "iopub.status.busy": "2025-04-07T23:20:28.689606Z",
     "iopub.status.idle": "2025-04-08T01:11:57.073571Z",
     "shell.execute_reply": "2025-04-08T01:11:57.072106Z"
    },
    "papermill": {
     "duration": 6688.389551,
     "end_time": "2025-04-08T01:11:57.075184",
     "exception": false,
     "start_time": "2025-04-07T23:20:28.685633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   3%|▎         | 250/7794 [00:36<18:19,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 2.0959935188293457, mse: 0.0, ce: 2.0959935188293457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   6%|▋         | 500/7794 [01:15<20:05,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 1.3833138942718506, mse: 0.0, ce: 1.3833138942718506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  10%|▉         | 750/7794 [01:59<19:52,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.9861836433410645, mse: 0.0, ce: 0.9861836433410645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  13%|█▎        | 1000/7794 [02:40<18:40,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.7746279239654541, mse: 0.0, ce: 0.7746279239654541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  16%|█▌        | 1250/7794 [03:23<18:33,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.3896009922027588, mse: 0.0, ce: 0.3896009922027588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  19%|█▉        | 1500/7794 [04:05<17:38,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.551738977432251, mse: 0.0, ce: 0.551738977432251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  22%|██▏       | 1750/7794 [04:47<16:46,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.6586273312568665, mse: 0.0, ce: 0.6586273312568665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  26%|██▌       | 2000/7794 [05:29<16:08,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.7216774225234985, mse: 0.0, ce: 0.7216774225234985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  29%|██▉       | 2250/7794 [06:11<15:38,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.5576450228691101, mse: 0.0, ce: 0.5576450228691101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  32%|███▏      | 2500/7794 [06:53<14:48,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.6334397196769714, mse: 0.0, ce: 0.6334397196769714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  35%|███▌      | 2750/7794 [07:35<14:09,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.5298137664794922, mse: 0.0, ce: 0.5298137664794922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  38%|███▊      | 3000/7794 [08:18<13:30,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.34729915857315063, mse: 0.0, ce: 0.34729915857315063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  42%|████▏     | 3250/7794 [09:00<12:55,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.46453025937080383, mse: 0.0, ce: 0.46453025937080383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  45%|████▍     | 3500/7794 [09:43<12:10,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.34283584356307983, mse: 0.0, ce: 0.34283584356307983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  48%|████▊     | 3750/7794 [10:25<11:24,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.3634548485279083, mse: 0.0, ce: 0.3634548485279083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  51%|█████▏    | 4000/7794 [11:07<10:47,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.44247061014175415, mse: 0.0, ce: 0.44247061014175415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  55%|█████▍    | 4250/7794 [11:50<10:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.45862331986427307, mse: 0.0, ce: 0.45862331986427307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  58%|█████▊    | 4500/7794 [12:33<09:22,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.6400315165519714, mse: 0.0, ce: 0.6400315165519714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  61%|██████    | 4750/7794 [13:15<08:39,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.43781426548957825, mse: 0.0, ce: 0.43781426548957825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  64%|██████▍   | 5000/7794 [13:58<07:50,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.44264793395996094, mse: 0.0, ce: 0.44264793395996094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  67%|██████▋   | 5250/7794 [14:40<07:07,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.5023562908172607, mse: 0.0, ce: 0.5023562908172607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  71%|███████   | 5500/7794 [15:22<06:27,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.3135105073451996, mse: 0.0, ce: 0.3135105073451996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  74%|███████▍  | 5750/7794 [16:04<05:43,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.4536731541156769, mse: 0.0, ce: 0.4536731541156769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  77%|███████▋  | 6000/7794 [16:47<05:02,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.4274200201034546, mse: 0.0, ce: 0.4274200201034546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  80%|████████  | 6250/7794 [17:29<04:22,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.6229063272476196, mse: 0.0, ce: 0.6229063272476196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  83%|████████▎ | 6500/7794 [18:12<03:40,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.7224781513214111, mse: 0.0, ce: 0.7224781513214111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  87%|████████▋ | 6750/7794 [18:54<02:58,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.2622915208339691, mse: 0.0, ce: 0.2622915208339691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  90%|████████▉ | 7000/7794 [19:37<02:14,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.3670249879360199, mse: 0.0, ce: 0.3670249879360199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  93%|█████████▎| 7250/7794 [20:20<01:33,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.47112178802490234, mse: 0.0, ce: 0.47112178802490234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  96%|█████████▌| 7500/7794 [21:03<00:50,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.44945427775382996, mse: 0.0, ce: 0.44945427775382996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  99%|█████████▉| 7750/7794 [21:46<00:07,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.42716532945632935, mse: 0.0, ce: 0.42716532945632935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 7794/7794 [21:53<00:00,  5.93it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:01<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.6946 (MSE: 0.0000, CE: 0.6946)\n",
      "Val Total Loss: 0.4103 (MSE: 0.0000, CE: 0.4103)\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.4103\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:   3%|▎         | 250/7794 [00:43<21:29,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 0.6500421762466431, mse: 0.0, ce: 0.6500421762466431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:   6%|▋         | 500/7794 [01:26<20:54,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 0.5229318141937256, mse: 0.0, ce: 0.5229318141937256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  10%|▉         | 750/7794 [02:08<20:07,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.5390527844429016, mse: 0.0, ce: 0.5390527844429016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  13%|█▎        | 1000/7794 [02:51<19:17,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.3529895544052124, mse: 0.0, ce: 0.3529895544052124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  16%|█▌        | 1250/7794 [03:34<18:47,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.41758567094802856, mse: 0.0, ce: 0.41758567094802856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  19%|█▉        | 1500/7794 [04:17<18:04,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.3934159278869629, mse: 0.0, ce: 0.3934159278869629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  22%|██▏       | 1750/7794 [05:00<17:12,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.5965246558189392, mse: 0.0, ce: 0.5965246558189392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  26%|██▌       | 2000/7794 [05:43<16:38,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.6266549229621887, mse: 0.0, ce: 0.6266549229621887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  29%|██▉       | 2250/7794 [06:26<15:48,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.4656807780265808, mse: 0.0, ce: 0.4656807780265808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  32%|███▏      | 2500/7794 [07:09<15:13,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.4573703408241272, mse: 0.0, ce: 0.4573703408241272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  35%|███▌      | 2750/7794 [07:52<14:28,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.43837130069732666, mse: 0.0, ce: 0.43837130069732666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  38%|███▊      | 3000/7794 [08:35<13:48,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.656796395778656, mse: 0.0, ce: 0.656796395778656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  42%|████▏     | 3250/7794 [09:18<13:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.35514935851097107, mse: 0.0, ce: 0.35514935851097107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  45%|████▍     | 3500/7794 [10:01<12:22,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.48884814977645874, mse: 0.0, ce: 0.48884814977645874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  48%|████▊     | 3750/7794 [10:44<11:33,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.5057061314582825, mse: 0.0, ce: 0.5057061314582825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  51%|█████▏    | 4000/7794 [11:27<10:50,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.5324031710624695, mse: 0.0, ce: 0.5324031710624695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  55%|█████▍    | 4250/7794 [12:10<10:02,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.3940209746360779, mse: 0.0, ce: 0.3940209746360779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  58%|█████▊    | 4500/7794 [12:52<09:21,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.34487712383270264, mse: 0.0, ce: 0.34487712383270264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  61%|██████    | 4750/7794 [13:35<08:36,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.5033984184265137, mse: 0.0, ce: 0.5033984184265137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  64%|██████▍   | 5000/7794 [14:17<07:58,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.32176944613456726, mse: 0.0, ce: 0.32176944613456726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  67%|██████▋   | 5250/7794 [15:00<07:11,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.47759753465652466, mse: 0.0, ce: 0.47759753465652466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  71%|███████   | 5500/7794 [15:43<06:30,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.43117138743400574, mse: 0.0, ce: 0.43117138743400574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  74%|███████▍  | 5750/7794 [16:26<05:49,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.2861112058162689, mse: 0.0, ce: 0.2861112058162689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  77%|███████▋  | 6000/7794 [17:08<05:07,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.3734230697154999, mse: 0.0, ce: 0.3734230697154999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  80%|████████  | 6250/7794 [17:51<04:22,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.4780431091785431, mse: 0.0, ce: 0.4780431091785431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  83%|████████▎ | 6500/7794 [18:34<03:40,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.4295591711997986, mse: 0.0, ce: 0.4295591711997986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  87%|████████▋ | 6750/7794 [19:17<02:59,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.41414496302604675, mse: 0.0, ce: 0.41414496302604675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  90%|████████▉ | 7000/7794 [20:00<02:16,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.4814465045928955, mse: 0.0, ce: 0.4814465045928955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  93%|█████████▎| 7250/7794 [20:43<01:33,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.3918391168117523, mse: 0.0, ce: 0.3918391168117523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  96%|█████████▌| 7500/7794 [21:26<00:50,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.4148487150669098, mse: 0.0, ce: 0.4148487150669098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  99%|█████████▉| 7750/7794 [22:09<00:07,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.4797041416168213, mse: 0.0, ce: 0.4797041416168213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 7794/7794 [22:17<00:00,  5.83it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:01<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.4079 (MSE: 0.0000, CE: 0.4079)\n",
      "Val Total Loss: 0.3394 (MSE: 0.0000, CE: 0.3394)\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.3394\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:   3%|▎         | 250/7794 [00:43<21:34,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 0.38123011589050293, mse: 0.0, ce: 0.38123011589050293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:   6%|▋         | 500/7794 [01:26<20:57,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 0.26696231961250305, mse: 0.0, ce: 0.26696231961250305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  10%|▉         | 750/7794 [02:09<20:06,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.17437680065631866, mse: 0.0, ce: 0.17437680065631866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  13%|█▎        | 1000/7794 [02:52<19:27,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.3272581398487091, mse: 0.0, ce: 0.3272581398487091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  16%|█▌        | 1250/7794 [03:35<18:44,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.2980583608150482, mse: 0.0, ce: 0.2980583608150482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  19%|█▉        | 1500/7794 [04:18<17:59,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.2964808940887451, mse: 0.0, ce: 0.2964808940887451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  22%|██▏       | 1750/7794 [05:01<17:22,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.5131774544715881, mse: 0.0, ce: 0.5131774544715881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  26%|██▌       | 2000/7794 [05:44<16:31,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.26165807247161865, mse: 0.0, ce: 0.26165807247161865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  29%|██▉       | 2250/7794 [06:27<15:44,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.34603697061538696, mse: 0.0, ce: 0.34603697061538696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  32%|███▏      | 2500/7794 [07:10<15:05,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.3343800902366638, mse: 0.0, ce: 0.3343800902366638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  35%|███▌      | 2750/7794 [07:52<14:20,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.3534228801727295, mse: 0.0, ce: 0.3534228801727295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  38%|███▊      | 3000/7794 [08:35<13:37,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.326313853263855, mse: 0.0, ce: 0.326313853263855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  42%|████▏     | 3250/7794 [09:18<13:02,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.2526393234729767, mse: 0.0, ce: 0.2526393234729767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  45%|████▍     | 3500/7794 [10:01<12:20,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.29640164971351624, mse: 0.0, ce: 0.29640164971351624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  48%|████▊     | 3750/7794 [10:44<11:34,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.3402020037174225, mse: 0.0, ce: 0.3402020037174225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  51%|█████▏    | 4000/7794 [11:27<10:50,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.24600699543952942, mse: 0.0, ce: 0.24600699543952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  55%|█████▍    | 4250/7794 [12:10<10:11,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.23261849582195282, mse: 0.0, ce: 0.23261849582195282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  58%|█████▊    | 4500/7794 [12:53<09:30,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.5491899251937866, mse: 0.0, ce: 0.5491899251937866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  61%|██████    | 4750/7794 [13:36<08:43,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.17952102422714233, mse: 0.0, ce: 0.17952102422714233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  64%|██████▍   | 5000/7794 [14:19<08:01,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.293037086725235, mse: 0.0, ce: 0.293037086725235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  67%|██████▋   | 5250/7794 [15:02<07:19,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.2918698191642761, mse: 0.0, ce: 0.2918698191642761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  71%|███████   | 5500/7794 [15:45<06:33,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.41294559836387634, mse: 0.0, ce: 0.41294559836387634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  74%|███████▍  | 5750/7794 [16:28<05:53,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.26378342509269714, mse: 0.0, ce: 0.26378342509269714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  77%|███████▋  | 6000/7794 [17:11<05:07,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.29532843828201294, mse: 0.0, ce: 0.29532843828201294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  80%|████████  | 6250/7794 [17:54<04:26,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.39727577567100525, mse: 0.0, ce: 0.39727577567100525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  83%|████████▎ | 6500/7794 [18:37<03:42,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.30034324526786804, mse: 0.0, ce: 0.30034324526786804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  87%|████████▋ | 6750/7794 [19:20<02:58,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.2840483486652374, mse: 0.0, ce: 0.2840483486652374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  90%|████████▉ | 7000/7794 [20:03<02:15,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.44323810935020447, mse: 0.0, ce: 0.44323810935020447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  93%|█████████▎| 7250/7794 [20:46<01:33,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.38260412216186523, mse: 0.0, ce: 0.38260412216186523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  96%|█████████▌| 7500/7794 [21:29<00:50,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.4733318090438843, mse: 0.0, ce: 0.4733318090438843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  99%|█████████▉| 7750/7794 [22:12<00:07,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.4221550524234772, mse: 0.0, ce: 0.4221550524234772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 7794/7794 [22:20<00:00,  5.81it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:01<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.3358 (MSE: 0.0000, CE: 0.3358)\n",
      "Val Total Loss: 0.2507 (MSE: 0.0000, CE: 0.2507)\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.2507\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:   3%|▎         | 250/7794 [00:43<21:40,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 0.27902504801750183, mse: 0.0, ce: 0.27902504801750183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:   6%|▋         | 500/7794 [01:26<21:01,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 0.20413123071193695, mse: 0.0, ce: 0.20413123071193695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  10%|▉         | 750/7794 [02:09<20:12,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.27219945192337036, mse: 0.0, ce: 0.27219945192337036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  13%|█▎        | 1000/7794 [02:52<19:37,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.3125012516975403, mse: 0.0, ce: 0.3125012516975403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  16%|█▌        | 1250/7794 [03:35<18:50,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.39672690629959106, mse: 0.0, ce: 0.39672690629959106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  19%|█▉        | 1500/7794 [04:18<18:07,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.4139100909233093, mse: 0.0, ce: 0.4139100909233093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  22%|██▏       | 1750/7794 [05:01<17:15,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.3353640139102936, mse: 0.0, ce: 0.3353640139102936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  26%|██▌       | 2000/7794 [05:45<16:37,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.22940339148044586, mse: 0.0, ce: 0.22940339148044586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  29%|██▉       | 2250/7794 [06:28<15:58,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.26748690009117126, mse: 0.0, ce: 0.26748690009117126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  32%|███▏      | 2500/7794 [07:11<15:13,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.30196669697761536, mse: 0.0, ce: 0.30196669697761536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  35%|███▌      | 2750/7794 [07:54<14:29,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.3562923073768616, mse: 0.0, ce: 0.3562923073768616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  38%|███▊      | 3000/7794 [08:37<13:52,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.2870573103427887, mse: 0.0, ce: 0.2870573103427887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  42%|████▏     | 3250/7794 [09:20<13:02,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.19751758873462677, mse: 0.0, ce: 0.19751758873462677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  45%|████▍     | 3500/7794 [10:03<12:14,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.32366302609443665, mse: 0.0, ce: 0.32366302609443665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  48%|████▊     | 3750/7794 [10:46<11:37,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.30602365732192993, mse: 0.0, ce: 0.30602365732192993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  51%|█████▏    | 4000/7794 [11:29<10:52,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.2765829861164093, mse: 0.0, ce: 0.2765829861164093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  55%|█████▍    | 4250/7794 [12:12<10:16,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.2699531316757202, mse: 0.0, ce: 0.2699531316757202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  58%|█████▊    | 4500/7794 [12:55<09:27,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.2605077922344208, mse: 0.0, ce: 0.2605077922344208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  61%|██████    | 4750/7794 [13:38<08:43,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.15949316322803497, mse: 0.0, ce: 0.15949316322803497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  64%|██████▍   | 5000/7794 [14:21<07:57,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.23554372787475586, mse: 0.0, ce: 0.23554372787475586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  67%|██████▋   | 5250/7794 [15:04<07:15,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.19814276695251465, mse: 0.0, ce: 0.19814276695251465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  71%|███████   | 5500/7794 [15:46<06:30,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.19781453907489777, mse: 0.0, ce: 0.19781453907489777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  74%|███████▍  | 5750/7794 [16:29<05:49,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.3288816809654236, mse: 0.0, ce: 0.3288816809654236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  77%|███████▋  | 6000/7794 [17:12<05:07,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.1729147881269455, mse: 0.0, ce: 0.1729147881269455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  80%|████████  | 6250/7794 [17:55<04:26,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.23858824372291565, mse: 0.0, ce: 0.23858824372291565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  83%|████████▎ | 6500/7794 [18:38<03:42,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.11731515824794769, mse: 0.0, ce: 0.11731515824794769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  87%|████████▋ | 6750/7794 [19:22<03:01,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.25534287095069885, mse: 0.0, ce: 0.25534287095069885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  90%|████████▉ | 7000/7794 [20:05<02:16,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.15243038535118103, mse: 0.0, ce: 0.15243038535118103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  93%|█████████▎| 7250/7794 [20:48<01:33,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.2936641573905945, mse: 0.0, ce: 0.2936641573905945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  96%|█████████▌| 7500/7794 [21:31<00:50,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.3346189260482788, mse: 0.0, ce: 0.3346189260482788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  99%|█████████▉| 7750/7794 [22:14<00:07,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.21741734445095062, mse: 0.0, ce: 0.21741734445095062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 7794/7794 [22:22<00:00,  5.81it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:01<00:00, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.2876 (MSE: 0.0000, CE: 0.2876)\n",
      "Val Total Loss: 0.2650 (MSE: 0.0000, CE: 0.2650)\n",
      "Learning Rate: 0.000100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/5:   3%|▎         | 250/7794 [00:42<21:24,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/7794:\n",
      "total_loss: 0.3248652517795563, mse: 0.0, ce: 0.3248652517795563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:   6%|▋         | 500/7794 [01:25<20:51,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/7794:\n",
      "total_loss: 0.4007319509983063, mse: 0.0, ce: 0.4007319509983063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  10%|▉         | 750/7794 [02:08<19:58,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/7794:\n",
      "total_loss: 0.21813498437404633, mse: 0.0, ce: 0.21813498437404633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  13%|█▎        | 1000/7794 [02:51<19:27,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/7794:\n",
      "total_loss: 0.2685067355632782, mse: 0.0, ce: 0.2685067355632782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  16%|█▌        | 1250/7794 [03:34<18:38,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/7794:\n",
      "total_loss: 0.15474452078342438, mse: 0.0, ce: 0.15474452078342438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  19%|█▉        | 1500/7794 [04:17<18:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/7794:\n",
      "total_loss: 0.3097650408744812, mse: 0.0, ce: 0.3097650408744812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  22%|██▏       | 1750/7794 [05:00<17:13,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/7794:\n",
      "total_loss: 0.2228013426065445, mse: 0.0, ce: 0.2228013426065445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  26%|██▌       | 2000/7794 [05:43<16:38,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/7794:\n",
      "total_loss: 0.12676292657852173, mse: 0.0, ce: 0.12676292657852173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  29%|██▉       | 2250/7794 [06:26<15:59,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/7794:\n",
      "total_loss: 0.24102245271205902, mse: 0.0, ce: 0.24102245271205902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  32%|███▏      | 2500/7794 [07:09<15:07,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/7794:\n",
      "total_loss: 0.23747645318508148, mse: 0.0, ce: 0.23747645318508148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  35%|███▌      | 2750/7794 [07:52<14:33,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/7794:\n",
      "total_loss: 0.1980520784854889, mse: 0.0, ce: 0.1980520784854889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  38%|███▊      | 3000/7794 [08:34<13:46,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/7794:\n",
      "total_loss: 0.36421695351600647, mse: 0.0, ce: 0.36421695351600647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  42%|████▏     | 3250/7794 [09:17<13:08,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/7794:\n",
      "total_loss: 0.23085744678974152, mse: 0.0, ce: 0.23085744678974152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  45%|████▍     | 3500/7794 [10:01<12:16,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/7794:\n",
      "total_loss: 0.1288127899169922, mse: 0.0, ce: 0.1288127899169922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  48%|████▊     | 3750/7794 [10:44<11:33,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/7794:\n",
      "total_loss: 0.3254624903202057, mse: 0.0, ce: 0.3254624903202057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  51%|█████▏    | 4000/7794 [11:27<10:57,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/7794:\n",
      "total_loss: 0.23803794384002686, mse: 0.0, ce: 0.23803794384002686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  55%|█████▍    | 4250/7794 [12:10<10:10,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/7794:\n",
      "total_loss: 0.23782725632190704, mse: 0.0, ce: 0.23782725632190704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  58%|█████▊    | 4500/7794 [12:53<09:27,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/7794:\n",
      "total_loss: 0.33139848709106445, mse: 0.0, ce: 0.33139848709106445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  61%|██████    | 4750/7794 [13:36<08:47,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/7794:\n",
      "total_loss: 0.31300613284111023, mse: 0.0, ce: 0.31300613284111023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  64%|██████▍   | 5000/7794 [14:20<08:05,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/7794:\n",
      "total_loss: 0.12538646161556244, mse: 0.0, ce: 0.12538646161556244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  67%|██████▋   | 5250/7794 [15:03<07:18,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/7794:\n",
      "total_loss: 0.3010265827178955, mse: 0.0, ce: 0.3010265827178955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  71%|███████   | 5500/7794 [15:46<06:39,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/7794:\n",
      "total_loss: 0.22625389695167542, mse: 0.0, ce: 0.22625389695167542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  74%|███████▍  | 5750/7794 [16:29<05:52,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/7794:\n",
      "total_loss: 0.33095985651016235, mse: 0.0, ce: 0.33095985651016235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  77%|███████▋  | 6000/7794 [17:12<05:08,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/7794:\n",
      "total_loss: 0.1846737116575241, mse: 0.0, ce: 0.1846737116575241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  80%|████████  | 6250/7794 [17:55<04:26,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/7794:\n",
      "total_loss: 0.31680700182914734, mse: 0.0, ce: 0.31680700182914734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  83%|████████▎ | 6500/7794 [18:39<03:43,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/7794:\n",
      "total_loss: 0.22530271112918854, mse: 0.0, ce: 0.22530271112918854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  87%|████████▋ | 6750/7794 [19:22<03:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/7794:\n",
      "total_loss: 0.32564473152160645, mse: 0.0, ce: 0.32564473152160645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  90%|████████▉ | 7000/7794 [20:05<02:18,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/7794:\n",
      "total_loss: 0.3079729974269867, mse: 0.0, ce: 0.3079729974269867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  93%|█████████▎| 7250/7794 [20:48<01:34,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/7794:\n",
      "total_loss: 0.19398263096809387, mse: 0.0, ce: 0.19398263096809387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  96%|█████████▌| 7500/7794 [21:32<00:51,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/7794:\n",
      "total_loss: 0.26854437589645386, mse: 0.0, ce: 0.26854437589645386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  99%|█████████▉| 7750/7794 [22:15<00:07,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/7794:\n",
      "total_loss: 0.3401208519935608, mse: 0.0, ce: 0.3401208519935608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 7794/7794 [22:23<00:00,  5.80it/s]\n",
      "Validating: 100%|██████████| 16/16 [00:01<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Train Total Loss: 0.2496 (MSE: 0.0000, CE: 0.2496)\n",
      "Val Total Loss: 0.1973 (MSE: 0.0000, CE: 0.1973)\n",
      "Learning Rate: 0.000100\n",
      "New best model saved with val loss: 0.1973\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pconfig = PointNetConfig(\n",
    "    embeddingSize=n_embd,\n",
    "    numberofPoints=numPoints,\n",
    "    numberofVars=numVars,\n",
    "    numberofYs=numYs,\n",
    ")\n",
    "\n",
    "model = SymbolicGaussianDiffusion(\n",
    "    tnet_config=pconfig,  \n",
    "    vocab_size=train_dataset.vocab_size,\n",
    "    max_seq_len=blockSize,\n",
    "    padding_idx=train_dataset.paddingID,\n",
    "    max_num_vars=9,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    n_embd=n_embd,\n",
    "    timesteps=timesteps,\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    ce_weight=1.0  \n",
    ")\n",
    "\n",
    "train_single_gpu(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    num_epochs=num_epochs,\n",
    "    save_every=2,\n",
    "    batch_size=batch_size,\n",
    "    timesteps=timesteps,\n",
    "    learning_rate=learning_rate\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6977314,
     "sourceId": 11178716,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 282263,
     "modelInstanceId": 261112,
     "sourceId": 306062,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 290784,
     "modelInstanceId": 269794,
     "sourceId": 319741,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 290853,
     "modelInstanceId": 269860,
     "sourceId": 319828,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6722.149967,
   "end_time": "2025-04-08T01:12:02.653506",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T23:20:00.503539",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
