{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b33175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_dataset, lossFunc, relativeErr\n",
    "from models import SymbolicDiffusion, PointNetConfig\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee353d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 32             \n",
    "timesteps = 1000         \n",
    "batch_size = 1024\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "blockSize = 32\n",
    "numVars = 1\n",
    "numYs = 1\n",
    "numPoints = 250\n",
    "const_range = [-2.1, 2.1]\n",
    "trainRange = [-3.0, 3.0]\n",
    "decimals = 8\n",
    "addVars = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset, testText = load_dataset(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_test.json\")\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41886624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "pconfig = PointNetConfig(\n",
    "    embeddingSize=n_embd,\n",
    "    numberofPoints=250,\n",
    "    numberofVars=1,\n",
    "    numberofYs=1,\n",
    ")\n",
    "model = SymbolicDiffusion(\n",
    "    pconfig=pconfig,\n",
    "    vocab_size=50,\n",
    "    max_seq_len=blockSize,\n",
    "    padding_idx=test_dataset.paddingID,\n",
    "    max_num_vars=9,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    n_embd=n_embd,\n",
    "    timesteps=timesteps,\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    ").to(device)\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/models/symbolic_diffusion_model.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_model(model, test_loader, test_dataset, device):\n",
    "    results = {'target': [], 'predicted': [], 'error': []}\n",
    "    \n",
    "    for batch_idx, (_, tokens, points, variables) in enumerate(test_loader):\n",
    "        points = points.to(device)    # [B, 2, 250]\n",
    "        tokens = tokens.to(device)    # [B, L]\n",
    "        variables = variables.to(device)  # [B]\n",
    "\n",
    "        generated_tokens = model.sample(points, variables, device)  \n",
    "\n",
    "        for i in range(batch_size):  \n",
    "            # Ground truth\n",
    "            gt_tokens = tokens[i].cpu().numpy()\n",
    "            gt_expr = ''.join(test_dataset.itos[int(idx)] for idx in gt_tokens)\n",
    "            gt_expr = gt_expr.strip(test_dataset.paddingToken).strip('<').strip('>').split(':')[-1]\n",
    "\n",
    "            # Predicted\n",
    "            pred_tokens = generated_tokens[i].cpu().numpy()\n",
    "            predicted = ''.join(test_dataset.itos[int(idx)] for idx in pred_tokens if int(idx) < len(test_dataset.itos))\n",
    "            predicted = predicted.strip(test_dataset.paddingToken).strip('<').strip('>').split(':')[-1]\n",
    "            predicted = predicted.replace('Ce', 'C*e')\n",
    "\n",
    "            # train a regressor to find the constants (too slow)\n",
    "            c = [1.0 for i,x in enumerate(predicted) if x=='C'] # initialize coefficients as 1\n",
    "            # c[-1] = 0 # initialize the constant as zero\n",
    "            b = [(-2,2) for i,x in enumerate(predicted) if x=='C']  # bounds on variables\n",
    "            try:\n",
    "                if len(c) != 0:\n",
    "                    # This is the bottleneck in our algorithm\n",
    "                    # for easier comparison, we are using minimize package  \n",
    "                    cHat = minimize(lossFunc, c, #bounds=b,\n",
    "                                args=(predicted, t['X'], t['Y'])) \n",
    "\n",
    "                    predicted = predicted.replace('C','{}').format(*cHat.x)\n",
    "            except ValueError:\n",
    "                raise 'Err: Wrong Equation {}'.format(predicted)\n",
    "            except Exception as e:\n",
    "                raise 'Err: Wrong Equation {}, Err: {}'.format(predicted, e)\n",
    "\n",
    "            Ys = [] #t['YT']\n",
    "            Yhats = []\n",
    "            for xs in t['XT']:\n",
    "                try:\n",
    "                    eqTmp = gt_expr + '' # copy eq\n",
    "                    eqTmp = eqTmp.replace(' ','')\n",
    "                    eqTmp = eqTmp.replace('\\n','')\n",
    "                    for i,x in enumerate(xs):\n",
    "                        # replace xi with the value in the eq\n",
    "                        eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                        if ',' in eqTmp:\n",
    "                            assert 'There is a , in the equation!'\n",
    "                    YEval = eval(eqTmp)\n",
    "                    # YEval = 0 if np.isnan(YEval) else YEval\n",
    "                    # YEval = 100 if np.isinf(YEval) else YEval\n",
    "                except:\n",
    "                    print('TA: For some reason, we used the default value. Eq:{}'.format(eqTmp))\n",
    "                    print(i)\n",
    "                    raise\n",
    "                    continue # if there is any point in the target equation that has any problem, ignore it\n",
    "                    YEval = 100 #TODO: Maybe I have to punish the model for each wrong template not for each point\n",
    "                Ys.append(YEval)\n",
    "                try:\n",
    "                    eqTmp = predicted + '' # copy eq\n",
    "                    eqTmp = eqTmp.replace(' ','')\n",
    "                    eqTmp = eqTmp.replace('\\n','')\n",
    "                    for i,x in enumerate(xs):\n",
    "                        # replace xi with the value in the eq\n",
    "                        eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
    "                        if ',' in eqTmp:\n",
    "                            assert 'There is a , in the equation!'\n",
    "                    Yhat = eval(eqTmp)\n",
    "                    # Yhat = 0 if np.isnan(Yhat) else Yhat\n",
    "                    # Yhat = 100 if np.isinf(Yhat) else Yhat\n",
    "                except:\n",
    "                    print('PR: For some reason, we used the default value. Eq:{}'.format(eqTmp))\n",
    "                    Yhat = 100\n",
    "                Yhats.append(Yhat)\n",
    "            err = relativeErr(Ys,Yhats, info=True)\n",
    "\n",
    "\n",
    "            results['target'].append(gt_expr)\n",
    "            results['predicted'].append(predicted)\n",
    "            results['error'].append(err)\n",
    "\n",
    "            print(f\"\\nSample {batch_idx * batch_size + i + 1}:\")\n",
    "            print(f\"Target: {gt_expr}\")\n",
    "            print(f\"Predicted: {predicted}\")\n",
    "            print(f\"Relative Error: {err:.6f}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing SymbolicDiffusion model...\")\n",
    "test_results = test_model(model, test_loader, test_dataset, device, num_samples=5)\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "for i in range(len(test_results['target'])):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Target: {test_results['target'][i]}\")\n",
    "    print(f\"  Predicted: {test_results['predicted'][i]}\")\n",
    "    print(f\"  Error: {test_results['error'][i]:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s946_env (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
