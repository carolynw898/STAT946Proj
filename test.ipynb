{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolynw898/STAT946Proj/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3CmZzXN5ny5A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CmZzXN5ny5A",
        "outputId": "e9f66902-fee7-46ca-843d-d91f6af53e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "aee353d1",
      "metadata": {
        "id": "aee353d1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "n_embd = 512\n",
        "timesteps = 1000\n",
        "batch_size = 256\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 5\n",
        "blockSize = 32\n",
        "testBlockSize = 400\n",
        "numVars = 1\n",
        "numYs = 1\n",
        "numPoints = 250\n",
        "target = 'Skeleton'\n",
        "const_range = [-2.1, 2.1]\n",
        "trainRange = [-3.0, 3.0]\n",
        "decimals = 8\n",
        "addVars = False\n",
        "maxNumFiles = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataDir = \"/content/drive/MyDrive/Colab/STAT946_proj/data\"\n",
        "dataFolder = \"1_var_dataset\""
      ],
      "metadata": {
        "id": "mHh9P6w6aZjV"
      },
      "id": "mHh9P6w6aZjV",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "JvNAveGHCEae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvNAveGHCEae",
        "outputId": "81ac835d-85b8-48b2-8984-22fc03d6d574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 498795 examples, 27 unique.\n",
            "id:327942\n",
            "outputs:C*cos(C*exp(C*x1)+C*cos(C*x1+C))+C>_____\n",
            "variables:1\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import glob\n",
        "from utils import processDataFiles, CharDataset, tokenize_equation\n",
        "import random\n",
        "import json\n",
        "\n",
        "path = '{}/{}/Train/*.json'.format(dataDir, dataFolder)\n",
        "files = glob.glob(path)[:maxNumFiles]\n",
        "text = processDataFiles(files)\n",
        "text = text.split('\\n') # convert the raw text to a set of examples\n",
        "# skeletons = []\n",
        "skeletons = [json.loads(item)['Skeleton'] for item in text if item.strip()]\n",
        "all_tokens = set()\n",
        "for eq in skeletons:\n",
        "    all_tokens.update(tokenize_equation(eq))\n",
        "integers = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
        "all_tokens.update(integers)  # add all integers to the token set\n",
        "tokens = sorted(list(all_tokens) + ['_', 'T', '<', '>', ':'])  # special tokens\n",
        "trainText = text[:-1] if len(text[-1]) == 0 else text\n",
        "random.shuffle(trainText) # shuffle the dataset, it's important specailly for the combined number of variables experiment\n",
        "train_dataset = CharDataset(trainText, blockSize, tokens=tokens, numVars=numVars,\n",
        "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
        "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
        "\n",
        "idx = np.random.randint(train_dataset.__len__())\n",
        "inputs, outputs, points, variables = train_dataset.__getitem__(idx)\n",
        "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
        "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
        "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "Xnj3g0a0_5R1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnj3g0a0_5R1",
        "outputId": "c4cf2114-3ad0-4477-afb0-64b9ee842824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 967 examples, 27 unique.\n",
            "tensor(-2.8461) tensor(2.5926)\n",
            "id:384\n",
            "outputs:C*sin(C*x1+C)+C>___________________\n",
            "variables:1\n"
          ]
        }
      ],
      "source": [
        "path = '{}/{}/Test/*.json'.format(dataDir,dataFolder)\n",
        "files = glob.glob(path)\n",
        "textTest = processDataFiles([files[0]])\n",
        "textTest = textTest.split('\\n') # convert the raw text to a set of examples\n",
        "test_dataset = CharDataset(textTest, blockSize, tokens=tokens, numVars=numVars,\n",
        "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
        "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
        "\n",
        "# print a random sample\n",
        "idx = np.random.randint(test_dataset.__len__())\n",
        "inputs, outputs, points, variables = test_dataset.__getitem__(idx)\n",
        "print(points.min(), points.max())\n",
        "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
        "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
        "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "itNSUyzeNVgV",
      "metadata": {
        "id": "itNSUyzeNVgV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "from scipy.optimize import minimize\n",
        "from math import log\n",
        "import math\n",
        "from utils import relativeErr, lossFunc\n",
        "\n",
        "SAFE_GLOBALS = {\n",
        "    'sin': math.sin,\n",
        "    'cos': math.cos,\n",
        "    'tan': math.tan,\n",
        "    'log': math.log,\n",
        "    'exp': math.exp,\n",
        "    'sqrt': math.sqrt,\n",
        "    'abs': abs,\n",
        "    'pow': pow,\n",
        "    '__builtins__': {}\n",
        "}\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model(model, test_loader, textTest, train_dataset, device):\n",
        "    results = {\"target\": [], \"target_skeleton\": [], \"predicted_skeleton\": [], \"predicted\": [], \"error\": []}\n",
        "    for batch_idx, (_, tokens, points, variables) in enumerate(test_loader):\n",
        "        points = points.to(device)\n",
        "        tokens = tokens.to(device)\n",
        "        variables = variables.to(device)\n",
        "        B = points.shape[0]\n",
        "        predicted_skeletons = model.sample(points, variables, train_dataset, B)\n",
        "\n",
        "        for i in range(B):\n",
        "            t = json.loads(textTest[batch_idx * test_loader.batch_size + i])\n",
        "            eq = t[\"EQ\"]\n",
        "\n",
        "            eq_skeleton = ''.join([train_dataset.itos[int(i)] for i in tokens[0]])\n",
        "            eq_skeleton = eq_skeleton.strip(train_dataset.paddingToken).split('>')\n",
        "            eq_skeleton = eq_skeleton[0] #if len(eq[0])>=1 else eq[1]\n",
        "            eq_skeleton = eq_skeleton.strip('<').strip(\">\")\n",
        "\n",
        "            # Predicted\n",
        "            predicted_skeleton = predicted_skeletons[i]\n",
        "            predicted = predicted_skeleton\n",
        "\n",
        "\n",
        "\n",
        "            # Fit constants\n",
        "            c = [1.0 for i,x in enumerate(predicted) if x=='C'] # initialize coefficients as 1\n",
        "            # c[-1] = 0 # initialize the constant as zero\n",
        "            b = [(-2,2) for i,x in enumerate(predicted) if x=='C']  # bounds on variables\n",
        "            try:\n",
        "                if len(c) != 0:\n",
        "                    # This is the bottleneck in our algorithm\n",
        "                    # for easier comparison, we are using minimize package\n",
        "                    cHat = minimize(lossFunc, c, #bounds=b,\n",
        "                                args=(predicted, t['X'], t['Y']))\n",
        "\n",
        "                    predicted = predicted.replace('C','{}').format(*cHat.x)\n",
        "            except ValueError:\n",
        "                raise 'Err: Wrong Equation {}'.format(predicted)\n",
        "            except Exception as e:\n",
        "                raise 'Err: Wrong Equation {}, Err: {}'.format(predicted, e)\n",
        "\n",
        "            Ys = [] #t['YT']\n",
        "            Yhats = []\n",
        "            for xs in t['XT']:\n",
        "                try:\n",
        "                    eqTmp = eq + '' # copy eq\n",
        "                    eqTmp = eqTmp.replace(' ','')\n",
        "                    eqTmp = eqTmp.replace('\\n','')\n",
        "                    for i,x in enumerate(xs):\n",
        "                        # replace xi with the value in the eq\n",
        "                        eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
        "                        if ',' in eqTmp:\n",
        "                             raise ValueError('There is a , in the equation!')\n",
        "                    YEval = eval(eqTmp, SAFE_GLOBALS)\n",
        "                    #YEval = 0 if np.isnan(YEval) else YEval\n",
        "                    #YEval = 100 if np.isinf(YEval) else YEval\n",
        "                except:\n",
        "                    #print('TA: For some reason, we used the default value. Eq:{}'.format(eqTmp))\n",
        "                    #print(i)\n",
        "                    #raise\n",
        "                    continue # if there is any point in the target equation that has any problem, ignore it\n",
        "                    YEval = 100 #TODO: Maybe I have to punish the model for each wrong template not for each point\n",
        "                Ys.append(YEval)\n",
        "                try:\n",
        "                    eqTmp = predicted + '' # copy eq\n",
        "                    eqTmp = eqTmp.replace(' ','')\n",
        "                    eqTmp = eqTmp.replace('\\n','')\n",
        "                    for i,x in enumerate(xs):\n",
        "                        # replace xi with the value in the eq\n",
        "                        eqTmp = eqTmp.replace('x{}'.format(i+1), str(x))\n",
        "                        if ',' in eqTmp:\n",
        "                            assert 'There is a , in the equation!'\n",
        "                    Yhat = eval(eqTmp, SAFE_GLOBALS)\n",
        "                    # Yhat = 0 if np.isnan(Yhat) else Yhat\n",
        "                    # Yhat = 100 if np.isinf(Yhat) else Yhat\n",
        "                except:\n",
        "                    #print('PR: For some reason, we used the default value. Eq:{}'.format(eqTmp))\n",
        "                    Yhat = 100\n",
        "                Yhats.append(Yhat)\n",
        "            err = relativeErr(Ys,Yhats, info=True)\n",
        "\n",
        "            print(f'\\nTarget: {eq_skeleton}')\n",
        "            print(f'Predicted: {predicted_skeleton}')\n",
        "            print('Err:{}'.format(err))\n",
        "            print('-'*10)\n",
        "\n",
        "            # Compute error and store results\n",
        "            err = relativeErr(Ys, Yhats, info=True)\n",
        "            results[\"target\"].append(eq)\n",
        "            results[\"target_skeleton\"].append(eq_skeleton)\n",
        "            results[\"predicted_skeleton\"].append(predicted_skeleton)\n",
        "            results[\"predicted\"].append(predicted)\n",
        "            results[\"error\"].append(err)\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a8306e68",
      "metadata": {
        "id": "a8306e68"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_and_save_results(resultDict, fName, pconf, titleTemplate, textTest, modelKey='DiffuSym'):\n",
        "    if isinstance(resultDict, dict):\n",
        "        num_eqns = len(resultDict[fName][modelKey]['err'])\n",
        "        num_vars = pconf.numberofVars\n",
        "        title = titleTemplate.format(num_eqns, num_vars)\n",
        "\n",
        "        models = list(key for key in resultDict[fName].keys() if len(resultDict[fName][key]['err'])==num_eqns)\n",
        "        lists_of_error_scores = [resultDict[fName][key]['err'] for key in models if len(resultDict[fName][key]['err'])==num_eqns]\n",
        "        linestyles = [\"-\",\"dashdot\",\"dotted\",\"--\"]\n",
        "\n",
        "        eps = 0.00001\n",
        "        y, x, _ = plt.hist([np.log([max(min(x+eps, 1e5),1e-5) for x in e]) for e in lists_of_error_scores],\n",
        "                        label=models,\n",
        "                        cumulative=True,\n",
        "                        histtype=\"step\",\n",
        "                        bins=2000,\n",
        "                        density=True,\n",
        "                        log=False)\n",
        "        y = np.expand_dims(y,0)\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for idx, m in enumerate(models):\n",
        "            plt.plot(x[:-1],\n",
        "                y[idx] * 100,\n",
        "                linestyle=linestyles[idx],\n",
        "                label=m)\n",
        "\n",
        "        plt.legend(loc=\"upper left\")\n",
        "        plt.title(title)\n",
        "        plt.xlabel(\"Log of Relative Mean Square Error\")\n",
        "        plt.ylabel(\"Normalized Cumulative Frequency\")\n",
        "\n",
        "        name = '{}.png'.format(fName.split('.txt')[0])\n",
        "        plt.savefig(name)\n",
        "\n",
        "        with open(fName, 'w', encoding=\"utf-8\") as o:\n",
        "            for i in range(num_eqns):\n",
        "                err = resultDict[fName][modelKey]['err'][i]\n",
        "                eq = resultDict[fName][modelKey]['trg'][i]\n",
        "                predicted = resultDict[fName][modelKey]['prd'][i]\n",
        "                print('Test Case {}.'.format(i))\n",
        "                print('Target:{}\\nSkeleton:{}'.format(eq, predicted))\n",
        "                print('Err:{}'.format(err))\n",
        "                print('') # just an empty line\n",
        "\n",
        "\n",
        "                o.write('Test Case {}/{}.\\n'.format(i,len(textTest)-1))\n",
        "\n",
        "                o.write('{}\\n'.format(eq))\n",
        "                o.write('{}:\\n'.format(modelKey))\n",
        "                o.write('{}\\n'.format(predicted))\n",
        "\n",
        "                o.write('{}\\n{}\\n\\n'.format(\n",
        "                                        predicted,\n",
        "                                        err\n",
        "                                        ))\n",
        "\n",
        "                print('Avg Err:{}'.format(np.mean(resultDict[fName][modelKey]['err'])))\n",
        "\n",
        "def run_and_plot(model, fName, test_loader, textTest, train_dataset, device, pconf=None):\n",
        "    \"\"\"\n",
        "    Run test_model and format results for plot_and_save_results, ensuring one figure.\n",
        "    \"\"\"\n",
        "\n",
        "    results = test_model(model, test_loader, textTest, train_dataset, device)\n",
        "\n",
        "    modelKey = 'DiffuSym'\n",
        "    resultDict = {\n",
        "        fName: {\n",
        "            modelKey: {\n",
        "                'err': results['error'],\n",
        "                'trg': results['target'],\n",
        "                'prd': results['predicted']\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    titleTemplate = \"{} equations of {} variables - Benchmark\"\n",
        "    plot_and_save_results(resultDict, fName, pconf, titleTemplate, textTest, modelKey=modelKey)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e676e953",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "e676e953",
        "outputId": "e7dacb0f-17c5-4a06-b408-ec7f9e1a60eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ef55c19e5c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1582, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
            "    ready = selector.select(timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-19a44d0110b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mfName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab/STAT946_proj/results/1_var_tnet.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_and_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-04ae9b7e6762>\u001b[0m in \u001b[0;36mrun_and_plot\u001b[0;34m(model, fName, test_loader, textTest, train_dataset, device, pconf)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \"\"\"\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mmodelKey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DiffuSym'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d9617a370538>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader, textTest, train_dataset, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpredicted_skeletons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, points, variables, train_dataset, batch_size, ddim_step, guidance_scale)\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n\u001b[1;32m    321\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition_uncodition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mx_condition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [B, L, n_embd]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36mp_sample\u001b[0;34m(self, x, t, t_next, condition)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_next\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from models import SymbolicGaussianDiffusion, PointNetConfig\n",
        "\n",
        "pconfig = PointNetConfig(\n",
        "    embeddingSize=n_embd,\n",
        "    numberofPoints=numPoints,\n",
        "    numberofVars=numVars,\n",
        "    numberofYs=numYs,\n",
        ")\n",
        "model = SymbolicGaussianDiffusion(\n",
        "    tnet_config=pconfig,\n",
        "    vocab_size=train_dataset.vocab_size,\n",
        "    max_seq_len=32,\n",
        "    padding_idx=test_dataset.paddingID,\n",
        "    max_num_vars=9,\n",
        "    n_layer=4,\n",
        "    n_head=4,\n",
        "    n_embd=n_embd,\n",
        "    timesteps=timesteps,\n",
        "    beta_start=0.0001,\n",
        "    beta_end=0.02,\n",
        "    set_transformer=False,\n",
        ").to(device)\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Colab/STAT946_proj/models/diffusym/1Var_tNet_best_model.pth\"\n",
        "model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
        "model.eval()\n",
        "fName=\"/content/drive/MyDrive/Colab/STAT946_proj/results/1_var_tnet.txt\"\n",
        "test_results = run_and_plot(model, fName, test_loader, textTest, train_dataset, device, pconfig)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}