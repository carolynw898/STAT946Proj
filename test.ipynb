{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolynw898/STAT946Proj/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "45b33175",
      "metadata": {
        "id": "45b33175"
      },
      "outputs": [],
      "source": [
        "from utils import load_dataset, lossFunc, relativeErr\n",
        "from models import SymbolicDiffusion, PointNetConfig\n",
        "import torch\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3CmZzXN5ny5A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CmZzXN5ny5A",
        "outputId": "780f8807-868a-402e-be35-d1b6e660b398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "aee353d1",
      "metadata": {
        "id": "aee353d1"
      },
      "outputs": [],
      "source": [
        "n_embd = 512\n",
        "timesteps = 1000\n",
        "batch_size = 4\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 10\n",
        "blockSize = 32\n",
        "testBlockSize = 400\n",
        "numVars = 1\n",
        "numYs = 1\n",
        "numPoints = 250\n",
        "target = 'Skeleton'\n",
        "const_range = [-2.1, 2.1]\n",
        "trainRange = [-3.0, 3.0]\n",
        "decimals = 8\n",
        "addVars = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "41886624",
      "metadata": {
        "id": "41886624"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "from scipy.optimize import minimize\n",
        "from math import log\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model(model, test_loader, test_dataset, textTest, train_dataset, device):\n",
        "    results = {'target': [], 'predicted': [], 'error': []}\n",
        "\n",
        "    for batch_idx, (_, tokens, points, variables) in enumerate(test_loader):\n",
        "        points = points.to(device)    # [B, 2, 250]\n",
        "        tokens = tokens.to(device)    # [B, L]\n",
        "        variables = variables.to(device)  # [B]\n",
        "\n",
        "        generated_tokens = model.sample(points, variables, device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Ground truth\n",
        "            eq = ''.join([train_dataset.itos[int(i)] for i in tokens[0]])\n",
        "            eq = eq.strip(train_dataset.paddingToken).split('>')\n",
        "            eq = eq[0] #if len(eq[0])>=1 else eq[1]\n",
        "            eq = eq.strip('<').strip(\">\")\n",
        "            print(eq)\n",
        "\n",
        "            # Predicted\n",
        "            pred_tokens = generated_tokens[i].cpu().numpy()\n",
        "            predicted = ''.join(train_dataset.itos[int(idx)] for idx in pred_tokens if int(idx) < len(train_dataset.itos))\n",
        "            predicted = predicted.strip(train_dataset.paddingToken).strip('<').strip('>').split(':')[-1]\n",
        "            predicted = predicted.replace('Ce', 'C*e')\n",
        "\n",
        "            print(f'predicted skeleton: {predicted}')\n",
        "\n",
        "            # train a regressor to find the constants (too slow)\n",
        "            c = [1.0 for i,x in enumerate(predicted) if x=='C'] # initialize coefficients as 1\n",
        "            # c[-1] = 0 # initialize the constant as zero\n",
        "            b = [(-2,2) for i,x in enumerate(predicted) if x=='C']  # bounds on variables\n",
        "            try:\n",
        "                if len(c) != 0:\n",
        "                    # This is the bottleneck in our algorithm\n",
        "                    # for easier comparison, we are using minimize package\n",
        "                    cHat = minimize(lossFunc, c, #bounds=b,\n",
        "                                args=(predicted, t['X'], t['Y']))\n",
        "\n",
        "                    predicted = predicted.replace('C','{}').format(*cHat.x)\n",
        "            except ValueError:\n",
        "                raise 'Err: Wrong Equation {}'.format(predicted)\n",
        "            except Exception as e:\n",
        "                raise 'Err: Wrong Equation {}, Err: {}'.format(predicted, e)\n",
        "\n",
        "            t = json.loads(textTest[i])\n",
        "            Ys = [] #t['YT']\n",
        "            Yhats = []\n",
        "            for xs in t['XT']:\n",
        "              try:\n",
        "                  eqTmp = eq + ''  # copy eq\n",
        "                  eqTmp = eqTmp.replace(' ', '')\n",
        "                  eqTmp = eqTmp.replace('\\n', '')\n",
        "                  for i, x in enumerate(xs):\n",
        "                      # replace xi with the value in the eq\n",
        "                      eqTmp = eqTmp.replace('x{}'.format(i + 1), str(x))\n",
        "                      if ',' in eqTmp:\n",
        "                          assert 'There is a \",\" in the equation!'\n",
        "                  YEval = eval(eqTmp)\n",
        "              except Exception as e:\n",
        "                  continue\n",
        "                  print(f\"TA: Invalid equation encountered. Eq: {eqTmp}, Reason: {e}\")\n",
        "                  YEval = 100  # Assign a default value or handle as needed\n",
        "                  #raise\n",
        "                  YEval = 100\n",
        "              Ys.append(YEval)\n",
        "\n",
        "              try:\n",
        "                  eqTmp = predicted + ''  # copy eq\n",
        "                  eqTmp = eqTmp.replace(' ', '')\n",
        "                  eqTmp = eqTmp.replace('\\n', '')\n",
        "                  for i, x in enumerate(xs):\n",
        "                      # replace xi with the value in the eq\n",
        "                      eqTmp = eqTmp.replace('x{}'.format(i + 1), str(x))\n",
        "                      if ',' in eqTmp:\n",
        "                          assert 'There is a \",\" in the equation!'\n",
        "                  Yhat = eval(eqTmp)\n",
        "              except Exception as e:\n",
        "                  continue\n",
        "                  print(f\"PR: Invalid equation encountered. Eq: {eqTmp}, Reason: {e}\")\n",
        "                  Yhat = 100  # Assign a default value or handle as needed\n",
        "              Yhats.append(Yhat)\n",
        "            err = relativeErr(Ys,Yhats, info=True)\n",
        "\n",
        "\n",
        "            results['target'].append(gt_expr)\n",
        "            results['predicted'].append(predicted)\n",
        "            results['error'].append(err)\n",
        "\n",
        "            print(f\"\\nSample {batch_idx * batch_size + i + 1}:\")\n",
        "            print(f\"Target: {gt_expr}\")\n",
        "            print(f\"Predicted: {predicted}\")\n",
        "            print(f\"Relative Error: {err:.6f}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset, textTest = load_dataset(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_test.json\",  blockSize, numVars=numVars,\n",
        "                numYs=numYs, numPoints=numPoints, addVars=addVars,\n",
        "                const_range=const_range, xRange=trainRange, decimals=decimals, augment=False)\n",
        "test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "train_dataset, textTrain = load_dataset(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_train.json\",  blockSize, numVars=numVars,\n",
        "                numYs=numYs, numPoints=numPoints, addVars=addVars,\n",
        "                const_range=const_range, xRange=trainRange, decimals=decimals, augment=False)"
      ],
      "metadata": {
        "id": "GJP05EEw4qVP"
      },
      "id": "GJP05EEw4qVP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "from utils import processDataFiles, CharDataset\n",
        "import random\n",
        "\n",
        "files = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_train.json\")\n",
        "text = processDataFiles(files)\n",
        "chars = sorted(list(set(text))+['_','T','<','>',':']) # extract unique characters from the text before converting the text to a list, # T is for the test data\n",
        "text = text.split('\\n') # convert the raw text to a set of examples\n",
        "trainText = text[:-1] if len(text[-1]) == 0 else text\n",
        "random.shuffle(trainText) # shuffle the dataset, it's important specailly for the combined number of variables experiment\n",
        "train_dataset = CharDataset(trainText, blockSize, chars, numVars=numVars,\n",
        "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
        "                        const_range=const_range, xRange=trainRange, decimals=decimals)"
      ],
      "metadata": {
        "id": "JvNAveGHCEae",
        "outputId": "983f4dcd-2249-4b37-a205-55f8e1f68999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JvNAveGHCEae",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 498795 examples, 49 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(train_dataset.__len__())\n",
        "inputs, outputs, points, variables = train_dataset.__getitem__(idx)\n",
        "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
        "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
        "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
      ],
      "metadata": {
        "id": "eee1EVQjCekJ",
        "outputId": "f4748a59-4e04-403c-8ecd-1f58cf2b293a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eee1EVQjCekJ",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id:364785\n",
            "outputs:C*sin(C*x1+C)+C>________________\n",
            "variables:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_test.json\")\n",
        "textTest = processDataFiles(files)\n",
        "textTest = textTest.split('\\n') # convert the raw text to a set of examples\n",
        "# test_dataset_target = CharDataset(textTest, blockSize, chars, target=target)\n",
        "test_dataset = CharDataset(textTest, testBlockSize, chars, numVars=numVars,\n",
        "                        numYs=numYs, numPoints=numPoints, addVars=addVars,\n",
        "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
        "\n",
        "idx = np.random.randint(test_dataset.__len__())\n",
        "inputs, outputs, points, variables = test_dataset.__getitem__(idx)\n",
        "print(points.min(), points.max())\n",
        "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
        "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
        "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
      ],
      "metadata": {
        "id": "Xnj3g0a0_5R1",
        "outputId": "c2d05cac-ddf7-470c-d2e8-ed764d0ec34d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Xnj3g0a0_5R1",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 967 examples, 49 unique.\n",
            "tensor(-2.8986) tensor(2.9954)\n",
            "id:250\n",
            "outputs:2.084393248840158*cos(-1.4709096106310513*cos(1.5560821715316582*x1))+0.47074460792932005>______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "variables:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e676e953",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "e676e953",
        "outputId": "2de18c78-80cd-4c68-ecbe-b4559eb25393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '\\n', 1: ' ', 2: '\"', 3: '(', 4: ')', 5: '*', 6: '+', 7: ',', 8: '-', 9: '.', 10: '/', 11: '0', 12: '1', 13: '2', 14: '3', 15: '4', 16: '5', 17: '6', 18: '7', 19: '8', 20: '9', 21: ':', 22: ':', 23: '<', 24: '>', 25: 'C', 26: 'E', 27: 'Q', 28: 'S', 29: 'T', 30: 'X', 31: 'Y', 32: '[', 33: ']', 34: '_', 35: 'c', 36: 'e', 37: 'g', 38: 'i', 39: 'k', 40: 'l', 41: 'n', 42: 'o', 43: 'p', 44: 's', 45: 't', 46: 'x', 47: '{', 48: '}'}\n",
            "Testing SymbolicDiffusion model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "49",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e98aba36a875>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing SymbolicDiffusion model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSummary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-65f0f1386f5c>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader, test_dataset, textTest, train_dataset, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0meq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0meq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaddingToken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0meq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#if len(eq[0])>=1 else eq[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-65f0f1386f5c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0meq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0meq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaddingToken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0meq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#if len(eq[0])>=1 else eq[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 49"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pconfig = PointNetConfig(\n",
        "    embeddingSize=n_embd,\n",
        "    numberofPoints=250,\n",
        "    numberofVars=1,\n",
        "    numberofYs=1,\n",
        ")\n",
        "model = SymbolicDiffusion(\n",
        "    pconfig=pconfig,\n",
        "    vocab_size=train_dataset.vocab_size,\n",
        "    max_seq_len=32,\n",
        "    padding_idx=test_dataset.paddingID,\n",
        "    max_num_vars=9,\n",
        "    n_layer=8,\n",
        "    n_head=8,\n",
        "    n_embd=n_embd,\n",
        "    timesteps=timesteps,\n",
        "    beta_start=0.0001,\n",
        "    beta_end=0.02,\n",
        ").to(device)\n",
        "\n",
        "\n",
        "print(train_dataset.itos)\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/models/model_epoch_2.pth\"\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Testing SymbolicDiffusion model...\")\n",
        "test_results = test_model(model, test_loader, test_dataset, textTest, train_dataset, device)\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "for i in range(len(test_results['target'])):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"  Target: {test_results['target'][i]}\")\n",
        "    print(f\"  Predicted: {test_results['predicted'][i]}\")\n",
        "    print(f\"  Error: {test_results['error'][i]:.6f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}