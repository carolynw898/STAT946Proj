{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolynw898/STAT946Proj/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "45b33175",
      "metadata": {
        "id": "45b33175"
      },
      "outputs": [],
      "source": [
        "from utils import load_dataset, lossFunc, relativeErr\n",
        "from models import SymbolicDiffusion, PointNetConfig\n",
        "import torch\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3CmZzXN5ny5A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CmZzXN5ny5A",
        "outputId": "780f8807-868a-402e-be35-d1b6e660b398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "aee353d1",
      "metadata": {
        "id": "aee353d1"
      },
      "outputs": [],
      "source": [
        "n_embd = 512\n",
        "timesteps = 1000\n",
        "batch_size = 4\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 10\n",
        "blockSize = 32\n",
        "testBlockSize = 400\n",
        "numVars = 1\n",
        "numYs = 1\n",
        "numPoints = 250\n",
        "target = 'Skeleton'\n",
        "const_range = [-2.1, 2.1]\n",
        "trainRange = [-3.0, 3.0]\n",
        "decimals = 8\n",
        "addVars = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "from utils import processDataFiles, CharDataset\n",
        "import random\n",
        "\n",
        "files = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_train.json\")\n",
        "text = processDataFiles(files)\n",
        "chars = sorted(list(set(text))+['_','T','<','>',':']) # extract unique characters from the text before converting the text to a list, # T is for the test data\n",
        "text = text.split('\\n') # convert the raw text to a set of examples\n",
        "trainText = text[:-1] if len(text[-1]) == 0 else text\n",
        "random.shuffle(trainText) # shuffle the dataset, it's important specailly for the combined number of variables experiment\n",
        "train_dataset = CharDataset(trainText, blockSize, chars, numVars=numVars,\n",
        "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
        "                        const_range=const_range, xRange=trainRange, decimals=decimals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvNAveGHCEae",
        "outputId": "983f4dcd-2249-4b37-a205-55f8e1f68999"
      },
      "id": "JvNAveGHCEae",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 498795 examples, 49 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(train_dataset.__len__())\n",
        "inputs, outputs, points, variables = train_dataset.__getitem__(idx)\n",
        "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
        "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
        "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eee1EVQjCekJ",
        "outputId": "f4748a59-4e04-403c-8ecd-1f58cf2b293a"
      },
      "id": "eee1EVQjCekJ",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id:364785\n",
            "outputs:C*sin(C*x1+C)+C>________________\n",
            "variables:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_test.json\")\n",
        "textTest = processDataFiles(files)\n",
        "textTest = textTest.split('\\n') # convert the raw text to a set of examples\n",
        "# test_dataset_target = CharDataset(textTest, blockSize, chars, target=target)\n",
        "test_dataset = CharDataset(textTest, testBlockSize, chars, numVars=numVars,\n",
        "                        numYs=numYs, numPoints=numPoints, addVars=addVars,\n",
        "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
        "\n",
        "idx = np.random.randint(test_dataset.__len__())\n",
        "inputs, outputs, points, variables = test_dataset.__getitem__(idx)\n",
        "print(points.min(), points.max())\n",
        "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
        "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
        "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnj3g0a0_5R1",
        "outputId": "a205cb67-6fc7-4a44-e9b3-b68aa2814ab3"
      },
      "id": "Xnj3g0a0_5R1",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 967 examples, 49 unique.\n",
            "tensor(-6.3984) tensor(2.8021)\n",
            "id:763\n",
            "outputs:1.371809790078026*log(-0.39229257750306923*log(1.7262107074431738*x1))+-0.8044378729746045>_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "variables:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from scipy.optimize import minimize\n",
        "from math import log\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model(model, test_loader, textTest, train_dataset, device):\n",
        "    results = {'target': [], 'predicted': [], 'error': []}\n",
        "\n",
        "    for batch_idx, (_, tokens, points, variables) in enumerate(test_loader):\n",
        "        points = points.to(device)    # [B, 2, 250]\n",
        "        tokens = tokens.to(device)    # [B, L]\n",
        "        variables = variables.to(device)  # [B]\n",
        "\n",
        "        generated_tokens = model.sample(points, variables, device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Ground truth\n",
        "            eq = ''.join([train_dataset.itos[int(i)] for i in tokens[0]])\n",
        "            eq = eq.strip(train_dataset.paddingToken).split('>')\n",
        "            eq = eq[0] #if len(eq[0])>=1 else eq[1]\n",
        "            eq = eq.strip('<').strip(\">\")\n",
        "\n",
        "            # Predicted\n",
        "            predicted_tokens = generated_tokens[i].cpu().numpy()\n",
        "            predicted = ''.join([train_dataset.itos[int(idx)] for idx in predicted_tokens])\n",
        "            predicted = predicted.strip(train_dataset.paddingToken).split('>')\n",
        "            predicted = predicted[0] if len(predicted[0]) >= 1 else predicted[1]\n",
        "            predicted = predicted.strip('<').strip(\">\")\n",
        "            predicted = predicted.replace('Ce', 'C*e')\n",
        "\n",
        "            # train a regressor to find the constants (too slow)\n",
        "            c = [1.0 for i,x in enumerate(predicted) if x=='C'] # initialize coefficients as 1\n",
        "            # c[-1] = 0 # initialize the constant as zero\n",
        "            b = [(-2,2) for i,x in enumerate(predicted) if x=='C']  # bounds on variables\n",
        "            try:\n",
        "                if len(c) != 0:\n",
        "                    # This is the bottleneck in our algorithm\n",
        "                    # for easier comparison, we are using minimize package\n",
        "                    cHat = minimize(lossFunc, c, #bounds=b,\n",
        "                                args=(predicted, t['X'], t['Y']))\n",
        "\n",
        "                    predicted = predicted.replace('C','{}').format(*cHat.x)\n",
        "            except ValueError:\n",
        "                raise 'Err: Wrong Equation {}'.format(predicted)\n",
        "            except Exception as e:\n",
        "                raise 'Err: Wrong Equation {}, Err: {}'.format(predicted, e)\n",
        "\n",
        "            t = json.loads(textTest[i])\n",
        "            Ys = [] #t['YT']\n",
        "            Yhats = []\n",
        "            for xs in t['XT']:\n",
        "              try:\n",
        "                  eqTmp = eq + ''  # copy eq\n",
        "                  eqTmp = eqTmp.replace(' ', '')\n",
        "                  eqTmp = eqTmp.replace('\\n', '')\n",
        "                  for i, x in enumerate(xs):\n",
        "                      # replace xi with the value in the eq\n",
        "                      eqTmp = eqTmp.replace('x{}'.format(i + 1), str(x))\n",
        "                      if ',' in eqTmp:\n",
        "                          assert 'There is a \",\" in the equation!'\n",
        "                  YEval = eval(eqTmp)\n",
        "              except Exception as e:\n",
        "                  continue\n",
        "                  print(f\"TA: Invalid equation encountered. Eq: {eqTmp}, Reason: {e}\")\n",
        "                  YEval = 100  # Assign a default value or handle as needed\n",
        "                  #raise\n",
        "                  YEval = 100\n",
        "              Ys.append(YEval)\n",
        "\n",
        "              try:\n",
        "                  eqTmp = predicted + ''  # copy eq\n",
        "                  eqTmp = eqTmp.replace(' ', '')\n",
        "                  eqTmp = eqTmp.replace('\\n', '')\n",
        "                  for i, x in enumerate(xs):\n",
        "                      # replace xi with the value in the eq\n",
        "                      eqTmp = eqTmp.replace('x{}'.format(i + 1), str(x))\n",
        "                      if ',' in eqTmp:\n",
        "                          assert 'There is a \",\" in the equation!'\n",
        "                  Yhat = eval(eqTmp)\n",
        "              except Exception as e:\n",
        "                  continue\n",
        "                  print(f\"PR: Invalid equation encountered. Eq: {eqTmp}, Reason: {e}\")\n",
        "                  Yhat = 100  # Assign a default value or handle as needed\n",
        "              Yhats.append(Yhat)\n",
        "            err = relativeErr(Ys,Yhats, info=True)\n",
        "\n",
        "\n",
        "            results['target'].append(eq)\n",
        "            results['predicted'].append(predicted)\n",
        "            results['error'].append(err)\n",
        "\n",
        "            print(f\"\\nSample {batch_idx * batch_size + i + 1}:\")\n",
        "            print(f\"Target: {eq}\")\n",
        "            print(f\"Predicted: {predicted}\")\n",
        "            print(f\"Relative Error: {err:.6f}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "itNSUyzeNVgV"
      },
      "id": "itNSUyzeNVgV",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "e676e953",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "e676e953",
        "outputId": "844cc601-5bf2-44ef-ce37-12026bc1f463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '\\n', 1: ' ', 2: '\"', 3: '(', 4: ')', 5: '*', 6: '+', 7: ',', 8: '-', 9: '.', 10: '/', 11: '0', 12: '1', 13: '2', 14: '3', 15: '4', 16: '5', 17: '6', 18: '7', 19: '8', 20: '9', 21: ':', 22: ':', 23: '<', 24: '>', 25: 'C', 26: 'E', 27: 'Q', 28: 'S', 29: 'T', 30: 'X', 31: 'Y', 32: '[', 33: ']', 34: '_', 35: 'c', 36: 'e', 37: 'g', 38: 'i', 39: 'k', 40: 'l', 41: 'n', 42: 'o', 43: 'p', 44: 's', 45: 't', 46: 'x', 47: '{', 48: '}'}\n",
            "Testing SymbolicDiffusion model...\n",
            "\n",
            "Sample 1:\n",
            "Target: -1.4608810703863337*exp(-1.3662906591107051*x1/(1.6570892466721525*x1))+-0.5481326790673482\n",
            "Predicted: 0c6221603.192..262.5.3.*9*92702.\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 1:\n",
            "Target: -1.4608810703863337*exp(-1.3662906591107051*x1/(1.6570892466721525*x1))+-0.5481326790673482\n",
            "Predicted: 89*6978*.060*08658.1575018190260\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 1:\n",
            "Target: -1.4608810703863337*exp(-1.3662906591107051*x1/(1.6570892466721525*x1))+-0.5481326790673482\n",
            "Predicted: .037x853.27x2209440-8(8g4.920813\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 1:\n",
            "Target: -1.4608810703863337*exp(-1.3662906591107051*x1/(1.6570892466721525*x1))+-0.5481326790673482\n",
            "Predicted: .5-56403883462*262414809*19l0148\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-f952f45f4ffb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing SymbolicDiffusion model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSummary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-9336fa855a25>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader, textTest, train_dataset, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mgenerated_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, points, variables, device)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mt_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update in-place: [B] all set to t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mnoise_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mxt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_pred\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# t as int for p_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mxt_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36mp_sample\u001b[0;34m(self, x, t, noise_pred)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0malpha_bar_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         mean = (1 / torch.sqrt(alpha_t)) * (\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha_bar_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "pconfig = PointNetConfig(\n",
        "    embeddingSize=n_embd,\n",
        "    numberofPoints=250,\n",
        "    numberofVars=1,\n",
        "    numberofYs=1,\n",
        ")\n",
        "model = SymbolicDiffusion(\n",
        "    pconfig=pconfig,\n",
        "    vocab_size=train_dataset.vocab_size,\n",
        "    max_seq_len=32,\n",
        "    padding_idx=test_dataset.paddingID,\n",
        "    max_num_vars=9,\n",
        "    n_layer=8,\n",
        "    n_head=8,\n",
        "    n_embd=n_embd,\n",
        "    timesteps=timesteps,\n",
        "    beta_start=0.0001,\n",
        "    beta_end=0.02,\n",
        ").to(device)\n",
        "\n",
        "\n",
        "print(train_dataset.itos)\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/models/model_epoch_2.pth\"\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Testing SymbolicDiffusion model...\")\n",
        "test_results = test_model(model, test_loader, textTest, train_dataset, device)\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "for i in range(len(test_results['target'])):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"  Target: {test_results['target'][i]}\")\n",
        "    print(f\"  Predicted: {test_results['predicted'][i]}\")\n",
        "    print(f\"  Error: {test_results['error'][i]:.6f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}