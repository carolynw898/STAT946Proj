{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolynw898/STAT946Proj/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "45b33175",
      "metadata": {
        "id": "45b33175"
      },
      "outputs": [],
      "source": [
        "from utils import lossFunc, relativeErr\n",
        "from models import SymbolicDiffusion, PointNetConfig\n",
        "import torch\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3CmZzXN5ny5A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CmZzXN5ny5A",
        "outputId": "4516c9f0-06b0-4b74-afdb-572e11e6b06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aee353d1",
      "metadata": {
        "id": "aee353d1"
      },
      "outputs": [],
      "source": [
        "n_embd = 512\n",
        "timesteps = 1000\n",
        "batch_size = 1\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 10\n",
        "blockSize = 32\n",
        "testBlockSize = 400\n",
        "numVars = 1\n",
        "numYs = 1\n",
        "numPoints = 250\n",
        "target = 'Skeleton'\n",
        "const_range = [-2.1, 2.1]\n",
        "trainRange = [-3.0, 3.0]\n",
        "decimals = 8\n",
        "addVars = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "from utils import processDataFiles, CharDataset\n",
        "import random\n",
        "\n",
        "files = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_train.json\")\n",
        "text = processDataFiles(files)\n",
        "chars = sorted(list(set(text))+['_','T','<','>',':']) # extract unique characters from the text before converting the text to a list, # T is for the test data\n",
        "text = text.split('\\n') # convert the raw text to a set of examples\n",
        "trainText = text[:-1] if len(text[-1]) == 0 else text\n",
        "random.shuffle(trainText) # shuffle the dataset, it's important specailly for the combined number of variables experiment\n",
        "train_dataset = CharDataset(trainText, blockSize, chars, numVars=numVars,\n",
        "                        numYs=numYs, numPoints=numPoints, target=target, addVars=addVars,\n",
        "                        const_range=const_range, xRange=trainRange, decimals=decimals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvNAveGHCEae",
        "outputId": "5f748962-99c8-4e4c-d66a-645837e34171"
      },
      "id": "JvNAveGHCEae",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 498795 examples, 49 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(train_dataset.__len__())\n",
        "inputs, outputs, points, variables = train_dataset.__getitem__(idx)\n",
        "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
        "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
        "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eee1EVQjCekJ",
        "outputId": "67060842-4584-425c-bfed-6ae59275cf67"
      },
      "id": "eee1EVQjCekJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id:195859\n",
            "outputs:C*exp(C*x1**3)+C*log(C*x1+C)+C>_\n",
            "variables:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/data/1_var_test.json\")\n",
        "textTest = processDataFiles(files)\n",
        "textTest = textTest.split('\\n') # convert the raw text to a set of examples\n",
        "# test_dataset_target = CharDataset(textTest, blockSize, chars, target=target)\n",
        "test_dataset = CharDataset(textTest, testBlockSize, chars, numVars=numVars,\n",
        "                        numYs=numYs, numPoints=numPoints, addVars=addVars,\n",
        "                        const_range=const_range, xRange=trainRange, decimals=decimals)\n",
        "\n",
        "idx = np.random.randint(test_dataset.__len__())\n",
        "inputs, outputs, points, variables = test_dataset.__getitem__(idx)\n",
        "print(points.min(), points.max())\n",
        "inputs = ''.join([train_dataset.itos[int(i)] for i in inputs])\n",
        "outputs = ''.join([train_dataset.itos[int(i)] for i in outputs])\n",
        "print('id:{}\\noutputs:{}\\nvariables:{}'.format(idx,outputs,variables))\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnj3g0a0_5R1",
        "outputId": "3801f9b7-c466-44ff-9d97-cd22ff16db66"
      },
      "id": "Xnj3g0a0_5R1",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 967 examples, 49 unique.\n",
            "tensor(-2.9053) tensor(4.1510)\n",
            "id:131\n",
            "outputs:0.7878403175777757*x1+1.9934309457418338>_______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "variables:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from scipy.optimize import minimize\n",
        "from math import log\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model(model, test_loader, textTest, train_dataset, device):\n",
        "    results = {'target': [], 'predicted': [], 'error': []}\n",
        "\n",
        "    for batch_idx, (_, tokens, points, variables) in enumerate(test_loader):\n",
        "        points = points.to(device)    # [B, 2, 250]\n",
        "        tokens = tokens.to(device)    # [B, L]\n",
        "        variables = variables.to(device)  # [B]\n",
        "\n",
        "        generated_tokens = model.sample(points, variables, device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Ground truth\n",
        "            eq = ''.join([train_dataset.itos[int(i)] for i in tokens[0]])\n",
        "            eq = eq.strip(train_dataset.paddingToken).split('>')\n",
        "            eq = eq[0] #if len(eq[0])>=1 else eq[1]\n",
        "            eq = eq.strip('<').strip(\">\")\n",
        "\n",
        "            # Predicted\n",
        "            predicted_tokens = generated_tokens[i].cpu().numpy()\n",
        "            predicted = ''.join([train_dataset.itos[int(idx)] for idx in predicted_tokens])\n",
        "            predicted = predicted.strip(train_dataset.paddingToken).split('>')\n",
        "            predicted = predicted[0] if len(predicted[0]) >= 1 else predicted[1]\n",
        "            predicted = predicted.strip('<').strip(\">\")\n",
        "            predicted = predicted.replace('Ce', 'C*e')\n",
        "\n",
        "            # train a regressor to find the constants (too slow)\n",
        "            c = [1.0 for i,x in enumerate(predicted) if x=='C'] # initialize coefficients as 1\n",
        "            # c[-1] = 0 # initialize the constant as zero\n",
        "            b = [(-2,2) for i,x in enumerate(predicted) if x=='C']  # bounds on variables\n",
        "            try:\n",
        "                if len(c) != 0:\n",
        "                    # This is the bottleneck in our algorithm\n",
        "                    # for easier comparison, we are using minimize package\n",
        "                    cHat = minimize(lossFunc, c, #bounds=b,\n",
        "                                args=(predicted, t['X'], t['Y']))\n",
        "\n",
        "                    predicted = predicted.replace('C','{}').format(*cHat.x)\n",
        "            except ValueError:\n",
        "                raise 'Err: Wrong Equation {}'.format(predicted)\n",
        "            except Exception as e:\n",
        "                raise 'Err: Wrong Equation {}, Err: {}'.format(predicted, e)\n",
        "\n",
        "            t = json.loads(textTest[i])\n",
        "            Ys = [] #t['YT']\n",
        "            Yhats = []\n",
        "            for xs in t['XT']:\n",
        "              try:\n",
        "                  eqTmp = eq + ''  # copy eq\n",
        "                  eqTmp = eqTmp.replace(' ', '')\n",
        "                  eqTmp = eqTmp.replace('\\n', '')\n",
        "                  for i, x in enumerate(xs):\n",
        "                      # replace xi with the value in the eq\n",
        "                      eqTmp = eqTmp.replace('x{}'.format(i + 1), str(x))\n",
        "                      if ',' in eqTmp:\n",
        "                          assert 'There is a \",\" in the equation!'\n",
        "                  YEval = eval(eqTmp)\n",
        "              except Exception as e:\n",
        "                  continue\n",
        "                  print(f\"TA: Invalid equation encountered. Eq: {eqTmp}, Reason: {e}\")\n",
        "                  YEval = 100  # Assign a default value or handle as needed\n",
        "                  #raise\n",
        "                  YEval = 100\n",
        "              Ys.append(YEval)\n",
        "\n",
        "              try:\n",
        "                  eqTmp = predicted + ''  # copy eq\n",
        "                  eqTmp = eqTmp.replace(' ', '')\n",
        "                  eqTmp = eqTmp.replace('\\n', '')\n",
        "                  for i, x in enumerate(xs):\n",
        "                      # replace xi with the value in the eq\n",
        "                      eqTmp = eqTmp.replace('x{}'.format(i + 1), str(x))\n",
        "                      if ',' in eqTmp:\n",
        "                          assert 'There is a \",\" in the equation!'\n",
        "                  Yhat = eval(eqTmp)\n",
        "              except Exception as e:\n",
        "                  continue\n",
        "                  print(f\"PR: Invalid equation encountered. Eq: {eqTmp}, Reason: {e}\")\n",
        "                  Yhat = 100  # Assign a default value or handle as needed\n",
        "              Yhats.append(Yhat)\n",
        "            err = relativeErr(Ys,Yhats, info=True)\n",
        "\n",
        "\n",
        "            results['target'].append(eq)\n",
        "            results['predicted'].append(predicted)\n",
        "            results['error'].append(err)\n",
        "\n",
        "            print(f\"\\nSample {batch_idx * batch_size + i + 1}:\")\n",
        "            print(f\"Target: {eq}\")\n",
        "            print(f\"Predicted: {predicted}\")\n",
        "            print(f\"Relative Error: {err:.6f}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "itNSUyzeNVgV"
      },
      "id": "itNSUyzeNVgV",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e676e953",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e676e953",
        "outputId": "3b3930c2-5c7a-4d72-cb4a-c3c2a289aae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '\\n', 1: ' ', 2: '\"', 3: '(', 4: ')', 5: '*', 6: '+', 7: ',', 8: '-', 9: '.', 10: '/', 11: '0', 12: '1', 13: '2', 14: '3', 15: '4', 16: '5', 17: '6', 18: '7', 19: '8', 20: '9', 21: ':', 22: ':', 23: '<', 24: '>', 25: 'C', 26: 'E', 27: 'Q', 28: 'S', 29: 'T', 30: 'X', 31: 'Y', 32: '[', 33: ']', 34: '_', 35: 'c', 36: 'e', 37: 'g', 38: 'i', 39: 'k', 40: 'l', 41: 'n', 42: 'o', 43: 'p', 44: 's', 45: 't', 46: 'x', 47: '{', 48: '}'}\n",
            "Testing SymbolicDiffusion model...\n",
            "\n",
            "Sample 1:\n",
            "Target: -1.4608810703863337*exp(-1.3662906591107051*x1/(1.6570892466721525*x1))+-0.5481326790673482\n",
            "Predicted: o3oo3oo3o3ooo33oo3o33o33oooo333o\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 2:\n",
            "Target: 0.9397283929441147*exp(-1.7138582239614426*x1)*-2.0077425853788546*cos(-1.3353942241925272*x1**2+-0.9402324542557938*x1)+0.7279997618628564\n",
            "Predicted: o333o33oo3o3o3oo3ooo3o3oo3oo333o\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 3:\n",
            "Target: 0.5035538309121157*x1**5+-1.7880275308333555*x1**4+1.9763031036747143*x1**3+0.64126273976877*x1**2*1.9018843748420244*log(0.8634365809569955*x1)+-1.6578296868442013*x1**2+-0.4515420744032035*x1+1.133184078275951\n",
            "Predicted: 33o3o3oo3oo33oo3333333333o33o33o\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 4:\n",
            "Target: 0.25685479717362014*x1/(1.3240180394403067*x1+-0.16002606291656596)+1.3023923419772578\n",
            "Predicted: o3oooo3333oooooooo3o3oo33o3333o3\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 5:\n",
            "Target: 0.9633718254570423*x1*1.9148717606989867*log(0.9006877952636358*x1**4+1.6669653267307702*x1**3+0.5648574464503451*x1**2+-1.2276559446229411*x1+-0.6261005199630683)*-1.7718715377928107*sin(1.342774419612362*x1)+0.6767932552032421\n",
            "Predicted: 3333333o3o3o3ooo333o3oo3o33o33oo\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 6:\n",
            "Target: -2.03995581177251*x1**2+1.784589431926912*x1+-0.0323998685508311\n",
            "Predicted: oo3ooo3o333o3o3ooo33o3oo3o33o3oo\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 7:\n",
            "Target: 0.7857267985261505*x1+1.8322960722393105*sin(1.4963571161610014*x1)+0.7030234480140063\n",
            "Predicted: 3o33o333o3333oo3333333o3oo33o3o3\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 8:\n",
            "Target: -0.961876108374458*x1+-1.250800758696987/x1+-1.0663702739185705\n",
            "Predicted: 3333o33o3oo33o333oo3o3o3o3o3o33o\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 9:\n",
            "Target: -1.1721166123163602*x1**5+1.6974628250176984*x1**4+-1.8183674492315656*x1**3+0.28345722200202106*x1**2+-0.20747095003007954*x1+-1.8057037618847964\n",
            "Predicted: 3oo3333o3o3oo3oooo33333333oo3333\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 10:\n",
            "Target: 0.5429391980551586*x1**4+0.5587698685776163*x1**2+0.26202636943628077\n",
            "Predicted: 3333333oo33ooo3o333oo33oo3o3oooo\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 11:\n",
            "Target: -1.6520979503835531*sin(-0.8793737280343623*cos(1.3548815753934487*exp(0.7480493823527654*x1)))+1.3078534309295304\n",
            "Predicted: oo33oo3ooo3oo333o33333ooo3oooo33\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n",
            "\n",
            "Sample 12:\n",
            "Target: 1.9408099468570277*x1*0.48518007925928686*log(-0.37576148071164694*x1**3+-0.4469742917830326*x1**2+1.2349053621894983*x1+-1.1406322138901035)+-0.6421494302018327*exp(-1.2980538069135452*x1)+1.9610357296909817\n",
            "Predicted: oo3oo3o33oo33ooo3333oooo3ooo333o\n",
            "Relative Error: 100.000000\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1cf7e80b2d39>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing SymbolicDiffusion model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSummary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9336fa855a25>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader, textTest, train_dataset, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mgenerated_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, points, variables, device)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimesteps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mt_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update in-place: [B] all set to t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mnoise_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mxt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_pred\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# t as int for p_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mxt_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_t, t, condition)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_emb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtime_emb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mnoise_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnoise_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    885\u001b[0m                     \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                 )\n\u001b[0;32m--> 887\u001b[0;31m                 return torch._transformer_encoder_layer_fwd(\n\u001b[0m\u001b[1;32m    888\u001b[0m                     \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "pconfig = PointNetConfig(\n",
        "    embeddingSize=n_embd,\n",
        "    numberofPoints=250,\n",
        "    numberofVars=1,\n",
        "    numberofYs=1,\n",
        ")\n",
        "model = SymbolicDiffusion(\n",
        "    pconfig=pconfig,\n",
        "    vocab_size=train_dataset.vocab_size,\n",
        "    max_seq_len=32,\n",
        "    padding_idx=test_dataset.paddingID,\n",
        "    max_num_vars=9,\n",
        "    n_layer=4,\n",
        "    n_head=4,\n",
        "    n_embd=n_embd,\n",
        "    timesteps=timesteps,\n",
        "    beta_start=0.0001,\n",
        "    beta_end=0.02,\n",
        ").to(device)\n",
        "\n",
        "\n",
        "print(train_dataset.itos)\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/STAT946_proj/models/best_model.pth\"\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Testing SymbolicDiffusion model...\")\n",
        "test_results = test_model(model, test_loader, textTest, train_dataset, device)\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "for i in range(len(test_results['target'])):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"  Target: {test_results['target'][i]}\")\n",
        "    print(f\"  Predicted: {test_results['predicted'][i]}\")\n",
        "    print(f\"  Error: {test_results['error'][i]:.6f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}